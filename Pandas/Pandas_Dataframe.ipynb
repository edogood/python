{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas \n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like Series and DataFrame, which allow for efficient handling of structured data. With Pandas, you can easily perform operations such as filtering, grouping, and aggregating data, making it an essential tool for data scientists and analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Pandas\n",
    "To use Pandas in your Python code, you need to import it first. The common convention is to import it as `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951555c3",
   "metadata": {},
   "source": [
    "# Basic Data Structures in Pandas\n",
    "Pandas provides two primary data structures: Series and DataFrame.\n",
    "- Series: A one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a database table.\n",
    "- DataFrame: A two-dimensional labeled data structure with columns of potentially different types. It is similar to a table in a relational database or a spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f640e",
   "metadata": {},
   "source": [
    "### Methods and Attributes of DataFrame\n",
    "\n",
    "**Construction and Creation**\n",
    "- [`from_dict`](#dataframefrom_dict)\n",
    "- [`from_records`](#dataframefrom_records)\n",
    "- [`from_arrow`](#dataframefrom_arrow)\n",
    "- [`copy`](#dataframecopy)\n",
    "- [`assign`](#dataframeassign)\n",
    "- [`astype`](#dataframeastype)\n",
    "- [`convert_dtypes`](#dataframeconvert_dtypes)\n",
    "- [`infer_objects`](#dataframeinfer_objects)\n",
    "- [`set_axis`](#dataframeset_axis)\n",
    "- [`set_flags`](#dataframeset_flags)\n",
    "- [`add_prefix`](#dataframeadd_prefix)\n",
    "- [`add_suffix`](#dataframeadd_suffix)\n",
    "\n",
    "**Structural Attributes**\n",
    "- [`info`](#dataframeinfo)\n",
    "- [`memory_usage`](#dataframememory_usage)\n",
    "- [`keys`](#dataframekeys)\n",
    "- [`items`](#dataframeitems)\n",
    "- [`select_dtypes`](#dataframeselect_dtypes)\n",
    "- [`squeeze`](#dataframesqueeze)\n",
    "\n",
    "**Selection and Access**\n",
    "- [`head`](#dataframehead)\n",
    "- [`tail`](#dataframetail)\n",
    "- [`sample`](#dataframesample)\n",
    "- [`take`](#dataframetake)\n",
    "- [`xs`](#dataframexs)\n",
    "- [`get`](#dataframeget)\n",
    "- [`filter`](#dataframefilter)\n",
    "- [`at_time`](#dataframeat_time)\n",
    "- [`between_time`](#dataframebetween_time)\n",
    "- [`iterrows`](#dataframeiterrows)\n",
    "- [`itertuples`](#dataframeitertuples)\n",
    "\n",
    "**Structure Manipulation**\n",
    "- [`insert`](#dataframeinsert)\n",
    "- [`pop`](#dataframepop)\n",
    "- [`drop`](#dataframedrop)\n",
    "- [`drop_duplicates`](#dataframedrop_duplicates)\n",
    "- [`duplicated`](#dataframeduplicated)\n",
    "- [`droplevel`](#dataframedroplevel)\n",
    "- [`set_index`](#dataframeset_index)\n",
    "- [`reset_index`](#dataframereset_index)\n",
    "- [`reindex`](#dataframereindex)\n",
    "- [`reindex_like`](#dataframereindex_like)\n",
    "- [`rename`](#dataframerename)\n",
    "- [`rename_axis`](#dataframerename_axis)\n",
    "- [`reorder_levels`](#dataframereorder_levels)\n",
    "- [`swaplevel`](#dataframeswaplevel)\n",
    "- [`explode`](#dataframeexplode)\n",
    "- [`melt`](#dataframemelt)\n",
    "- [`stack`](#dataframestack)\n",
    "- [`unstack`](#dataframeunstack)\n",
    "- [`transpose`](#dataframetranspose)\n",
    "- [`truncate`](#dataframetruncate)\n",
    "- [`replace`](#dataframereplace)\n",
    "- [`update`](#dataframeupdate)\n",
    "- [`isetitem`](#dataframeisetitem)\n",
    "\n",
    "**Missing Data**\n",
    "- [`isna`](#dataframeisna)\n",
    "- [`isnull`](#dataframeisnull)\n",
    "- [`notna`](#dataframenotna)\n",
    "- [`notnull`](#dataframenotnull)\n",
    "- [`fillna`](#dataframefillna)\n",
    "- [`ffill`](#dataframeffill)\n",
    "- [`bfill`](#dataframebfill)\n",
    "- [`dropna`](#dataframedropna)\n",
    "- [`interpolate`](#dataframeinterpolate)\n",
    "- [`first_valid_index`](#dataframefirst_valid_index)\n",
    "- [`combine_first`](#dataframecombine_first)\n",
    "- [`where`](#dataframewhere)\n",
    "- [`mask`](#dataframemask)\n",
    "\n",
    "**Mathematical and Logical Operations**\n",
    "- [`abs`](#dataframeabs)\n",
    "- [`add`](#dataframeadd)\n",
    "- [`radd`](#dataframeradd)\n",
    "- [`sub`](#dataframesub)\n",
    "- [`subtract`](#dataframesubtract)\n",
    "- [`rsub`](#dataframersub)\n",
    "- [`mul`](#dataframemul)\n",
    "- [`multiply`](#dataframemultiply)\n",
    "- [`rmul`](#dataframermul)\n",
    "- [`div`](#dataframediv)\n",
    "- [`divide`](#dataframedivide)\n",
    "- [`rdiv`](#dataframerdiv)\n",
    "- [`truediv`](#dataframetruediv)\n",
    "- [`rtruediv`](#dataframertruediv)\n",
    "- [`floordiv`](#dataframefloordiv)\n",
    "- [`rfloordiv`](#dataframerfloordiv)\n",
    "- [`mod`](#dataframemod)\n",
    "- [`rmod`](#dataframermod)\n",
    "- [`pow`](#dataframepow)\n",
    "- [`rpow`](#dataframerpow)\n",
    "- [`dot`](#dataframedot)\n",
    "- [`clip`](#dataframeclip)\n",
    "- [`round`](#dataframeround)\n",
    "- [`eq`](#dataframeeq)\n",
    "- [`ne`](#dataframene)\n",
    "- [`gt`](#dataframegt)\n",
    "- [`ge`](#dataframege)\n",
    "- [`lt`](#dataframelt)\n",
    "- [`le`](#dataframele)\n",
    "- [`all`](#dataframeall)\n",
    "- [`any`](#dataframeany)\n",
    "- [`equals`](#dataframeequals)\n",
    "\n",
    "**Aggregation and Statistics**\n",
    "- [`agg`](#dataframeagg)\n",
    "- [`aggregate`](#dataframeaggregate)\n",
    "- [`count`](#dataframecount)\n",
    "- [`sum`](#dataframesum)\n",
    "- [`prod`](#dataframeprod)\n",
    "- [`product`](#dataframeproduct)\n",
    "- [`mean`](#dataframemean)\n",
    "- [`median`](#dataframemedian)\n",
    "- [`min`](#dataframemin)\n",
    "- [`max`](#dataframemax)\n",
    "- [`mode`](#dataframemode)\n",
    "- [`std`](#dataframestd)\n",
    "- [`var`](#dataframevar)\n",
    "- [`sem`](#dataframesem)\n",
    "- [`skew`](#dataframeskew)\n",
    "- [`kurt`](#dataframekurt)\n",
    "- [`kurtosis`](#dataframekurtosis)\n",
    "- [`describe`](#dataframedescribe)\n",
    "- [`quantile`](#dataframequantile)\n",
    "- [`nunique`](#dataframenunique)\n",
    "- [`value_counts`](#dataframevalue_counts)\n",
    "- [`idxmax`](#dataframeidxmax)\n",
    "- [`idxmin`](#dataframeidxmin)\n",
    "- [`corr`](#dataframecorr)\n",
    "- [`corrwith`](#dataframecorrwith)\n",
    "- [`cov`](#dataframecov)\n",
    "- [`cumsum`](#dataframecumsum)\n",
    "- [`cumprod`](#dataframecumprod)\n",
    "- [`cummax`](#dataframecummax)\n",
    "- [`cummin`](#dataframecummin)\n",
    "- [`diff`](#dataframediff)\n",
    "- [`boxplot`](#dataframeboxplot)\n",
    "- [`hist`](#dataframehist)\n",
    "\n",
    "**GroupBy and Window**\n",
    "- [`groupby`](#dataframegroupby)\n",
    "- [`rolling`](#dataframerolling)\n",
    "- [`expanding`](#dataframeexpanding)\n",
    "- [`ewm`](#dataframeewm)\n",
    "\n",
    "**Merge, Join and Reshape**\n",
    "- [`merge`](#dataframemerge)\n",
    "- [`join`](#dataframejoin)\n",
    "- [`align`](#dataframealign)\n",
    "- [`combine`](#dataframecombine)\n",
    "- [`compare`](#dataframecompare)\n",
    "- [`pivot`](#dataframepivot)\n",
    "- [`pivot_table`](#dataframepivot_table)\n",
    "\n",
    "**Time Series**\n",
    "- [`asfreq`](#dataframeasfreq)\n",
    "- [`asof`](#dataframeasof)\n",
    "- [`shift`](#dataframeshift)\n",
    "- [`resample`](#dataframeresample)\n",
    "- [`pct_change`](#dataframepct_change)\n",
    "- [`to_period`](#dataframeto_period)\n",
    "- [`to_timestamp`](#dataframeto_timestamp)\n",
    "- [`tz_convert`](#dataframetz_convert)\n",
    "- [`tz_localize`](#dataframetz_localize)\n",
    "\n",
    "**Sorting and Ranking**\n",
    "- [`sort_index`](#dataframesort_index)\n",
    "- [`sort_values`](#dataframesort_values)\n",
    "- [`rank`](#dataframerank)\n",
    "- [`nlargest`](#dataframenlargest)\n",
    "- [`nsmallest`](#dataframensmallest)\n",
    "\n",
    "**Function Application**\n",
    "- [`apply`](#dataframeapply)\n",
    "- [`map`](#dataframemap)\n",
    "- [`pipe`](#dataframepipe)\n",
    "- [`eval`](#dataframeeval)\n",
    "- [`query`](#dataframequery)\n",
    "- [`transform`](#dataframetransform)\n",
    "\n",
    "**I/O and Serialization**\n",
    "- [`to_clipboard`](#dataframeto_clipboard)\n",
    "- [`to_csv`](#dataframeto_csv)\n",
    "- [`to_dict`](#dataframeto_dict)\n",
    "- [`to_excel`](#dataframeto_excel)\n",
    "- [`to_feather`](#dataframeto_feather)\n",
    "- [`to_hdf`](#dataframeto_hdf)\n",
    "- [`to_html`](#dataframeto_html)\n",
    "- [`to_iceberg`](#dataframeto_iceberg)\n",
    "- [`to_json`](#dataframeto_json)\n",
    "- [`to_latex`](#dataframeto_latex)\n",
    "- [`to_markdown`](#dataframeto_markdown)\n",
    "- [`to_numpy`](#dataframeto_numpy)\n",
    "- [`to_orc`](#dataframeto_orc)\n",
    "- [`to_parquet`](#dataframeto_parquet)\n",
    "- [`to_pickle`](#dataframeto_pickle)\n",
    "- [`to_records`](#dataframeto_records)\n",
    "- [`to_sql`](#dataframeto_sql)\n",
    "- [`to_stata`](#dataframeto_stata)\n",
    "- [`to_string`](#dataframeto_string)\n",
    "- [`to_xarray`](#dataframeto_xarray)\n",
    "- [`to_xml`](#dataframeto_xml)\n",
    "\n",
    "**Special Methods (dunder methods)**\n",
    "- [`dataframe`](#dataframedataframe)\n",
    "- [`iter`](#dataframeiter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d24b2",
   "metadata": {},
   "source": [
    "## Construction and Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Start with constructors (`from_dict`, `from_records`, `from_arrow`), then schema controls (`astype`, `convert_dtypes`, `infer_objects`).\n",
    "- Finish with metadata/label helpers (`set_axis`, `set_flags`, `add_prefix`, `add_suffix`).\n",
    "- Goal: build clean, typed DataFrames before analysis starts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4982145",
   "metadata": {},
   "source": [
    "### DataFrame.from_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de2e7e",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77bb6a",
   "metadata": {},
   "source": [
    "`DataFrame.from_dict` builds a DataFrame from a Python dictionary.\n",
    "It is one of the fastest ways to turn in-memory dict data into tabular form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068bfdd0",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d7280",
   "metadata": {},
   "source": [
    "- `data`: dictionary of array-like values, Series, or dicts.\n",
    "- `orient`: `'columns'` (default), `'index'`, or `'tight'` to interpret dict layout.\n",
    "- `dtype`: optional dtype cast applied to result.\n",
    "- `columns`: optional column labels (used with `orient='index'`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1a232",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ef905",
   "metadata": {},
   "source": [
    "- You have labeled boxes (`dict` keys) and each box contains values.\n",
    "- `from_dict` arranges those boxes into DataFrame columns or rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17cc08",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb56ae",
   "metadata": {},
   "source": [
    "- Pandas reads keys as labels and normalizes values to aligned arrays.\n",
    "- If `orient='columns'`, keys become columns.\n",
    "- If `orient='index'`, keys become row labels and values become row records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289a109",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3a957",
   "metadata": {},
   "source": [
    "- Uneven list lengths raise errors.\n",
    "- `orient='index'` with missing fields can introduce `NaN`.\n",
    "- Large nested dicts can be slower than loading from file formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ad777",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190193e",
   "metadata": {},
   "source": [
    "- Is your dict column-oriented or row-oriented?\n",
    "- Do all value arrays have consistent lengths?\n",
    "- Do you need explicit dtype control after construction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4309f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d010171",
   "metadata": {},
   "source": [
    "Use `from_dict` when your data already exists as a Python dictionary and you need a DataFrame immediately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f31e8",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97910157",
   "metadata": {},
   "source": [
    "Scenario: API response comes as a dictionary of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d995226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "payload = {\n",
    "    'customer_id': [101, 102, 103],\n",
    "    'country': ['US', 'IT', 'US'],\n",
    "    'spend': [120.5, 80.0, 230.1],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(payload)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fad7f6",
   "metadata": {},
   "source": [
    "### DataFrame.from_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb0fa2",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f084eb",
   "metadata": {},
   "source": [
    "`DataFrame.from_records` builds a DataFrame from row records, such as list-of-dicts or list-of-tuples.\n",
    "It is ideal when each element represents one row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28765b1f",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7c01a",
   "metadata": {},
   "source": [
    "- `data`: structured ndarray, sequence of tuples, dicts, or dataclass-like records.\n",
    "- `index`: optional index for resulting DataFrame.\n",
    "- `exclude`: fields to exclude from structured input.\n",
    "- `columns`: explicit column order/names.\n",
    "- `coerce_float`: try converting non-string, non-numeric objects to float.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf397864",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3594bad",
   "metadata": {},
   "source": [
    "- Think of filling a spreadsheet row by row from forms submitted by users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75d72c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c0583",
   "metadata": {},
   "source": [
    "- Pandas iterates record entries and unions keys/fields into columns.\n",
    "- Missing keys in some records produce `NaN` in those cells.\n",
    "- Structured arrays keep field names as column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbc2fc",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee00ac",
   "metadata": {},
   "source": [
    "- Inconsistent key sets across dict records create sparse columns.\n",
    "- Large Python object records can be slower than vectorized sources.\n",
    "- Tuple records need clear column order to avoid mistakes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4367d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523c911",
   "metadata": {},
   "source": [
    "- Is each element in your input truly a row?\n",
    "- Do records have consistent fields?\n",
    "- Do you need to preserve field order explicitly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472da18",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625135b6",
   "metadata": {},
   "source": [
    "Use `from_records` when your source data is naturally row-based.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61de3c1",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b3f25",
   "metadata": {},
   "source": [
    "Scenario: logs already parsed into list-of-dicts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records = [\n",
    "    {'event': 'login', 'user': 'anna', 'ok': True},\n",
    "    {'event': 'purchase', 'user': 'anna', 'ok': True},\n",
    "    {'event': 'login', 'user': 'mike', 'ok': False},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2132e",
   "metadata": {},
   "source": [
    "### DataFrame.from_arrow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf6aaa",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b0d24",
   "metadata": {},
   "source": [
    "`DataFrame.from_arrow` creates a DataFrame from a PyArrow table/array.\n",
    "It is useful in Arrow-native pipelines for analytics and efficient memory interchange.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87caeaa1",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e3642",
   "metadata": {},
   "source": [
    "- `data`: Arrow object (typically a `pyarrow.Table` or compatible structure).\n",
    "- Additional behavior depends on pandas and pyarrow versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c9e67",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd61a89",
   "metadata": {},
   "source": [
    "- You receive data already packed in a high-performance container (Arrow).\n",
    "- `from_arrow` unpacks it into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b8232",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35763cbf",
   "metadata": {},
   "source": [
    "- Pandas reads Arrow schema and columns, then materializes pandas-compatible columns.\n",
    "- Depending on backend settings, some Arrow dtypes can remain Arrow-backed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c6ac",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed5378",
   "metadata": {},
   "source": [
    "- Requires `pyarrow` installed and compatible version.\n",
    "- Type conversion differences may appear (especially strings, timestamps, null handling).\n",
    "- Behavior can vary by pandas release and Arrow backend configuration.\n",
    "- Availability can depend on pandas version and installed `pyarrow` backend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f120aa",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efc3a3",
   "metadata": {},
   "source": [
    "- Is your upstream data already in Arrow format?\n",
    "- Do you need Arrow-backed dtypes or classic NumPy-backed dtypes?\n",
    "- Are you pinned to pandas/pyarrow versions in production?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0eabbb",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee157e",
   "metadata": {},
   "source": [
    "Use `from_arrow` when integrating Arrow-native data without first converting to Python objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff562b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc7b6d",
   "metadata": {},
   "source": [
    "Scenario: convert an Arrow table from a data lake query into pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "table = pa.table({\n",
    "    'id': [1, 2, 3],\n",
    "    'city': ['New York', 'Rome', 'Berlin'],\n",
    "})\n",
    "\n",
    "df = pd.DataFrame.from_arrow(table)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7145c70",
   "metadata": {},
   "source": [
    "### DataFrame.copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e68fb9",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72458a43",
   "metadata": {},
   "source": [
    "`DataFrame.copy` duplicates a DataFrame so later edits do not unexpectedly affect the original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174538b",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27a325",
   "metadata": {},
   "source": [
    "- `deep`: `True` (default) for deep copy of data and index; `False` for shallow copy semantics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b5b3e",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8841acd",
   "metadata": {},
   "source": [
    "- Deep copy is photocopying a document.\n",
    "- Shallow copy is sharing the same sheet with another label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434b91b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9da355",
   "metadata": {},
   "source": [
    "- With `deep=True`, pandas allocates new objects for data containers.\n",
    "- With `deep=False`, references can still point to shared underlying blocks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d36702",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ab4ec",
   "metadata": {},
   "source": [
    "- Deep copies consume memory.\n",
    "- Shallow copy can surprise you if one object mutation appears in another.\n",
    "- Copy-on-write behavior can differ by pandas version/settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a88af7",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202e882",
   "metadata": {},
   "source": [
    "- Do you need full isolation or just a temporary view-like object?\n",
    "- Is memory pressure a concern?\n",
    "- Will downstream code mutate the DataFrame?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8eaac3",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e3f64",
   "metadata": {},
   "source": [
    "Use `copy` before risky mutations when you need control over side effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c86333",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbaaf92",
   "metadata": {},
   "source": [
    "Scenario: preserve raw data before feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3bcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.DataFrame({'x': [1, 2, 3]})\n",
    "work = raw.copy(deep=True)\n",
    "work['x2'] = work['x'] ** 2\n",
    "\n",
    "print('raw:')\n",
    "print(raw)\n",
    "print('work:')\n",
    "print(work)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e2116",
   "metadata": {},
   "source": [
    "### DataFrame.assign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50143e5",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454da63f",
   "metadata": {},
   "source": [
    "`DataFrame.assign` returns a new DataFrame with added or replaced columns.\n",
    "It is convenient for readable method chains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0dd7e",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf2a78",
   "metadata": {},
   "source": [
    "- `**kwargs`: column names mapped to values or callables.\n",
    "- Callable values receive the DataFrame and should return a column-like result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321cef06",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a529bb2",
   "metadata": {},
   "source": [
    "- You keep the original table untouched and create a new version with extra calculated columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0c410",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67685855",
   "metadata": {},
   "source": [
    "- Pandas evaluates keyword arguments left-to-right.\n",
    "- New columns can reference columns created earlier in the same `assign` call.\n",
    "- Result is a new DataFrame object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab378b6",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e00c28",
   "metadata": {},
   "source": [
    "- Large chained operations can increase temporary memory usage.\n",
    "- Name collisions overwrite existing columns.\n",
    "- Callable logic should remain simple for readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b46446",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf49ec",
   "metadata": {},
   "source": [
    "- Are you intentionally creating a new DataFrame rather than mutating in place?\n",
    "- Do any new column names overwrite existing columns?\n",
    "- Are dependencies between assigned columns ordered correctly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d1f6e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337d576",
   "metadata": {},
   "source": [
    "Use `assign` to build clean, composable feature engineering pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6e707",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c8aaa",
   "metadata": {},
   "source": [
    "Scenario: compute revenue and margin columns in a pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdba9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'units': [10, 5, 8],\n",
    "    'price': [20, 30, 15],\n",
    "    'cost': [120, 90, 80],\n",
    "})\n",
    "\n",
    "out = (\n",
    "    df\n",
    "    .assign(revenue=lambda x: x['units'] * x['price'])\n",
    "    .assign(margin=lambda x: x['revenue'] - x['cost'])\n",
    ")\n",
    "\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb9b8c",
   "metadata": {},
   "source": [
    "### DataFrame.astype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7a8ba",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526fa13",
   "metadata": {},
   "source": [
    "`DataFrame.astype` converts one or more columns to target data types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f648a0",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d0659",
   "metadata": {},
   "source": [
    "- `dtype`: single dtype or dict mapping `column -> dtype`.\n",
    "- `copy`: whether to return a new object (behavior can depend on internals/settings).\n",
    "- `errors`: `'raise'` or `'ignore'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4d11c",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610adb09",
   "metadata": {},
   "source": [
    "- You relabel storage boxes so each column is stored in the most suitable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9256c3",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acef9c",
   "metadata": {},
   "source": [
    "- Pandas applies dtype conversion column-wise.\n",
    "- If conversion succeeds, the resulting column uses the new dtype representation.\n",
    "- If conversion fails and `errors='raise'`, pandas throws an exception.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15263a7a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c73424",
   "metadata": {},
   "source": [
    "- Converting dirty strings to numeric/int often fails.\n",
    "- Plain `int64` cannot represent missing values; nullable `Int64` can.\n",
    "- Unexpected timezone or category conversion issues can occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff5216",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3aea4",
   "metadata": {},
   "source": [
    "- Are missing values present in columns you cast to integer?\n",
    "- Should invalid parse values fail fast or be left unchanged?\n",
    "- Is nullable dtype (`Int64`, `string`, `boolean`) more appropriate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312ef1a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87103e15",
   "metadata": {},
   "source": [
    "Use `astype` to enforce stable schema and predictable downstream behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768f03e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9fac4",
   "metadata": {},
   "source": [
    "Scenario: normalize schema after CSV ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'user_id': ['1', '2', '3'],\n",
    "    'active': ['True', 'False', 'True'],\n",
    "})\n",
    "\n",
    "df = df.astype({'user_id': 'Int64', 'active': 'string'})\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e127e20",
   "metadata": {},
   "source": [
    "### DataFrame.convert_dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb32289",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c57ead",
   "metadata": {},
   "source": [
    "`DataFrame.convert_dtypes` upgrades columns to pandas nullable dtypes automatically.\n",
    "It is a safe schema cleanup step after loading mixed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02721306",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefff11",
   "metadata": {},
   "source": [
    "- `infer_objects`: whether to infer better dtypes for object columns.\n",
    "- `convert_string`, `convert_integer`, `convert_boolean`, `convert_floating`: per-family conversion toggles.\n",
    "- `dtype_backend`: backend choice (for example nullable NumPy or pyarrow-backed, depending on version).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d2d37",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebeafb9",
   "metadata": {},
   "source": [
    "- It is like asking pandas to apply a smart \"best available type\" pass over your table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055ceb5",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdead2c",
   "metadata": {},
   "source": [
    "- Pandas inspects values column-by-column.\n",
    "- When possible, object columns are converted to nullable logical dtypes (`string`, `Int64`, `boolean`, etc.).\n",
    "- Missing values are preserved with pandas NA semantics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08462be7",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a397078",
   "metadata": {},
   "source": [
    "- Automatic inference is helpful but not always what business rules need.\n",
    "- You may still need explicit `astype` for strict schemas.\n",
    "- Backend choices can affect memory/performance and interoperability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067b9af",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514bade",
   "metadata": {},
   "source": [
    "- Do you want nullable dtypes consistently across the project?\n",
    "- Is explicit schema enforcement required by downstream systems?\n",
    "- Are you using pyarrow backend in your stack?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30d362",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f47b5",
   "metadata": {},
   "source": [
    "Use `convert_dtypes` as a first cleanup pass, then enforce strict types where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4b6bb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f14fe",
   "metadata": {},
   "source": [
    "Scenario: improve dtypes right after importing messy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.DataFrame({\n",
    "    'age': [21, None, 35],\n",
    "    'name': ['Ana', 'Leo', None],\n",
    "    'flag': [True, None, False],\n",
    "})\n",
    "\n",
    "clean = raw.convert_dtypes()\n",
    "print(clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3190966",
   "metadata": {},
   "source": [
    "### DataFrame.infer_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044bc0f",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154b2e0",
   "metadata": {},
   "source": [
    "`DataFrame.infer_objects` tries to convert `object` columns to better concrete types when possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed1727",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ad0b0",
   "metadata": {},
   "source": [
    "- `copy`: whether to return a copy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6b89d",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474032f",
   "metadata": {},
   "source": [
    "- You ask pandas: \"These generic object boxes, can you recognize and relabel them as specific types?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5b013",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d99fd",
   "metadata": {},
   "source": [
    "- Pandas inspects object columns and attempts soft conversion.\n",
    "- It converts only when inference is safe, otherwise keeps original dtype.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640e20d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da230dae",
   "metadata": {},
   "source": [
    "- It does not aggressively parse everything (less powerful than explicit converters).\n",
    "- Complex mixed-type columns often remain `object`.\n",
    "- Behavior differs from `convert_dtypes`, which targets nullable dtypes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3d82e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0a8c1f",
   "metadata": {},
   "source": [
    "- Are your columns currently `object` because of import issues?\n",
    "- Do you need soft inference or strict explicit casting?\n",
    "- Would `convert_dtypes` be a better first choice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b328e4",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6718ed",
   "metadata": {},
   "source": [
    "Use `infer_objects` for lightweight cleanup of object columns without hard casting rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010867d",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157328d",
   "metadata": {},
   "source": [
    "Scenario: quick dtype improvement after concatenating heterogeneous DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'qty': [1, 2, 3],\n",
    "    'price': [10.0, 20.5, 30.0],\n",
    "}, dtype='object')\n",
    "\n",
    "better = df.infer_objects()\n",
    "print(df.dtypes)\n",
    "print(better.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d90c39",
   "metadata": {},
   "source": [
    "### DataFrame.set_axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fe4b6",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c9fd3",
   "metadata": {},
   "source": [
    "`DataFrame.set_axis` replaces the labels of rows or columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95e479",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef4eeb",
   "metadata": {},
   "source": [
    "- `labels`: new index or column labels.\n",
    "- `axis`: `0/'index'` for rows, `1/'columns'` for columns.\n",
    "- `copy`: whether to return a copy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5d6c4",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779729f7",
   "metadata": {},
   "source": [
    "- Same table, new name tags on rows or columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54385ef3",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44733b4",
   "metadata": {},
   "source": [
    "- Pandas validates the new labels length against the target axis length.\n",
    "- If lengths match, labels are assigned to that axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cf9b8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5564a5",
   "metadata": {},
   "source": [
    "- Label count mismatch raises errors.\n",
    "- Renaming all labels can hide intent compared with `rename` for partial changes.\n",
    "- Duplicate labels may be allowed but can complicate selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3fb691",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8928af",
   "metadata": {},
   "source": [
    "- Are you renaming all labels or only a subset?\n",
    "- Does `labels` length exactly match axis length?\n",
    "- Do duplicate labels create ambiguity later?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811cb972",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7823d0",
   "metadata": {},
   "source": [
    "Use `set_axis` when you want to replace an entire row/column label set at once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a76a692",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4715139",
   "metadata": {},
   "source": [
    "Scenario: assign canonical column names after reading raw file headers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384aa21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[1, 'US'], [2, 'IT']])\n",
    "df = df.set_axis(['customer_id', 'country'], axis='columns')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac2624",
   "metadata": {},
   "source": [
    "### DataFrame.set_flags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d4cc0",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f2252",
   "metadata": {},
   "source": [
    "`DataFrame.set_flags` returns a new DataFrame with updated internal flags metadata.\n",
    "A common use is controlling duplicate-label policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9613a9",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92352f13",
   "metadata": {},
   "source": [
    "- `copy`: whether to return a copy.\n",
    "- `allows_duplicate_labels`: set to `True` or `False` to control duplicate label allowance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4714ef",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b135124",
   "metadata": {},
   "source": [
    "- You keep the same table but change safety rules attached to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca94dd",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19df4f0",
   "metadata": {},
   "source": [
    "- Flags are metadata on the DataFrame object.\n",
    "- When duplicate labels are disallowed, operations creating duplicates can raise errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aceebdf",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd95af",
   "metadata": {},
   "source": [
    "- It does not clean existing data issues by itself.\n",
    "- If duplicates already exist, stricter flags may raise immediately.\n",
    "- Team members may be unfamiliar with this API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d357fd5",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c29a1d",
   "metadata": {},
   "source": [
    "- Do you want to enforce label uniqueness as a data quality guardrail?\n",
    "- Could upstream operations generate duplicate columns/index labels?\n",
    "- Will stricter policy break existing workflows?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170bf44",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0406b88",
   "metadata": {},
   "source": [
    "Use `set_flags` to encode DataFrame-level safety constraints, especially around duplicate labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd1ef7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3189c27",
   "metadata": {},
   "source": [
    "Scenario: enforce no duplicate labels in a critical transformation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df = df.set_flags(allows_duplicate_labels=False)\n",
    "\n",
    "print(df.flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc66b7",
   "metadata": {},
   "source": [
    "### DataFrame.add_prefix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3514cb9",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344b950",
   "metadata": {},
   "source": [
    "`DataFrame.add_prefix` prepends a string to every column label (or index label for some objects).\n",
    "For DataFrame, this is commonly used to namespace columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae2740",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbe5f8",
   "metadata": {},
   "source": [
    "- `prefix`: string added before each label.\n",
    "- `axis`: available in newer pandas versions to choose target axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad960992",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c8ca2",
   "metadata": {},
   "source": [
    "- You add a department code before every field name, like `sales_` or `raw_`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b33a3",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb26b5",
   "metadata": {},
   "source": [
    "- Pandas maps each label to `prefix + label` on the selected axis.\n",
    "- Data values remain unchanged; only labels are transformed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5179cfd",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b91592",
   "metadata": {},
   "source": [
    "- Repeated runs can create double prefixes.\n",
    "- Very long labels can hurt readability.\n",
    "- Prefixing may break code expecting old column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf908d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d1025",
   "metadata": {},
   "source": [
    "- Are you namespacing columns before merge/join?\n",
    "- Could this be applied multiple times accidentally?\n",
    "- Do downstream consumers rely on exact old names?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392b0f6",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a0547",
   "metadata": {},
   "source": [
    "Use `add_prefix` to quickly namespace labels and avoid naming collisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b732df",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65114fb9",
   "metadata": {},
   "source": [
    "Scenario: distinguish features from two sources before merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'id': [1, 2], 'score': [80, 90]})\n",
    "features = left[['score']].add_prefix('model_a_')\n",
    "\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4dd01",
   "metadata": {},
   "source": [
    "### DataFrame.add_suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c099c0f",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfde5f",
   "metadata": {},
   "source": [
    "`DataFrame.add_suffix` appends a string to every column label.\n",
    "It is useful when creating versioned or source-specific column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd4b22",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40421dac",
   "metadata": {},
   "source": [
    "- `suffix`: string added after each label.\n",
    "- `axis`: available in newer pandas versions to choose target axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53657673",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5f4d1",
   "metadata": {},
   "source": [
    "- You tag each field with a version stamp, like `_2026`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719b2f0",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8769340",
   "metadata": {},
   "source": [
    "- Pandas maps each label to `label + suffix` on the selected axis.\n",
    "- Data itself is untouched.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c281b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6e536",
   "metadata": {},
   "source": [
    "- Repeated use can create noisy labels.\n",
    "- Suffix changes can break hardcoded column references.\n",
    "- Label collisions are still possible if naming strategy is weak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b0f31",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f5b38",
   "metadata": {},
   "source": [
    "- Are you tracking period/source in column names?\n",
    "- Could multiple transformations append duplicate suffixes?\n",
    "- Is there a schema contract that forbids renamed columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7e553",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3a3af",
   "metadata": {},
   "source": [
    "Use `add_suffix` to label columns systematically without changing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982cf38",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41514482",
   "metadata": {},
   "source": [
    "Scenario: add snapshot suffix before combining monthly datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'revenue': [100, 120], 'cost': [70, 85]})\n",
    "snap = df.add_suffix('_jan')\n",
    "\n",
    "print(snap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be6bf2",
   "metadata": {},
   "source": [
    "## Structural Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Begin with introspection (`info`, `memory_usage`), then label access (`keys`, `items`).\n",
    "- Use `select_dtypes` and `squeeze` to prepare shape/type-aware pipelines.\n",
    "- Goal: understand table structure before transforming it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783cf29",
   "metadata": {},
   "source": [
    "### DataFrame.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d81b1",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1159aab",
   "metadata": {},
   "source": [
    "`DataFrame.info` prints a compact technical summary of a DataFrame: shape, columns, dtypes, non-null counts, and memory usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f5809",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2006fba",
   "metadata": {},
   "source": [
    "- `verbose`: include full column-level output.\n",
    "- `buf`: output buffer destination.\n",
    "- `max_cols`: threshold for truncating columns in output.\n",
    "- `memory_usage`: include memory information.\n",
    "- `show_counts`: explicitly show non-null counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e5757",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4046ada",
   "metadata": {},
   "source": [
    "- It is a quick health-check report before you start analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccced74",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3b3d6",
   "metadata": {},
   "source": [
    "- Pandas inspects index and each column metadata.\n",
    "- It computes non-null counts and dtype summary.\n",
    "- It prints to stdout (or custom buffer), not returning a transformed DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db249f8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9bcb2",
   "metadata": {},
   "source": [
    "- `info()` is for diagnostics; it does not return structured data for pipelines.\n",
    "- Memory reporting is approximate in some object-heavy cases.\n",
    "- Large wide tables may need `max_cols` tuning for readable output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbc489",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91201c",
   "metadata": {},
   "source": [
    "- Do you need a human-readable summary or machine-readable stats?\n",
    "- Is missingness concentrated in specific columns?\n",
    "- Are dtypes aligned with downstream operations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c531cb8",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3b3fd",
   "metadata": {},
   "source": [
    "Use `info()` as your first schema and quality sanity check right after loading data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f64fd2",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b2bf0",
   "metadata": {},
   "source": [
    "Scenario: inspect a newly loaded dataset before cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'email': ['a@x.com', None, 'c@x.com'],\n",
    "    'signup_ts': ['2026-01-01', '2026-01-02', '2026-01-03'],\n",
    "})\n",
    "\n",
    "df.info(show_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26898a",
   "metadata": {},
   "source": [
    "### DataFrame.memory_usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966328e",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582df9b",
   "metadata": {},
   "source": [
    "`DataFrame.memory_usage` reports memory consumed by index and columns.\n",
    "It helps you understand RAM footprint and optimize large workloads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1137af0",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd0a76",
   "metadata": {},
   "source": [
    "- `index`: include index memory if `True`.\n",
    "- `deep`: deep introspection for `object` dtype memory estimation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d185b",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8a34a",
   "metadata": {},
   "source": [
    "- Think of it as a per-column storage bill in bytes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cb685",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5127d9f",
   "metadata": {},
   "source": [
    "- Pandas sums underlying array/block memory per column.\n",
    "- With `deep=True`, object elements are inspected more deeply to estimate real Python-object overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58f935",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8ebf5",
   "metadata": {},
   "source": [
    "- `deep=True` can be slower on large object columns.\n",
    "- Estimates are not always exact for all backends and internals.\n",
    "- Ignoring index memory can underestimate total footprint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0385cd",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef19fa",
   "metadata": {},
   "source": [
    "- Which columns dominate memory usage?\n",
    "- Are object/string columns the bottleneck?\n",
    "- Do you need deep estimates or fast approximate checks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa1e1f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f48ca8",
   "metadata": {},
   "source": [
    "Use `memory_usage` to identify expensive columns before optimization (dtype conversion, categoricals, pruning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f4032",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8308bd",
   "metadata": {},
   "source": [
    "Scenario: find memory-heavy columns in a medium-size table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'country': ['US', 'IT', 'US', 'DE'],\n",
    "    'revenue': [100.0, 120.0, 90.0, 110.0],\n",
    "})\n",
    "\n",
    "print(df.memory_usage(index=True, deep=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a689f6",
   "metadata": {},
   "source": [
    "### DataFrame.keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86a364",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b56315",
   "metadata": {},
   "source": [
    "`DataFrame.keys` returns the DataFrame column labels.\n",
    "For DataFrame, it is effectively an alias of `df.columns`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062dee9",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519295a1",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549abfb9",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38319dd1",
   "metadata": {},
   "source": [
    "- If each column is a drawer, `keys()` gives you the drawer names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc288af",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64c778",
   "metadata": {},
   "source": [
    "- Pandas returns the column `Index` object.\n",
    "- No data values are scanned; this is metadata access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c045e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8129b",
   "metadata": {},
   "source": [
    "- It does not include row index labels.\n",
    "- Duplicate column names are returned as-is and can create ambiguity later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878055f2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efd9dc",
   "metadata": {},
   "source": [
    "- Do you need only column labels, or full schema details with dtypes?\n",
    "- Are duplicate column labels possible in your pipeline?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9e163",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe51c1",
   "metadata": {},
   "source": [
    "Use `keys()` when you just need the list-like object of column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567764d3",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246b547",
   "metadata": {},
   "source": [
    "Scenario: validate required columns before processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8618f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'amount': [10, 20]})\n",
    "required = {'id', 'amount'}\n",
    "\n",
    "if required.issubset(set(df.keys())):\n",
    "    print('schema ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3738e88",
   "metadata": {},
   "source": [
    "### DataFrame.items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0718d",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f4ba6",
   "metadata": {},
   "source": [
    "`DataFrame.items` iterates over `(column_name, Series)` pairs.\n",
    "It is useful when applying custom logic column-by-column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532ceeb",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce7c17",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb286c",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee57522",
   "metadata": {},
   "source": [
    "- You walk through a folder where each file is one column: name plus its values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5499a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0438c32",
   "metadata": {},
   "source": [
    "- Pandas yields one tuple per column.\n",
    "- Each yielded object is a Series aligned to the DataFrame index.\n",
    "- Iteration is lazy: items are produced on demand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c48e8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf059a",
   "metadata": {},
   "source": [
    "- Python-level loops can be slow for large transformations.\n",
    "- In-place edits inside loops can be error-prone.\n",
    "- Vectorized operations are usually faster and clearer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d08aaf",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d683afd",
   "metadata": {},
   "source": [
    "- Is per-column custom logic really needed?\n",
    "- Could the task be expressed vectorially?\n",
    "- Are you accidentally mutating views/copies in a loop?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9eb1d",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377940eb",
   "metadata": {},
   "source": [
    "Use `items()` when you need explicit per-column iteration with both name and Series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b43e5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac71b23",
   "metadata": {},
   "source": [
    "Scenario: report null ratio for each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284793a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, None, 3],\n",
    "    'b': [None, None, 2],\n",
    "})\n",
    "\n",
    "for col, s in df.items():\n",
    "    print(col, s.isna().mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c044c09",
   "metadata": {},
   "source": [
    "### DataFrame.select_dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c46c1",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63ce9a",
   "metadata": {},
   "source": [
    "`DataFrame.select_dtypes` filters columns by dtype include/exclude rules.\n",
    "It is essential for schema-aware pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc170447",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910b1b0",
   "metadata": {},
   "source": [
    "- `include`: dtype or list of dtypes to keep.\n",
    "- `exclude`: dtype or list of dtypes to remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b98be",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434dfcc",
   "metadata": {},
   "source": [
    "- You apply a sieve to keep only numeric, datetime, or other chosen column families.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12d79d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffed5d1",
   "metadata": {},
   "source": [
    "- Pandas evaluates each column dtype against include/exclude criteria.\n",
    "- Columns that pass rules are returned in a new DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84814392",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e060525",
   "metadata": {},
   "source": [
    "- String dtype handling can vary if data is `object` vs pandas `string`.\n",
    "- Overlapping include/exclude logic can raise errors.\n",
    "- Nullable dtypes may need explicit matching in older codebases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1601921",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48496ac2",
   "metadata": {},
   "source": [
    "- Are text fields true `string` dtype or generic `object`?\n",
    "- Do your include/exclude sets overlap?\n",
    "- Is dtype normalization needed before selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61535242",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06425e05",
   "metadata": {},
   "source": [
    "Use `select_dtypes` to select schema subsets reliably without hardcoding column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53c1c0",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905619d",
   "metadata": {},
   "source": [
    "Scenario: compute stats only on numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf31da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'city': ['NY', 'Rome', 'Berlin'],\n",
    "    'sales': [100, 120, 90],\n",
    "    'margin': [0.30, 0.25, 0.35],\n",
    "})\n",
    "\n",
    "num = df.select_dtypes(include='number')\n",
    "print(num.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d658435",
   "metadata": {},
   "source": [
    "### DataFrame.squeeze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab9f4c",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301aed20",
   "metadata": {},
   "source": [
    "`DataFrame.squeeze` reduces dimensionality when possible.\n",
    "A single-column DataFrame can become a Series; a 1x1 DataFrame can become a scalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53243c1d",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393c7a1",
   "metadata": {},
   "source": [
    "- `axis`: optional axis to squeeze (`'index'` or `'columns'`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebae56",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ce090",
   "metadata": {},
   "source": [
    "- You compress packaging when there is only one item dimension left.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3a0b2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbe554",
   "metadata": {},
   "source": [
    "- Pandas checks shape constraints.\n",
    "- If exactly one column (or one row on chosen axis), it returns a lower-dimensional object.\n",
    "- Otherwise it returns the original DataFrame shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b4bf2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febd52c",
   "metadata": {},
   "source": [
    "- Return type is shape-dependent, so downstream typing can be unstable.\n",
    "- In pipelines, implicit type changes can break expectations.\n",
    "- Explicit indexing is often clearer when stable type is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad8735",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a16d90",
   "metadata": {},
   "source": [
    "- Do you require a predictable return type?\n",
    "- Can shape vary between runs (e.g., filters)?\n",
    "- Is this for convenience or strict API contract?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc353ac",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f7016",
   "metadata": {},
   "source": [
    "Use `squeeze` when you intentionally want automatic reduction from DataFrame to Series/scalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afb761",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a49883",
   "metadata": {},
   "source": [
    "Scenario: extract a scalar from a 1x1 result table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame({'total': [420]})\n",
    "value = summary.squeeze()\n",
    "print(value)\n",
    "print(type(value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23a094",
   "metadata": {},
   "source": [
    "## Selection and Access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Learn basic slicing first (`head`, `tail`, `sample`, `take`).\n",
    "- Then move to label/time-aware access (`xs`, `get`, `filter`, `at_time`, `between_time`).\n",
    "- End with iteration methods only for edge cases (`iterrows`, `itertuples`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.head` returns the first *n* rows. It is the quickest way to inspect structure and values after loading or transforming data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n`: number of rows to return (default `5`).\n",
    "- If `n` is negative, it returns all rows except the last `|n|` rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like reading the first lines of a report to check whether the format looks correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs a position-based slice from the top of the row axis.\n",
    "- Column structure and original index labels are preserved.\n",
    "- A new DataFrame object is returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `head()` is not random; it can hide issues present later in the dataset.\n",
    "- With sorted data, first rows may be biased and not representative.\n",
    "- Negative `n` behavior is often forgotten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need a quick preview or a representative sample?\n",
    "- Are the first rows potentially biased by sort order?\n",
    "- Are column names and dtypes what you expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `head()` for fast structural sanity checks, not statistical representativeness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: verify schema and first records right after ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'order_id': [1001, 1002, 1003, 1004, 1005, 1006],\n",
    "    'country': ['US', 'IT', 'US', 'DE', 'FR', 'ES'],\n",
    "    'amount': [120, 80, 210, 95, 60, 140],\n",
    "})\n",
    "\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.tail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.tail` returns the last *n* rows. It is useful to inspect recent records or the bottom of sorted outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n`: number of rows to return (default `5`).\n",
    "- If `n` is negative, it returns all rows except the first `|n|` rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like checking the final lines of a log file to see the latest events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas slices the row axis from the end by position.\n",
    "- Index and columns are preserved exactly.\n",
    "- Result is a DataFrame with the selected trailing rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tail()` is still positional, not based on timestamps unless data is already sorted.\n",
    "- If the DataFrame is unsorted, last rows may not mean latest business records.\n",
    "- Negative `n` can surprise readers of your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is your DataFrame sorted in the order you intend to inspect?\n",
    "- Do you need last rows by position or by time condition?\n",
    "- Could filtering be clearer than relying on row order?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tail()` to inspect the end of the current row order quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inspect the most recent rows after sorting by event timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'event': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
    "    'ts': pd.date_range('2026-02-17 09:00', periods=6, freq='h')\n",
    "}).sort_values('ts')\n",
    "\n",
    "print(df.tail(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sample` returns random rows (or columns) for exploratory checks, quick tests, and stochastic workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n`: exact number of items to sample.\n",
    "- `frac`: fraction of axis items to sample.\n",
    "- `replace`: sample with replacement if `True`.\n",
    "- `weights`: sampling probabilities.\n",
    "- `random_state`: seed for reproducible sampling.\n",
    "- `axis`: `0` rows (default) or `1` columns.\n",
    "- `ignore_index`: reset index in the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like pulling random cards from a deck to inspect typical patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects positions using random sampling logic.\n",
    "- `n` and `frac` control sample size; weights can skew probability.\n",
    "- `random_state` fixes pseudo-random sequence for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do not set both `n` and `frac` together.\n",
    "- Weighted sampling requires valid non-negative weights aligned to axis.\n",
    "- Without `random_state`, results vary between runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need reproducibility for debugging/tests?\n",
    "- Should sampling be uniform or weighted?\n",
    "- Is replacement acceptable for your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sample()` for representative spot-checking, and set `random_state` when determinism matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: pull a reproducible random subset for manual QA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, 11),\n",
    "    'score': [51, 62, 75, 80, 68, 91, 73, 84, 59, 77]\n",
    "})\n",
    "\n",
    "print(df.sample(n=3, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.take\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.take` selects rows or columns by explicit integer positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `indices`: sequence of positional indices to extract.\n",
    "- `axis`: `0` for rows (default), `1` for columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You hand pandas a list of seat numbers and ask for exactly those seats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs low-level positional selection on the specified axis.\n",
    "- Order and duplicates in `indices` are preserved in output.\n",
    "- The result keeps original labels for selected elements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out-of-bounds indices raise errors.\n",
    "- `take` is strictly positional, unlike label-based selection.\n",
    "- Readability can be lower than `iloc` for simple slices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are your positions guaranteed valid at runtime?\n",
    "- Would `iloc` slicing be clearer for maintainers?\n",
    "- Do you intentionally preserve duplicate positional picks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `take()` when you already have exact integer positions to extract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep rows selected by an upstream ranking process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'value': [10, 20, 30, 40, 50]\n",
    "})\n",
    "\n",
    "top_positions = [4, 2, 2, 0]\n",
    "print(df.take(top_positions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.xs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.xs` (cross-section) extracts data at a particular key from a MultiIndex (rows or columns).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `key`: label to select at target level.\n",
    "- `axis`: `0` index (default) or `1` columns.\n",
    "- `level`: level name/position in MultiIndex.\n",
    "- `drop_level`: remove selected level from result if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like slicing one floor out of a multi-floor building organized by levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas resolves the key within the chosen MultiIndex level.\n",
    "- It filters matching labels and returns the corresponding cross-section.\n",
    "- With `drop_level=True`, selected level is removed from resulting index structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Works best with MultiIndex; single-level use is often unnecessary.\n",
    "- Wrong level/key combinations can raise `KeyError`.\n",
    "- Level dropping can surprise downstream code expecting full index depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is your target axis actually MultiIndex?\n",
    "- Should selected level remain (`drop_level=False`) for later joins?\n",
    "- Are key names and level names unambiguous?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `xs()` for clean cross-sections on MultiIndex data without complex manual indexing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: extract all metrics for one region from hierarchical index data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.MultiIndex.from_product([['EU', 'US'], ['A', 'B']], names=['region', 'store'])\n",
    "df = pd.DataFrame({'sales': [10, 12, 20, 22]}, index=idx)\n",
    "\n",
    "print(df.xs('EU', level='region'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.get\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.get` retrieves a column (or set of columns) safely, returning a default value instead of raising `KeyError` when missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `key`: column label or list-like of labels.\n",
    "- `default`: value returned if key is not present (default `None`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking a dictionary for a key with a fallback value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas checks whether the key exists among columns.\n",
    "- If found, it returns normal column selection output.\n",
    "- If not found, it returns `default` directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing keys silently return defaults, which can hide schema problems.\n",
    "- Return type varies: Series for one column, DataFrame for multiple columns.\n",
    "- Defaults should be type-compatible with downstream logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you want fail-fast behavior (`[]`) or safe fallback (`get`)?\n",
    "- Is your fallback value explicit enough for debugging?\n",
    "- Are you handling both Series and DataFrame return types?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get()` when optional columns are expected and fallback handling is intentional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: handle optional enrichment columns gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'amount': [100, 120]})\n",
    "\n",
    "print(df.get('amount'))\n",
    "print(df.get('currency', 'USD'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.filter` subsets rows/columns by label rules (`items`, `like`, `regex`) along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `items`: keep exact labels in this list.\n",
    "- `like`: keep labels containing this substring.\n",
    "- `regex`: keep labels matching this regex pattern.\n",
    "- `axis`: target axis (`0/'index'` or `1/'columns'`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like filtering file names by exact list, keyword, or pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas evaluates label strings on the chosen axis.\n",
    "- It returns only labels that satisfy the selected criterion.\n",
    "- Data values are untouched; only label-based inclusion changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It filters by labels, not by cell values.\n",
    "- Regex patterns can unintentionally match more labels than expected.\n",
    "- Ambiguous axis choice can yield surprising outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you filtering by labels or by values?\n",
    "- Would exact `items` be safer than a broad regex?\n",
    "- Did you set `axis` to the intended dimension?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `filter()` for label-pattern selection when column/index names follow conventions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: select all KPI columns prefixed with `sales_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sales_q1': [100, 120],\n",
    "    'sales_q2': [110, 130],\n",
    "    'cost_q1': [70, 80],\n",
    "})\n",
    "\n",
    "print(df.filter(regex=r'^sales_', axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.at_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.at_time` selects rows at a specific time-of-day from a `DatetimeIndex`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `time`: target time (string or `datetime.time`).\n",
    "- `asof`: include nearest previous time if exact match is absent (behavior/version dependent).\n",
    "- `axis`: axis containing `DatetimeIndex` (usually index).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like pulling all records logged exactly at 09:00 across different dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas extracts time component from datetime labels.\n",
    "- It compares against the requested clock time and returns matching rows.\n",
    "- Date component is ignored for matching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires a `DatetimeIndex` on the selected axis.\n",
    "- Timezones can change which rows match expected clock times.\n",
    "- Unsorted or irregular timestamps can complicate interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is your index truly datetime-typed?\n",
    "- Do timezone conversions need to happen first?\n",
    "- Do you want exact time matches or ranges (`between_time`)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `at_time()` for exact time-of-day slices across many dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: extract daily 09:00 operational snapshots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-02-15 08:00', periods=8, freq='12h')\n",
    "df = pd.DataFrame({'load': [10, 20, 11, 19, 12, 18, 13, 17]}, index=idx)\n",
    "\n",
    "print(df.at_time('08:00'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.between_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.between_time` selects rows whose time-of-day falls inside a specified interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `start_time`: interval start time.\n",
    "- `end_time`: interval end time.\n",
    "- `inclusive`: boundary inclusion (`'both'`, `'left'`, `'right'`, `'neither'`).\n",
    "- `axis`: axis containing the `DatetimeIndex`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like keeping only transactions occurring during business hours each day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas compares each datetime label's clock time to interval bounds.\n",
    "- Rows in range are returned, preserving original date and ordering.\n",
    "- If start > end, interval wraps around midnight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires datetime-like index on target axis.\n",
    "- Boundary handling depends on `inclusive` and pandas version.\n",
    "- Cross-midnight logic can be misunderstood if undocumented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need a normal interval or a wrap-around one (night window)?\n",
    "- Should boundaries be included or excluded?\n",
    "- Is timezone normalization needed before filtering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `between_time()` to slice recurring intraday windows across dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep rows between 09:00 and 17:00 for daily business-hour analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-02-16 06:00', periods=16, freq='h')\n",
    "df = pd.DataFrame({'traffic': range(16)}, index=idx)\n",
    "\n",
    "print(df.between_time('09:00', '17:00'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.iterrows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.iterrows` iterates over rows as `(index, Series)` pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like reading a table row by row with each row presented as a mini labeled record.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas yields one row at a time as a Series with column labels.\n",
    "- Each row object is created during iteration (Python-level loop).\n",
    "- Original column dtypes are not strictly preserved per yielded row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slow for large DataFrames compared with vectorized operations.\n",
    "- Row Series can coerce values to common dtype (often object/float).\n",
    "- In-loop assignments to the row object do not reliably write back.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can this be vectorized or done with `apply`/group operations instead?\n",
    "- Do you depend on exact dtypes while iterating?\n",
    "- Is iteration volume small enough to justify row-wise Python loops?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `iterrows()` only for small, logic-heavy row inspections where vectorization is impractical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: create custom alert messages for a small exception table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'service': ['api', 'db', 'cache'],\n",
    "    'latency_ms': [120, 380, 95]\n",
    "})\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row['latency_ms'] > 200:\n",
    "        print(f\"ALERT row={idx}: {row['service']} latency={row['latency_ms']}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.itertuples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.itertuples` iterates over rows as lightweight tuples (or namedtuples), usually faster than `iterrows`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `index`: include index in tuples if `True` (default).\n",
    "- `name`: namedtuple class name; use `None` for regular tuples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like streaming compact row packets instead of full row objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas constructs tuple-like row representations with positional access.\n",
    "- Namedtuples expose attribute access for valid field names.\n",
    "- Lower overhead than per-row Series creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Still Python-loop based and slower than vectorized operations.\n",
    "- Column names may be sanitized in namedtuple fields if invalid identifiers.\n",
    "- Tuple immutability means no in-place row mutation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need row iteration at all, or can this be vectorized?\n",
    "- Would plain tuples (`name=None`) be enough for speed and simplicity?\n",
    "- Are your column names safe for attribute access?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `itertuples()` for row iteration when performance matters more than row mutability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: export selected row fields to an external API payload list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'status': ['ok', 'fail', 'ok']\n",
    "})\n",
    "\n",
    "for row in df.itertuples(index=False, name='Event'):\n",
    "    print({'id': row.id, 'status': row.status})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff6782",
   "metadata": {},
   "source": [
    "## Structure Manipulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Start with column/index management (`insert`, `drop`, `set_index`, `reset_index`, `rename`).\n",
    "- Continue with reshape operations (`explode`, `melt`, `stack`, `unstack`, `transpose`).\n",
    "- Goal: control schema evolution intentionally and avoid accidental shape drift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.insert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.insert` adds a new column at a specific position, instead of appending it at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loc`: integer position where the new column is inserted.\n",
    "- `column`: new column label.\n",
    "- `value`: scalar, array-like, or Series used as column values.\n",
    "- `allow_duplicates`: allow duplicate column labels if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like inserting a new chapter in the middle of a book, not only at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas validates target position and aligns `value` to row index when needed.\n",
    "- Column metadata is shifted right from `loc` onward.\n",
    "- This mutates the DataFrame in place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loc` out of bounds raises an error.\n",
    "- By default, duplicate column names are not allowed.\n",
    "- For chained pipelines, `assign` is often cleaner than in-place `insert`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need a precise column order requirement?\n",
    "- Could duplicate names break downstream selections?\n",
    "- Is in-place mutation acceptable in your pipeline?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `insert()` when column order matters and you need explicit positional control.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: add an ID column as the first column before export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'name': ['Ana', 'Leo'], 'score': [88, 92]})\n",
    "df.insert(loc=0, column='student_id', value=[1001, 1002])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pop` removes one column and returns it as a Series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `item`: column label to remove and return.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like pulling one file out of a folder: it is returned to you and removed from the folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas locates the target column by label.\n",
    "- It returns the column as a Series.\n",
    "- The original DataFrame is mutated (column removed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing column label raises `KeyError`.\n",
    "- It is in-place mutation, so other references to the DataFrame observe the change.\n",
    "- Only one column can be popped per call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need the removed column for later processing?\n",
    "- Should removal be fail-fast on missing labels?\n",
    "- Would `drop(columns=...)` be clearer for multiple columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pop()` when you want to move one column out of a DataFrame and keep it as Series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: extract target variable and keep only feature columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x1': [1, 2, 3], 'x2': [4, 5, 6], 'target': [0, 1, 0]})\n",
    "y = df.pop('target')\n",
    "\n",
    "print('features:')\n",
    "print(df)\n",
    "print('target:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.drop` removes specified rows or columns by label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `labels`: label(s) to drop.\n",
    "- `axis`: `0/'index'` for rows, `1/'columns'` for columns.\n",
    "- `index` / `columns`: explicit alternatives to `labels` + `axis`.\n",
    "- `level`: MultiIndex level to apply label matching.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `errors`: `'raise'` or `'ignore'` for missing labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like crossing out specific rows/fields from a report by name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas resolves labels on the target axis.\n",
    "- Matched labels are excluded and a new DataFrame is returned (unless `inplace=True`).\n",
    "- Index/column order of remaining data is preserved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Axis confusion (`rows` vs `columns`) is a common source of bugs.\n",
    "- Missing labels raise errors unless `errors='ignore'`.\n",
    "- `inplace=True` can make pipeline debugging harder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you dropping by row labels or column labels?\n",
    "- Should missing labels fail fast?\n",
    "- Do you need immutable pipeline style instead of in-place edits?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `drop()` for explicit label-based removal of rows/columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: remove helper columns before sending data to BI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2],\n",
    "    'revenue': [100, 120],\n",
    "    'tmp_flag': [True, False]\n",
    "})\n",
    "\n",
    "clean = df.drop(columns=['tmp_flag'])\n",
    "print(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.drop_duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.drop_duplicates` removes duplicate rows based on all columns or a subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `subset`: column(s) used to detect duplicates.\n",
    "- `keep`: `'first'`, `'last'`, or `False` to drop all duplicates.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `ignore_index`: reset index in result if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like removing repeated customer forms and keeping only the first accepted submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes duplicate keys row-wise using selected columns.\n",
    "- Rows marked as duplicates are excluded according to `keep` policy.\n",
    "- Result preserves original order of retained rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `subset` is missing, full-row comparison might not match business identity rules.\n",
    "- `keep='first'` depends on current row order.\n",
    "- Null handling in key columns may need business-specific interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What defines uniqueness in your domain (which columns)?\n",
    "- Is row order deterministic before deduplication?\n",
    "- Do you want to keep one duplicate or remove all duplicates?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `drop_duplicates()` to enforce row-level uniqueness with explicit key columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep one transaction per `(user_id, order_id)` pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'user_id': [1, 1, 2, 2],\n",
    "    'order_id': [10, 10, 20, 21],\n",
    "    'amount': [50, 50, 80, 90]\n",
    "})\n",
    "\n",
    "dedup = df.drop_duplicates(subset=['user_id', 'order_id'], keep='first')\n",
    "print(dedup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.duplicated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.duplicated` returns a boolean Series marking whether each row is a duplicate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `subset`: column(s) used for duplicate detection.\n",
    "- `keep`: `'first'`, `'last'`, or `False` to mark all duplicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like highlighting repeated records without deleting anything yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas compares row keys (full row or subset) against previously seen keys.\n",
    "- It emits `True`/`False` flags per row according to `keep` strategy.\n",
    "- You can then filter, audit, or count duplicates explicitly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flag meaning changes with `keep` value.\n",
    "- Subset choice strongly impacts detected duplicates.\n",
    "- People often forget that the first occurrence is usually `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need duplicate diagnostics before dropping rows?\n",
    "- Which columns define duplicate identity?\n",
    "- Should all duplicate occurrences be flagged?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `duplicated()` when you want visibility into duplicates before removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: audit duplicate orders before deciding dedup policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'order_id': [101, 101, 102, 103, 103],\n",
    "    'customer': ['A', 'A', 'B', 'C', 'C']\n",
    "})\n",
    "\n",
    "mask = df.duplicated(subset=['order_id'], keep=False)\n",
    "print(df[mask])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.droplevel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.droplevel` removes one or more levels from a MultiIndex (rows or columns).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `level`: level name or position to remove.\n",
    "- `axis`: `0/'index'` (default) or `1/'columns'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like simplifying a two-level folder path by removing one folder layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas reconstructs the target MultiIndex without the specified level(s).\n",
    "- Underlying values are unchanged.\n",
    "- Result has simpler index/column hierarchy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only applies meaningfully when axis has MultiIndex.\n",
    "- Dropping too many levels can collapse needed context.\n",
    "- Duplicate labels may appear after level removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which hierarchy level is no longer needed?\n",
    "- Will downstream joins still have enough key context?\n",
    "- Could level removal create ambiguous labels?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `droplevel()` to flatten hierarchical labels when one level is redundant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: remove top category level from MultiIndex columns for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = pd.MultiIndex.from_tuples([('sales', 'q1'), ('sales', 'q2')])\n",
    "df = pd.DataFrame([[100, 120], [90, 110]], columns=cols)\n",
    "\n",
    "flat = df.droplevel(0, axis=1)\n",
    "print(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.set_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.set_index` moves one or more columns into the row index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `keys`: column label(s) or array-like used as new index.\n",
    "- `drop`: remove index columns from data if `True`.\n",
    "- `append`: append to existing index if `True`.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `verify_integrity`: check index uniqueness and raise on duplicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like promoting a regular column to become the row identifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas builds a new Index/MultiIndex from selected keys.\n",
    "- Rows are relabeled with these keys.\n",
    "- Depending on `drop`, source columns remain or are removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duplicate index labels can break assumptions in joins/resampling.\n",
    "- Losing key columns with `drop=True` may hurt readability.\n",
    "- `inplace=True` can obscure lineage in notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does your new index need to be unique?\n",
    "- Should key columns remain visible after indexing?\n",
    "- Is MultiIndex necessary or over-complicating the table?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `set_index()` when row labels should carry business keys or time keys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: index by timestamp for time-based slicing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ts': pd.date_range('2026-02-17', periods=3, freq='D'),\n",
    "    'value': [10, 12, 11]\n",
    "})\n",
    "\n",
    "ts_df = df.set_index('ts')\n",
    "print(ts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.reset_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.reset_index` moves index levels back into columns and restores a default integer index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `level`: specific index level(s) to reset.\n",
    "- `drop`: if `True`, discard index instead of adding it as columns.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `col_level` / `col_fill`: placement behavior for MultiIndex columns.\n",
    "- `names`: custom names for inserted index columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like demoting an identifier from row labels back into normal table columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas extracts selected index levels.\n",
    "- Extracted labels are inserted as columns unless `drop=True`.\n",
    "- A RangeIndex (or partially reset index) is produced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can create extra columns named `index` if you reset repeatedly.\n",
    "- MultiIndex reset may alter column hierarchy complexity.\n",
    "- Type expectations can change after reset in downstream code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need index labels as data columns or should they be discarded?\n",
    "- Are you resetting all levels or only part of a MultiIndex?\n",
    "- Will repeated resets clutter schema with helper columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reset_index()` to return from index-centric layout to column-centric tabular layout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: flatten indexed aggregation output before exporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'city': ['NY', 'Rome'], 'sales': [100, 120]}).set_index('city')\n",
    "flat = df.reset_index()\n",
    "\n",
    "print(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.reindex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.reindex` conforms rows/columns to a new label set, adding missing labels and reordering existing ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `labels`, `index`, `columns`: target labels for axes.\n",
    "- `axis`: axis used with `labels`.\n",
    "- `method`: fill method (`ffill`, `bfill`) for monotonic indexes.\n",
    "- `fill_value`: value for newly introduced missing entries.\n",
    "- `limit`, `tolerance`: controls for filling behavior.\n",
    "- `copy`: force copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like forcing your table into a template layout, even if some slots are missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns existing labels to target labels.\n",
    "- New labels are inserted with missing values (or `fill_value`).\n",
    "- Missing old labels are dropped from result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduced labels create `NaN` unless you fill them.\n",
    "- Filling with `method` requires sorted/monotonic context.\n",
    "- `reindex` is label-based, not positional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are your target labels complete and intentional?\n",
    "- Should new gaps become `NaN` or a specific fill value?\n",
    "- Is label-based alignment what you need, not `iloc` slicing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reindex()` to align DataFrame shape and label order to a required template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: align monthly report columns to a fixed standard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'B': [2, 3], 'A': [1, 4]}, index=['x', 'y'])\n",
    "aligned = df.reindex(index=['x', 'y', 'z'], columns=['A', 'B', 'C'], fill_value=0)\n",
    "\n",
    "print(aligned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.reindex_like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.reindex_like` reindexes a DataFrame to match another object's index and columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: reference object providing target index/columns.\n",
    "- `method`, `copy`, `limit`, `tolerance`, `fill_value`: behavior similar to `reindex`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like resizing one spreadsheet to mirror another spreadsheet's exact row/column layout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas reads row/column labels from `other`.\n",
    "- Current DataFrame is conformed to that schema.\n",
    "- Missing entries are introduced as `NaN` or configured fill values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may unintentionally lose labels not present in `other`.\n",
    "- Mismatched dtypes can produce many missing values.\n",
    "- It mirrors labels only, not business semantics automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is `other` the authoritative schema/template?\n",
    "- Do you want to preserve extra labels currently present?\n",
    "- Should newly missing values be filled immediately?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reindex_like()` when you need exact structural alignment to a reference DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: align predictions table to the same shape as ground-truth table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "actual = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}, index=['r1', 'r2'])\n",
    "pred = pd.DataFrame({'B': [30], 'C': [50]}, index=['r2'])\n",
    "\n",
    "aligned_pred = pred.reindex_like(actual)\n",
    "print(aligned_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rename` changes row or column labels using a mapping or function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mapper`: mapping/function for labels.\n",
    "- `index` / `columns`: explicit mapping for each axis.\n",
    "- `axis`: axis target when using `mapper`.\n",
    "- `copy`, `inplace`: output behavior.\n",
    "- `level`: target level in MultiIndex.\n",
    "- `errors`: `'ignore'` or `'raise'` for missing labels in mapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like replacing old field names with business-friendly names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies mapping/function to labels on target axis.\n",
    "- Only specified labels are changed; others are preserved.\n",
    "- Values remain unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Partial mappings leave unspecified labels unchanged (can hide mistakes).\n",
    "- `inplace=True` reduces traceability in notebook workflows.\n",
    "- Renaming to existing labels may create duplicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Should missing mapping keys fail (`errors='raise'`)?\n",
    "- Are you renaming all labels or only selected ones?\n",
    "- Could new labels collide with existing labels?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rename()` for controlled relabeling without touching data values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: standardize column names before model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Cust ID': [1, 2], 'Total Sales': [100, 120]})\n",
    "standard = df.rename(columns={'Cust ID': 'customer_id', 'Total Sales': 'total_sales'})\n",
    "\n",
    "print(standard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rename_axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rename_axis` renames the axis name(s), not the labels themselves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mapper`: new axis name(s) or mapping.\n",
    "- `index` / `columns`: explicit axis-name assignment.\n",
    "- `axis`: axis selector when using `mapper`.\n",
    "- `copy`, `inplace`: output behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like changing the title of the row/column index, not the individual entries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas updates `Index.name` / `MultiIndex.names` metadata.\n",
    "- Actual row/column label values remain untouched.\n",
    "- Useful for clearer outputs and downstream merges/groupby clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Common confusion: this does not rename labels; use `rename` for that.\n",
    "- MultiIndex may require list-like names matching level count.\n",
    "- Axis names can be dropped later by operations that reset/rebuild indexes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need to rename labels or just axis metadata?\n",
    "- Is this DataFrame part of a MultiIndex workflow needing named levels?\n",
    "- Will clearer axis names improve readability of outputs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rename_axis()` to label index/column axes for semantic clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: name index and columns axes before exporting to markdown/HTML tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120]}, index=['NY', 'Rome'])\n",
    "named = df.rename_axis(index='city', columns='metric')\n",
    "\n",
    "print(named)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.reorder_levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.reorder_levels` reorders MultiIndex levels on rows or columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `order`: new level order (names/positions).\n",
    "- `axis`: `0/'index'` or `1/'columns'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like changing hierarchy order in a multi-layer folder path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas rebuilds MultiIndex metadata with specified order.\n",
    "- Data values remain unchanged.\n",
    "- Output keeps same shape with reordered index/columns hierarchy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only meaningful on MultiIndex axes.\n",
    "- Wrong order specification raises errors.\n",
    "- Reordering can affect downstream slicing/grouping behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does your axis actually use MultiIndex?\n",
    "- Which level order improves access patterns?\n",
    "- Will downstream code assume old level order?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reorder_levels()` to standardize MultiIndex hierarchy order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: place date level before store level for easier slicing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.MultiIndex.from_product([['store_a', 'store_b'], ['2026-01', '2026-02']], names=['store', 'month'])\n",
    "df = pd.DataFrame({'sales': [10, 12, 15, 14]}, index=idx)\n",
    "print(df.reorder_levels(['month', 'store']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.swaplevel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.swaplevel` swaps two MultiIndex levels on rows or columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `i`, `j`: levels to swap (names or positions).\n",
    "- `axis`: `0/'index'` or `1/'columns'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like flipping two hierarchy layers in a nested key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas exchanges positions of specified levels.\n",
    "- No data values change, only structure.\n",
    "- Useful before sort/group operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applies only to MultiIndex axes.\n",
    "- Swapping without sorting can leave non-monotonic order.\n",
    "- Invalid level names/positions raise errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are target levels correctly identified?\n",
    "- Do you need `swaplevel` or full `reorder_levels`?\n",
    "- Should you sort after swapping?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `swaplevel()` for quick two-level hierarchy inversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: swap region and date levels before reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.MultiIndex.from_product([['EU', 'US'], ['2026-01', '2026-02']], names=['region', 'month'])\n",
    "df = pd.DataFrame({'kpi': [1, 2, 3, 4]}, index=idx)\n",
    "print(df.swaplevel('region', 'month'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.explode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.explode` transforms list-like elements in a column into multiple rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `column`: column label(s) to explode.\n",
    "- `ignore_index`: reset index if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like expanding each cell that contains a list into one row per item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas repeats non-exploded values for each expanded item.\n",
    "- List-like entries are flattened into separate rows.\n",
    "- Index is duplicated unless reset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scalars remain unchanged, creating mixed behavior.\n",
    "- Empty lists may produce missing outputs.\n",
    "- Exploding multiple columns requires aligned list lengths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are list lengths consistent across exploded columns?\n",
    "- Do you need original index preserved?\n",
    "- Could row count explode dramatically?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `explode()` to normalize nested list data into row format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert tag arrays into one-tag-per-row records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'tags': [['pandas', 'python'], ['data']]})\n",
    "print(df.explode('tags', ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.melt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.melt` unpivots wide-format columns into long-format rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `id_vars`: columns kept as identifiers.\n",
    "- `value_vars`: columns to unpivot.\n",
    "- `var_name`: output name for former columns.\n",
    "- `value_name`: output name for values.\n",
    "- `ignore_index`: reset index if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like turning monthly columns into one month column plus value column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas keeps id variables fixed and stacks value vars.\n",
    "- Former column names become entries in `var_name` column.\n",
    "- Result is a tidy long table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Long format increases row count.\n",
    "- Need enough id vars to preserve uniqueness.\n",
    "- Default names may be too generic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are id columns sufficient for entity identity?\n",
    "- Do you need custom output names?\n",
    "- Will downstream tools expect long format?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `melt()` to reshape wide tables into tidy long format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert quarterly revenue columns into one `quarter` dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'q1': [10, 20], 'q2': [15, 25]})\n",
    "print(df.melt(id_vars='id', var_name='quarter', value_name='revenue'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.stack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.stack` pivots column levels into the row index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `level`: column level(s) to stack.\n",
    "- `dropna`: drop missing stacked entries.\n",
    "- `future_stack`: option in newer versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like moving column headers down into row labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas transfers selected column levels to index.\n",
    "- Result becomes Series/DataFrame depending on remaining levels.\n",
    "- Often paired with `unstack` as inverse reshape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can create complex MultiIndex outputs.\n",
    "- Missing combinations may disappear if dropping NaNs.\n",
    "- Large reshapes can cost memory/time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need hierarchical index output?\n",
    "- Should missing combinations be preserved?\n",
    "- Would `melt` be clearer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `stack()` for MultiIndex reshape workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: move metric columns into index for compact hierarchy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}, index=['x', 'y'])\n",
    "print(df.stack())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.unstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.unstack` pivots index levels into columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `level`: index level(s) to unstack.\n",
    "- `fill_value`: fill value for introduced missing cells.\n",
    "- `sort`: sort labels where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like spreading a row hierarchy level out into separate columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas moves index level(s) to column axis.\n",
    "- Shape usually widens and may create missing combinations.\n",
    "- Conceptual inverse of matching `stack` operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can introduce many NaNs.\n",
    "- Resulting MultiIndex columns may be complex.\n",
    "- Wide outputs can increase memory usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is widening necessary for downstream use?\n",
    "- Should missing combinations be filled?\n",
    "- Can consumers handle MultiIndex columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `unstack()` to pivot index hierarchy into wide layout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: turn `(region, month)` index into month columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.MultiIndex.from_tuples([('EU', 'Jan'), ('EU', 'Feb'), ('US', 'Jan')], names=['region', 'month'])\n",
    "df = pd.DataFrame({'sales': [10, 12, 20]}, index=idx)\n",
    "print(df.unstack('month'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.transpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.transpose` (or `.T`) swaps rows and columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `copy`: copy behavior where applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like rotating a table so rows become columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas flips axes: index becomes columns and vice versa.\n",
    "- Values are reoriented accordingly.\n",
    "- Mixed types may coerce toward object dtype.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can produce object-heavy output.\n",
    "- Large transposes can be expensive.\n",
    "- Semantic meaning may be less clear after transpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is axis swap meaningful downstream?\n",
    "- Can you tolerate dtype coercion?\n",
    "- Would reshape operations be clearer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `transpose()` when analysis requires switched orientation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert row-centric view to column-centric format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "print(df.transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.truncate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.truncate` keeps rows/columns between specified label boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `before`: starting label boundary.\n",
    "- `after`: ending label boundary.\n",
    "- `axis`: target axis.\n",
    "- `copy`: copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like trimming a timeline to a selected interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs label-based slicing between boundaries.\n",
    "- Boundary inclusion is label-based on target axis.\n",
    "- Useful for concise range extraction with labeled indexes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires sortable meaningful labels.\n",
    "- Unsorted indexes can give surprising subsets.\n",
    "- Different from positional slicing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are labels sorted?\n",
    "- Need label-based or position-based slicing?\n",
    "- Should both boundaries be inclusive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `truncate()` for concise label-range trimming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep only February to April records from date index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01', periods=6, freq='MS')\n",
    "df = pd.DataFrame({'value': [1, 2, 3, 4, 5, 6]}, index=idx)\n",
    "print(df.truncate(before='2026-02-01', after='2026-04-01'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.replace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.replace` substitutes values using exact matches, mappings, or regex patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `to_replace`: value/list/dict/regex targets.\n",
    "- `value`: replacement value(s).\n",
    "- `inplace`: mutate if `True`.\n",
    "- `regex`: treat patterns as regex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like find-and-replace across a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas matches targets using replacement rules.\n",
    "- Matched entries are rewritten with replacements.\n",
    "- Supports global and column-specific mappings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regex can overmatch unexpectedly.\n",
    "- Large replacements can be costly.\n",
    "- Replacement types may coerce column dtypes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need exact or pattern-based replacement?\n",
    "- Should scope be global or column-specific?\n",
    "- Will replacement alter critical dtypes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `replace()` for controlled value remapping and normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: standardize sentinel values to `pd.NA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'city': ['NY', 'N/A', 'Rome'], 'score': [10, -1, 8]})\n",
    "clean = df.replace({'N/A': pd.NA, -1: pd.NA})\n",
    "print(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.update` modifies a DataFrame in place using non-NA values from another aligned object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: DataFrame with replacement values.\n",
    "- `join`: currently `'left'`.\n",
    "- `overwrite`: replace existing values if `True`.\n",
    "- `filter_func`: callable filter.\n",
    "- `errors`: overlap error behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like patching an existing table with corrected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns `other` by index/columns.\n",
    "- Matching cells are updated in place.\n",
    "- Shape is preserved; no new rows/columns added.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In-place update can surprise shared-object workflows.\n",
    "- Unmatched labels are silently ignored.\n",
    "- Partial updates can hide alignment issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need in-place patching or new DataFrame?\n",
    "- Are labels aligned for intended updates?\n",
    "- Should existing values be protected?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `update()` for controlled in-place corrections on existing schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: patch corrected prices into base table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.DataFrame({'price': [10, 20, 30]}, index=[1, 2, 3])\n",
    "patch = pd.DataFrame({'price': [22]}, index=[2])\n",
    "base.update(patch)\n",
    "print(base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.isetitem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.isetitem` sets column values by integer position instead of label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loc`: integer column position.\n",
    "- `value`: new column data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like updating the nth column slot directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas targets column by positional index.\n",
    "- Assigned values are aligned/broadcast as needed.\n",
    "- Operation mutates DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Brittle if column order changes.\n",
    "- Out-of-range position raises errors.\n",
    "- Less readable than label-based assignment.\n",
    "- This is a more advanced positional API; availability and intended usage can vary by pandas version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is positional assignment required?\n",
    "- Would label assignment be clearer?\n",
    "- Is column order stable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `isetitem()` when positional column assignment is explicitly needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: overwrite second column from generated vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.isetitem(1, [30, 40])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969cf62",
   "metadata": {},
   "source": [
    "## Missing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Detect first (`isna`, `notna` family), then choose a policy (`fillna`, `ffill`, `bfill`, `interpolate`).\n",
    "- Use removal (`dropna`) only after measuring data-loss impact.\n",
    "- Goal: treat missingness as a modeling decision, not just a cleanup step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.isna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.isna` returns a boolean DataFrame indicating which cells are missing (`NaN`, `None`, `pd.NA`, `NaT`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like turning on a missing-value detector light for each cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas checks each value against its missing-value rules.\n",
    "- It produces the same shape as the input with `True` where values are missing.\n",
    "- No data is modified; it is a diagnostic mask.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- String placeholders like `'N/A'` are not missing unless normalized first.\n",
    "- `isna()` does not tell you why data is missing, only where.\n",
    "- Boolean mask tables can be large on wide datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Have textual placeholders been converted to real missing values?\n",
    "- Do you need per-column missing ratios after the mask?\n",
    "- Will you use this mask for filtering, filling, or alerts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `isna()` to locate missing values before deciding how to handle them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: quickly profile which columns contain nulls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Ana', None, 'Leo'],\n",
    "    'score': [10, None, 8]\n",
    "})\n",
    "\n",
    "print(df.isna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.isnull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.isnull` is an alias of `isna`; it returns a boolean mask of missing cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same detector as `isna`, just an alternate method name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Internally it delegates to the same missingness logic as `isna`.\n",
    "- Output shape and behavior are equivalent.\n",
    "- It is commonly used in legacy codebases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No functional difference from `isna`; mixing both styles can reduce consistency.\n",
    "- String placeholders are still not auto-converted.\n",
    "- Large masks can consume memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you want naming consistency (`isna`) across the project?\n",
    "- Have non-standard null markers been normalized?\n",
    "- Do you need column-level summary instead of full mask output?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `isnull()` when matching existing style; behavior is the same as `isna()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compatibility with an older codebase using `isnull` naming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, None], 'b': [None, 2]})\n",
    "print(df.isnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.notna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.notna` returns a boolean mask with `True` where values are present (non-missing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It highlights valid cells you can trust for computations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies missing-value detection then inverts the result.\n",
    "- Output mirrors DataFrame shape with presence flags.\n",
    "- Useful for filtering complete observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Still sensitive to unnormalized placeholders like empty strings.\n",
    "- Boolean mask operations on large tables can be expensive.\n",
    "- Per-cell truth does not imply row completeness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need row-wise completeness (`all(axis=1)`) or any valid value (`any(axis=1)`)?\n",
    "- Should empty strings be treated as missing first?\n",
    "- Will this mask feed a filter or metric?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `notna()` to identify values available for reliable analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep rows where mandatory field `email` is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'email': ['a@x.com', None, 'c@x.com'], 'age': [20, 30, None]})\n",
    "print(df[df['email'].notna()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.notnull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.notnull` is an alias of `notna`; it marks non-missing values with `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same valid-value detector as `notna`, different naming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It follows pandas missingness rules and returns the inverted null mask.\n",
    "- Behavior matches `notna` exactly.\n",
    "- Commonly present in historical notebooks/scripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No semantic difference from `notna`.\n",
    "- Unclean placeholders can still appear as valid values.\n",
    "- Using both aliases in one project hurts style consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Should your team standardize on `notna` naming?\n",
    "- Have placeholder strings been normalized first?\n",
    "- Do you need element-level or row-level completeness checks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `notnull()` for compatibility; it is equivalent to `notna()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: preserve older code semantics while filtering valid cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, None, 3], 'y': [None, 2, 4]})\n",
    "print(df.notnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.fillna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.fillna` replaces missing values using constants, per-column mappings, or propagation methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `value`: scalar/dict/Series/DataFrame used to fill nulls.\n",
    "- `method`: fill strategy (`ffill`/`bfill`) in supported versions.\n",
    "- `axis`: axis to apply fill logic.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `limit`: maximum consecutive nulls to fill.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like patching holes in a table with predefined values or nearby known values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas locates missing entries and applies fill rules per axis/column.\n",
    "- Scalar fills broadcast broadly; dict fills target specific columns.\n",
    "- Returns a new DataFrame unless `inplace=True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blind filling can hide data quality issues.\n",
    "- Using `0` can bias aggregates if missing has business meaning.\n",
    "- Method-based filling depends on row order and grouping context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is a constant fill statistically/business-wise appropriate?\n",
    "- Should fill be global or column-specific?\n",
    "- Do you need to preserve a missingness indicator before filling?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `fillna()` when you have an explicit missing-data imputation rule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: fill numeric nulls with 0 and text nulls with `'unknown'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'city': ['NY', None, 'Rome'],\n",
    "    'sales': [100, None, 80]\n",
    "})\n",
    "\n",
    "filled = df.fillna({'city': 'unknown', 'sales': 0})\n",
    "print(filled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.ffill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.ffill` forward-fills missing values using the last valid observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis along which to fill (`0` by default).\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `limit`: max consecutive missing values to fill.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like carrying the last known reading forward until a new reading appears.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas scans along the axis and propagates prior non-null values to subsequent nulls.\n",
    "- Leading null blocks stay null until a valid value appears.\n",
    "- Often used in time-series continuity assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can create stale values if gaps are large.\n",
    "- Order matters: unsorted time data produces incorrect fills.\n",
    "- Should often be done per group (e.g., per customer) not globally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is forward carry logically valid for this feature?\n",
    "- Is data correctly sorted before filling?\n",
    "- Do you need group-wise forward fill instead of global fill?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ffill()` when previous valid value is the best estimate for short gaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: carry latest sensor reading forward in minute-level data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [10, None, None, 14, None]})\n",
    "print(df.ffill(limit=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.bfill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.bfill` backward-fills missing values using the next valid observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis along which to backfill.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `limit`: max consecutive nulls to fill.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like filling earlier blanks using the next available confirmed value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas scans from the opposite direction and propagates next non-null values backward.\n",
    "- Trailing nulls remain null if no future value exists.\n",
    "- Useful for certain alignment tasks and backward inference assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can leak future information in predictive modeling if used incorrectly.\n",
    "- Requires careful ordering context.\n",
    "- Global backfill may cross logical entity boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is using future information acceptable in this context?\n",
    "- Should fill happen within groups only?\n",
    "- Are you preventing data leakage in ML pipelines?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `bfill()` when next known value is a justified replacement for earlier gaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: fill initial missing values in a calibration phase from first valid reading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [None, None, 7, None, 9]})\n",
    "print(df.bfill(limit=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.dropna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.dropna` removes rows or columns containing missing values according to thresholds/rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: drop rows (`0`) or columns (`1`).\n",
    "- `how`: `'any'` or `'all'` missingness condition.\n",
    "- `thresh`: minimum non-null count required to keep.\n",
    "- `subset`: evaluate missingness on selected columns.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `ignore_index`: reset index in the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like removing incomplete forms that do not meet minimum required fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas evaluates null counts per row/column on target axis.\n",
    "- Entries failing criteria are removed.\n",
    "- Remaining data order is preserved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aggressive dropping can discard too much data.\n",
    "- `how` and `thresh` cannot be used blindly; they encode different retention policies.\n",
    "- Dropping rows can unbalance class distributions in ML datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What completeness threshold is acceptable for your analysis?\n",
    "- Should rules apply to all columns or a critical subset?\n",
    "- Do you need to quantify dropped records before applying?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `dropna()` when incomplete records are unusable under explicit quality rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep only rows where `name` and `email` are both present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Ana', 'Leo', None],\n",
    "    'email': ['a@x.com', None, 'c@x.com'],\n",
    "    'age': [20, 30, 40]\n",
    "})\n",
    "\n",
    "clean = df.dropna(subset=['name', 'email'])\n",
    "print(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.interpolate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.interpolate` fills missing numeric values using interpolation between known points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `method`: interpolation algorithm (`linear`, `time`, `index`, etc.).\n",
    "- `axis`: interpolation direction.\n",
    "- `limit`: max consecutive nulls to fill.\n",
    "- `limit_direction`: `forward`, `backward`, or `both`.\n",
    "- `limit_area`: control where filling is allowed (`inside`/`outside`).\n",
    "- `inplace`: mutate DataFrame if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like drawing a smooth line between known points and estimating values in the gap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes estimated values from neighboring non-null points using selected method.\n",
    "- Interpolation can use positional index or time-aware index depending on method.\n",
    "- Primarily intended for numeric/time-series contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interpolation assumptions may be invalid for categorical or irregular jumps.\n",
    "- Requires ordered index for meaningful time/index interpolation.\n",
    "- Can silently produce unrealistic values if method is mismatched.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is interpolation statistically valid for this variable?\n",
    "- Is the index sorted and appropriate for the chosen method?\n",
    "- Should long gaps remain missing instead of interpolated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `interpolate()` when missing numeric points can be reasonably estimated from nearby observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: fill short gaps in hourly sensor measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'temp': [20.0, None, None, 26.0, 27.0]})\n",
    "print(df.interpolate(method='linear', limit=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.first_valid_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.first_valid_index` returns the index label of the first row that contains at least one non-missing value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like finding the first usable row in a partially empty sheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas scans rows from top to bottom.\n",
    "- It returns the first index label where row has any non-null value.\n",
    "- Returns `None` if all rows are fully missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It checks row validity by any non-null cell, not full row completeness.\n",
    "- With duplicated index labels, returned label may not identify a unique row.\n",
    "- Can be expensive on very large all-null leading segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need first partially valid row or fully valid row?\n",
    "- Could duplicated index labels cause ambiguity?\n",
    "- Do you also need `last_valid_index` for window trimming?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `first_valid_index()` to locate where meaningful data starts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: trim warm-up null period before analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [None, None, 3, 4], 'b': [None, None, None, 1]}, index=[10, 11, 12, 13])\n",
    "print(df.first_valid_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.combine_first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.combine_first` fills nulls in one DataFrame using non-null values from another, aligned by index/columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: fallback DataFrame used where current DataFrame has missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like overlaying a backup table to patch holes in a primary table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns both DataFrames by labels.\n",
    "- For each cell, it keeps left value if non-null; otherwise takes right value.\n",
    "- Union of indexes/columns can appear in result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unexpected extra rows/columns may appear due to label union.\n",
    "- Type coercion can happen when mixing incompatible dtypes.\n",
    "- Not symmetric: `a.combine_first(b)` differs from `b.combine_first(a)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which DataFrame is authoritative primary source?\n",
    "- Are label sets aligned or expected to expand?\n",
    "- Should patched fields be tracked for lineage?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `combine_first()` for label-aware fallback filling between two tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: patch missing CRM fields using backup export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "primary = pd.DataFrame({'email': ['a@x.com', None], 'tier': [None, 'gold']}, index=[1, 2])\n",
    "backup = pd.DataFrame({'email': ['a@x.com', 'b@x.com'], 'tier': ['silver', 'gold']}, index=[1, 2])\n",
    "\n",
    "patched = primary.combine_first(backup)\n",
    "print(patched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.where\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.where` keeps original values where a condition is `True`, and replaces values where condition is `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cond`: boolean DataFrame/array/callable condition.\n",
    "- `other`: replacement value(s) where condition is False.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `axis`, `level`: alignment controls in advanced use.\n",
    "- `errors`, `try_cast`: compatibility options by version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a stencil: keep data through allowed holes, paint over the rest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns condition with DataFrame shape.\n",
    "- Cells with `True` keep original value.\n",
    "- Cells with `False` are replaced by `other` (or missing if omitted).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Condition alignment mistakes can produce unexpected NaNs.\n",
    "- `where` logic is opposite of `mask` (easy to invert by mistake).\n",
    "- Replacement dtype may upcast columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is your condition aligned correctly by index/columns?\n",
    "- Do you want to preserve `True` cells (`where`) or `False` cells (`mask`)?\n",
    "- Is replacement value dtype-compatible with existing columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `where()` when you want to keep valid values and replace invalid ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep non-negative values and null out negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [5, -2, 3], 'b': [-1, 4, 6]})\n",
    "clean = df.where(df >= 0)\n",
    "print(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.mask` replaces values where a condition is `True`, keeping values where condition is `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cond`: boolean condition aligned to DataFrame.\n",
    "- `other`: replacement value(s) where condition is True.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `axis`, `level`: advanced alignment controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like covering forbidden cells and replacing them with safe placeholders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns condition with the DataFrame.\n",
    "- `True` locations are replaced by `other` (or missing if omitted).\n",
    "- `False` locations retain original values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Easy to confuse with `where` because condition meaning is inverted.\n",
    "- Misaligned masks lead to unexpected nulls.\n",
    "- Replacement can trigger dtype changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you intend to replace condition-true cells (`mask`) or keep them (`where`)?\n",
    "- Are mask dimensions and labels aligned?\n",
    "- Should replacement be scalar or column-specific mapping?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mask()` when condition marks values to suppress/replace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: cap outliers by replacing values above threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'score': [50, 72, 180, 65]})\n",
    "capped = df.mask(df > 100, other=100)\n",
    "print(capped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10595f1",
   "metadata": {},
   "source": [
    "## Mathematical and Logical Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Learn alignment-aware arithmetic (`add/sub/mul/div` family) before comparisons (`eq`, `gt`, ...).\n",
    "- Then use reducers (`all`, `any`) to turn masks into decisions.\n",
    "- Goal: write explicit, label-safe numeric logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.abs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.abs` returns absolute values element-wise, removing the sign from numeric entries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like converting all distances to magnitude regardless of direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies absolute-value operation to each numeric element.\n",
    "- Positive values stay unchanged; negative values become positive.\n",
    "- Non-numeric columns are left unchanged or skipped depending on dtype handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Absolute value removes direction/sign information.\n",
    "- Applying it blindly can hide important meaning (e.g., deficits vs profits).\n",
    "- Mixed dtypes may require explicit numeric selection first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is sign meaningful in your domain?\n",
    "- Should you restrict operation to selected numeric columns?\n",
    "- Do you need original signed values for later interpretation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `abs()` when you need magnitude-only comparisons across values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert signed residuals to error magnitudes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'err_a': [-3, 2, -1], 'err_b': [4, -5, 0]})\n",
    "print(df.abs())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.add` performs element-wise addition with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left + right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `add()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply addition across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.add(right, fill_value=0)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.radd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.radd` performs element-wise reverse addition with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right + left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `radd()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse addition across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(left.radd(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sub` performs element-wise subtraction with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left - right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sub()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply subtraction across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.sub(right, fill_value=0)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.subtract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.subtract` performs element-wise subtraction (alias of `sub`) with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left - right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `subtract()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply subtraction (alias of `sub`) across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.subtract(right, fill_value=0)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rsub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rsub` performs element-wise reverse subtraction with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right - left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rsub()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse subtraction across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(left.rsub(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.mul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.mul` performs element-wise multiplication with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left * right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mul()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply multiplication across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.mul(right, fill_value=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.multiply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.multiply` performs element-wise multiplication (alias of `mul`) with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left * right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `multiply()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply multiplication (alias of `mul`) across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.multiply(right, fill_value=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rmul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rmul` performs element-wise reverse multiplication with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right * left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rmul()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse multiplication across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(left.rmul(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.div` performs element-wise division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left / right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `div()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.div(right, fill_value=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.divide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.divide` performs element-wise division (alias of `div`) with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left / right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `divide()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply division (alias of `div`) across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.divide(right, fill_value=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rdiv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rdiv` performs element-wise reverse division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right / left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rdiv()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1.0, 2.0], 'b': [4.0, 5.0]})\n",
    "print(left.rdiv(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.truediv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.truediv` performs element-wise true division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left / right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `truediv()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply true division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.truediv(right, fill_value=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rtruediv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rtruediv` performs element-wise reverse true division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: axis used to align Series operands.\n",
    "- `level`: broadcast across a specific MultiIndex level when applicable.\n",
    "- `fill_value`: substitute value used for missing entries before operation (supported where applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right / left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rtruediv()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse true division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1.0, 2.0], 'b': [4.0, 5.0]})\n",
    "print(left.rtruediv(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.floordiv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.floordiv` performs element-wise floor division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left // right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `floordiv()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply floor division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.floordiv(3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rfloordiv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rfloordiv` performs element-wise reverse floor division with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right // left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rfloordiv()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse floor division across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [2, 3], 'b': [4, 5]})\n",
    "print(left.rfloordiv(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.mod` performs element-wise modulo with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left % right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mod()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply modulo across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.mod(3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rmod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rmod` performs element-wise reverse modulo with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right % left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rmod()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse modulo across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [2, 3], 'b': [4, 5]})\n",
    "print(left.rmod(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pow` performs element-wise power with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `left ** right` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pow()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply power across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "right = pd.DataFrame({'a': [10, 20], 'b': [30, 40]})\n",
    "\n",
    "result = left.pow(2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rpow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rpow` performs element-wise reverse power with automatic label alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like operand.\n",
    "- `axis`: alignment axis for Series operands.\n",
    "- `level`: MultiIndex broadcast level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two spreadsheets cell by cell using `right ** left` rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands on index and columns before computing.\n",
    "- Element-wise operation is applied where aligned values exist.\n",
    "- Missing alignments may produce NaN unless `fill_value` is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misaligned labels can create many NaNs unexpectedly.\n",
    "- Arithmetic may upcast dtypes (e.g., int to float).\n",
    "- Reverse methods (`r*`) flip operand order, which changes non-commutative results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operand labels aligned as intended?\n",
    "- Do you need `fill_value` to avoid NaN propagation?\n",
    "- Does operand order matter for this operation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rpow()` for explicit label-aware arithmetic in pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: apply reverse power across aligned numeric tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(left.rpow(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.dot` performs matrix multiplication between a DataFrame and another object (Series/DataFrame/array).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: Series, DataFrame, or array-like with compatible dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like multiplying a feature matrix by a weight vector to produce scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns labels when possible (especially with Series/DataFrame operands).\n",
    "- It computes row-by-column dot products following linear algebra rules.\n",
    "- Output shape depends on the right-hand operand dimensionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dimension mismatch raises errors.\n",
    "- Label misalignment can produce unexpected results if indexes/columns differ.\n",
    "- For very large matrices, specialized numeric libraries may be faster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are matrix dimensions compatible?\n",
    "- Do labels align as expected?\n",
    "- Would NumPy/scipy sparse operations be more efficient at scale?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `dot()` for label-aware matrix-style multiplication in pandas pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute weighted score from multiple feature columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame({'f1': [1, 2], 'f2': [3, 4]})\n",
    "w = pd.Series({'f1': 0.5, 'f2': 2.0})\n",
    "\n",
    "score = X.dot(w)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.clip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.clip` limits values to lower/upper bounds, capping outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `lower`: minimum threshold (scalar or aligned object).\n",
    "- `upper`: maximum threshold (scalar or aligned object).\n",
    "- `axis`: alignment axis when thresholds are array-like.\n",
    "- `inplace`: mutate DataFrame if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like setting floor and ceiling limits for acceptable values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Values below `lower` are set to `lower`.\n",
    "- Values above `upper` are set to `upper`.\n",
    "- Values inside range remain unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Capping can distort distributions and hide anomalies.\n",
    "- Threshold choice should be justified (domain/statistical).\n",
    "- Per-column bounds require careful alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are bounds domain-driven or arbitrary?\n",
    "- Should clipping be symmetric or one-sided?\n",
    "- Do you need to track which values were clipped?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `clip()` for bounded transformations when extreme values must be controlled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: cap unrealistic negative and very high transaction values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'amount': [-20, 50, 900, 120]})\n",
    "print(df.clip(lower=0, upper=500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.round\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.round` rounds numeric values to a specified number of decimals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `decimals`: int, dict, or Series specifying decimal places globally or per column.\n",
    "- `*args`, `**kwargs`: accepted for NumPy compatibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like formatting measurements to the precision your report requires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies rounding column-wise on numeric data.\n",
    "- With dict/Series, each column can use different precision.\n",
    "- Non-numeric columns remain unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rounding too early can accumulate precision error in later calculations.\n",
    "- Binary floating-point representation can still show surprises.\n",
    "- Round for presentation separately from core calculations when possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is rounding for display or for stored analytical results?\n",
    "- Do different columns need different precision?\n",
    "- Could premature rounding bias downstream metrics?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `round()` at reporting boundaries or when precision policy is explicit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: prepare KPI table with stable decimal formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'ratio': [0.12345, 0.98765], 'price': [10.555, 20.444]})\n",
    "print(df.round({'ratio': 3, 'price': 2}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.eq` performs element-wise comparison and returns a boolean DataFrame for values equal to another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `==` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `==` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `eq()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Check whether values equal a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.eq(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.ne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.ne` performs element-wise comparison and returns a boolean DataFrame for values not equal to another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `!=` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `!=` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ne()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Check whether values differ from a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.ne(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.gt` performs element-wise comparison and returns a boolean DataFrame for values greater than another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `>` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `>` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `gt()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Identify values above a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.gt(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.ge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.ge` performs element-wise comparison and returns a boolean DataFrame for values greater than or equal to another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `>=` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `>=` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ge()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Identify values meeting/exceeding a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.ge(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.lt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.lt` performs element-wise comparison and returns a boolean DataFrame for values less than another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `<` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `<` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `lt()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Identify values below a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.lt(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.le` performs element-wise comparison and returns a boolean DataFrame for values less than or equal to another object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: scalar, Series, DataFrame, or array-like for comparison.\n",
    "- `axis`: alignment axis when comparing with Series.\n",
    "- `level`: broadcast across MultiIndex level when applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like applying the `<=` rule to every cell in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by labels when possible.\n",
    "- Each element is compared using `<=` semantics.\n",
    "- Result is a boolean DataFrame with same aligned shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label misalignment can introduce unexpected missing comparisons.\n",
    "- Comparing mixed dtypes may yield surprising outcomes.\n",
    "- Floating-point edge values may need tolerance logic instead of strict comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are operands aligned on the intended labels?\n",
    "- Do you need exact comparison or tolerance-based checks?\n",
    "- Will missing values require additional handling after comparison?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `le()` for explicit, readable element-wise comparison masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Identify values at/below a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 2, 1]})\n",
    "print(df.le(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.all` returns whether all values are True/non-zero along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: `0` (columns) or `1` (rows).\n",
    "- `bool_only`: include only boolean columns if `True`.\n",
    "- `skipna`: ignore missing values if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like checking if every checklist item passes in each group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas reduces boolean truth across axis entries.\n",
    "- If any value is False, result for that axis position is False.\n",
    "- Output is a Series unless reduced to scalar with further ops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non-boolean numeric values are truth-tested (0=False, non-zero=True).\n",
    "- Missing-value behavior depends on `skipna`.\n",
    "- Axis confusion can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are your inputs truly boolean flags?\n",
    "- Should missing values count as failures?\n",
    "- Do you need row-level or column-level checks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `all()` for strict all-conditions-must-pass reductions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: verify each row satisfies all quality checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "checks = pd.DataFrame({'c1': [True, True, False], 'c2': [True, True, True]})\n",
    "print(checks.all(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.any` returns whether at least one value is True/non-zero along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: `0` (columns) or `1` (rows).\n",
    "- `bool_only`: include only boolean columns if `True`.\n",
    "- `skipna`: ignore missing values if `True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like checking if at least one alarm condition is triggered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs boolean OR-style reduction along the axis.\n",
    "- If any value is True, result for that axis position is True.\n",
    "- Output is a Series by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numeric columns are truth-tested if not filtered.\n",
    "- Missing handling can affect edge cases.\n",
    "- `any` is permissive; do not confuse with strict `all`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need permissive detection (`any`) or strict validation (`all`)?\n",
    "- Are you reducing on the intended axis?\n",
    "- Should NA values be ignored or treated explicitly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `any()` to detect whether at least one condition holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: detect rows with at least one failed check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fails = pd.DataFrame({'rule_a_fail': [False, True, False], 'rule_b_fail': [False, False, True]})\n",
    "print(fails.any(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.equals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.equals` returns `True` if two DataFrames have the same shape and identical elements (including NaN positions).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: DataFrame to compare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like verifying two spreadsheets are exactly identical cell by cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas checks shape, index/column labels, dtypes, and values.\n",
    "- NaNs in the same positions are considered equal.\n",
    "- Returns a single boolean scalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Small dtype differences can make otherwise similar tables unequal.\n",
    "- Order of rows/columns matters.\n",
    "- For tolerance-based numeric checks, use specialized comparison tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do labels and ordering match between the two DataFrames?\n",
    "- Do you need exact equality or approximate numeric equality?\n",
    "- Could dtype differences be intentional?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `equals()` for strict identity checks in tests and validation gates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: verify post-processing did not alter a control dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame({'x': [1, 2], 'y': [3, None]})\n",
    "b = pd.DataFrame({'x': [1, 2], 'y': [3, None]})\n",
    "\n",
    "print(a.equals(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00cf5ee",
   "metadata": {},
   "source": [
    "## Aggregation and Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Start with core reducers (`sum`, `mean`, `count`) and flexible `agg/aggregate`.\n",
    "- Add distribution diagnostics (`describe`, `quantile`, `mode`, `value_counts`).\n",
    "- Finish with dependence/trend metrics (`corr`, `cov`, cumulative/diff methods).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.agg` applies one or multiple aggregation functions across an axis or per column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: function, function name, list, or dict of aggregations.\n",
    "- `axis`: axis to aggregate.\n",
    "- `*args`, `**kwargs`: extra arguments passed to aggregation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking for a custom summary report where each metric can use different formulas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas dispatches requested function(s) over selected data.\n",
    "- With list/dict syntax, it builds a richer result shape containing multiple metrics.\n",
    "- Output type varies (scalar/Series/DataFrame) based on function specification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Result shape can change dramatically depending on `func` form.\n",
    "- Custom Python functions may be slower than built-in vectorized reducers.\n",
    "- Ambiguous aggregation names can fail if unsupported for dtype.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need one metric or multiple metrics per column?\n",
    "- Is function output shape acceptable for downstream steps?\n",
    "- Can you use built-in reductions for speed/stability?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `agg()` for flexible, multi-metric summarization in one call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute mean and max for numeric columns in one pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120, 80], 'cost': [60, 70, 50]})\n",
    "print(df.agg(['mean', 'max']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.aggregate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.aggregate` applies one or multiple aggregation functions across an axis or per column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: function, function name, list, or dict of aggregations.\n",
    "- `axis`: axis to aggregate.\n",
    "- `*args`, `**kwargs`: extra arguments passed to aggregation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking for a custom summary report where each metric can use different formulas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas dispatches requested function(s) over selected data.\n",
    "- With list/dict syntax, it builds a richer result shape containing multiple metrics.\n",
    "- Output type varies (scalar/Series/DataFrame) based on function specification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Result shape can change dramatically depending on `func` form.\n",
    "- Custom Python functions may be slower than built-in vectorized reducers.\n",
    "- Ambiguous aggregation names can fail if unsupported for dtype.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need one metric or multiple metrics per column?\n",
    "- Is function output shape acceptable for downstream steps?\n",
    "- Can you use built-in reductions for speed/stability?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `aggregate()` for flexible, multi-metric summarization in one call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute mean and max for numeric columns in one pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120, 80], 'cost': [60, 70, 50]})\n",
    "print(df.aggregate(['mean', 'max']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.count` computes non-missing count along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one non-missing count score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the non-missing count reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `count()` for fast axis-wise non-missing count summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute non-missing count KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sum` computes sum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one sum score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the sum reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sum()` for fast axis-wise sum summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute sum KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.prod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.prod` computes product along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one product score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the product reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `prod()` for fast axis-wise product summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute product KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.prod())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.product` computes product (alias of `prod`) along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one product (alias of `prod`) score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the product (alias of `prod`) reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `product()` for fast axis-wise product (alias of `prod`) summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute product (alias of `prod`) KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.product())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.mean` computes mean along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one mean score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the mean reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mean()` for fast axis-wise mean summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute mean KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.median` computes median along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one median score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the median reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `median()` for fast axis-wise median summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute median KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.min` computes minimum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one minimum score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the minimum reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `min()` for fast axis-wise minimum summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute minimum KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.max` computes maximum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one maximum score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the maximum reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `max()` for fast axis-wise maximum summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute maximum KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.mode` returns the most frequent value(s) per column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: compute mode along columns (`0`) or rows (`1`).\n",
    "- `numeric_only`: include only numeric columns where supported.\n",
    "- `dropna`: whether to consider NaN as a value in mode computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like finding the most common answer in each survey question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas counts frequency of values per axis slice.\n",
    "- It returns all ties (multiple modes) as multiple rows when needed.\n",
    "- Result is a DataFrame because each column can have different mode counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output can have more than one row due to ties.\n",
    "- Non-numeric/object behavior depends on dtype and `numeric_only`.\n",
    "- Missing-value treatment depends on `dropna`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can your data have multiple equally frequent values?\n",
    "- Should missing values compete as valid mode candidates?\n",
    "- Do downstream steps handle multi-row mode output?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mode()` to extract the most frequent value patterns, including ties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: identify most common category per feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'color': ['red', 'blue', 'red', 'blue'], 'size': ['M', 'M', 'L', 'M']})\n",
    "print(df.mode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.std` computes standard deviation along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n",
    "- `ddof`: delta degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one standard deviation score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the standard deviation reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `std()` for fast axis-wise standard deviation summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute standard deviation KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.var` computes variance along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n",
    "- `ddof`: delta degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one variance score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the variance reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `var()` for fast axis-wise variance summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute variance KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.var())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sem` computes standard error of the mean along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n",
    "- `ddof`: delta degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one standard error of the mean score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the standard error of the mean reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sem()` for fast axis-wise standard error of the mean summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute standard error of the mean KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.sem())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.skew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.skew` computes skewness along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one skewness score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the skewness reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `skew()` for fast axis-wise skewness summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute skewness KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.kurt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.kurt` computes kurtosis along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one kurtosis score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the kurtosis reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `kurt()` for fast axis-wise kurtosis summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute kurtosis KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.kurt())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.kurtosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.kurtosis` computes kurtosis (alias of `kurt`) along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one kurtosis (alias of `kurt`) score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the kurtosis (alias of `kurt`) reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `kurtosis()` for fast axis-wise kurtosis (alias of `kurt`) summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute kurtosis (alias of `kurt`) KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.kurtosis())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.describe` generates descriptive statistics summary for numeric and/or object columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `percentiles`: list of percentiles to include.\n",
    "- `include`: dtypes to include.\n",
    "- `exclude`: dtypes to exclude.\n",
    "- `datetime_is_numeric`: treat datetime as numeric in supported versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like an automatic profile card of your dataset's core distribution stats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas chooses summary metrics based on column dtypes.\n",
    "- Numeric columns get count/mean/std/min/quantiles/max; object columns get count/unique/top/freq.\n",
    "- Returns a DataFrame indexed by statistic names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed-type frames can produce heterogeneous summary rows.\n",
    "- Percentile set affects readability and output size.\n",
    "- Not a replacement for full EDA on skewed or multimodal distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which dtypes should be included in summary?\n",
    "- Do custom percentiles matter for your business thresholds?\n",
    "- Do you need more granular distribution diagnostics afterward?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `describe()` for a fast first-pass statistical profile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: run quick EDA snapshot on newly ingested data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120, 80, 95], 'city': ['NY', 'Rome', 'NY', 'Berlin']})\n",
    "print(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.quantile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.quantile` computes value thresholds at given quantile probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `q`: float or array of quantile probabilities in [0, 1].\n",
    "- `axis`: axis to compute quantiles on.\n",
    "- `numeric_only`: include numeric columns only.\n",
    "- `interpolation`: interpolation strategy between data points.\n",
    "- `method`: quantile calculation method in supported versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like finding percentile cut points (e.g., median, p90) for each metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas sorts values conceptually and locates positions for requested quantiles.\n",
    "- If quantile position falls between observations, interpolation rules apply.\n",
    "- Output is Series/DataFrame depending on number of requested `q` values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interpolation choice can change threshold values.\n",
    "- Small samples make quantiles unstable.\n",
    "- Mixed dtypes require explicit numeric filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need one percentile or multiple?\n",
    "- Which interpolation rule aligns with your reporting standard?\n",
    "- Is sample size large enough for robust quantiles?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `quantile()` for percentile-based thresholding and robust summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute p50 and p90 for service latency columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'latency_ms': [80, 95, 110, 150, 220]})\n",
    "print(df.quantile([0.5, 0.9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.nunique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.nunique` computes number of distinct values along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: reduce by columns (`0`) or rows (`1`).\n",
    "- `skipna`: ignore missing values where supported.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like summarizing many values into one number of distinct values score per row or column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas selects the target axis and eligible columns.\n",
    "- It applies the number of distinct values reduction over each axis slice.\n",
    "- Output is typically a Series (one value per label on the opposite axis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixed dtypes can silently exclude columns depending on `numeric_only`.\n",
    "- Missing-value handling changes results if `skipna` differs.\n",
    "- Axis choice (`0` vs `1`) can invert interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are you reducing on the intended axis?\n",
    "- Should missing values be ignored or treated explicitly?\n",
    "- Do you need numeric-only filtering before reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `nunique()` for fast axis-wise number of distinct values summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute number of distinct values KPI per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, None]})\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.value_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.value_counts` counts unique row combinations across selected columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `subset`: columns used to define unique combinations.\n",
    "- `normalize`: return proportions instead of counts.\n",
    "- `sort`: sort by frequency if `True`.\n",
    "- `ascending`: sort direction.\n",
    "- `dropna`: include/exclude NaN combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like counting how many times each multi-column key pattern appears.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas groups identical row tuples (or subset tuples).\n",
    "- It computes frequency per unique tuple.\n",
    "- Result is a Series with MultiIndex keys for combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output index can become complex with many columns.\n",
    "- High-cardinality combinations can be memory heavy.\n",
    "- `dropna` choice affects key completeness interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which columns define the pattern you care about?\n",
    "- Do you need counts or proportions?\n",
    "- Should null-containing combinations be included?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `value_counts()` for fast pattern frequency analysis across columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: find most common `(country, device)` combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'country': ['US', 'US', 'IT', 'US'], 'device': ['mobile', 'web', 'web', 'mobile']})\n",
    "print(df.value_counts(subset=['country', 'device']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.idxmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.idxmax` returns index labels of the maximum value along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis to search along.\n",
    "- `skipna`: ignore missing values.\n",
    "- `numeric_only`: restrict to numeric columns where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking: where (which label) does each column/row reach its peak or bottom?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas scans each axis slice for maximum value.\n",
    "- It returns the label position of first occurrence of that extreme.\n",
    "- Output is typically a Series of labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ties return first occurrence only.\n",
    "- All-NA slices can produce NA outputs or errors depending on context/version.\n",
    "- Requires meaningful index labels for interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are ties possible and acceptable with first-occurrence behavior?\n",
    "- Do you need the value itself too, not only the label?\n",
    "- Are index labels meaningful business keys?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `idxmax()` when you need labels of extrema, not just extrema values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: find row label where each metric reaches its maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 140, 120], 'cost': [70, 60, 90]}, index=['A', 'B', 'C'])\n",
    "print(df.idxmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.idxmin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.idxmin` returns index labels of the minimum value along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis to search along.\n",
    "- `skipna`: ignore missing values.\n",
    "- `numeric_only`: restrict to numeric columns where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking: where (which label) does each column/row reach its peak or bottom?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas scans each axis slice for minimum value.\n",
    "- It returns the label position of first occurrence of that extreme.\n",
    "- Output is typically a Series of labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ties return first occurrence only.\n",
    "- All-NA slices can produce NA outputs or errors depending on context/version.\n",
    "- Requires meaningful index labels for interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are ties possible and acceptable with first-occurrence behavior?\n",
    "- Do you need the value itself too, not only the label?\n",
    "- Are index labels meaningful business keys?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `idxmin()` when you need labels of extrema, not just extrema values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: find row label where each metric reaches its minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 140, 120], 'cost': [70, 60, 90]}, index=['A', 'B', 'C'])\n",
    "print(df.idxmin())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.corr` computes pairwise correlation between columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `method`: `'pearson'`, `'kendall'`, `'spearman'`.\n",
    "- `min_periods`: minimum paired observations required.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like measuring how strongly columns move together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes pairwise correlations for eligible numeric column pairs.\n",
    "- Each pair uses overlapping non-missing observations.\n",
    "- Output is a square correlation matrix DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation is not causation.\n",
    "- Outliers and non-linear relationships can mislead Pearson correlation.\n",
    "- Small sample sizes produce unstable coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which correlation method matches your data distribution?\n",
    "- Is sample size sufficient for reliable inference?\n",
    "- Do missing patterns bias pairwise comparisons?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `corr()` for quick dependency screening among numeric features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inspect linear relationships before feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, 2, 3, 4], 'y': [2, 4, 6, 8], 'z': [4, 1, 3, 2]})\n",
    "print(df.corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.corrwith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.corrwith` computes correlation between aligned objects (DataFrame/DataFrame or DataFrame/Series).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: Series or DataFrame to correlate with.\n",
    "- `axis`: axis along which to compute pairings.\n",
    "- `drop`: drop missing labels before matching.\n",
    "- `method`: correlation method.\n",
    "- `numeric_only`: numeric filtering where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like comparing matching columns (or rows) between two aligned tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns labels between both objects.\n",
    "- It computes one correlation per aligned pair (column-wise or row-wise).\n",
    "- Result is a Series of correlation coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Misalignment can silently reduce compared data.\n",
    "- Non-overlapping labels yield missing outputs.\n",
    "- Interpretation depends on chosen axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are both objects aligned on intended labels?\n",
    "- Do you want per-column or per-row correlations?\n",
    "- Should missing labels be dropped or investigated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `corrwith()` when you need one-to-one aligned correlation comparisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compare model predictions vs actuals per metric column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "actual = pd.DataFrame({'m1': [1, 2, 3], 'm2': [4, 5, 6]})\n",
    "pred = pd.DataFrame({'m1': [1, 2, 4], 'm2': [3, 5, 7]})\n",
    "print(actual.corrwith(pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.cov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.cov` computes pairwise covariance between numeric columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `min_periods`: minimum observations required per pair.\n",
    "- `ddof`: delta degrees of freedom.\n",
    "- `numeric_only`: include numeric columns only where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like measuring how two variables vary together in raw units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes pairwise covariance using overlapping non-missing data.\n",
    "- It returns a square covariance matrix.\n",
    "- Diagonal entries are variances of each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Covariance depends on variable scale and is not standardized.\n",
    "- Outliers can heavily influence values.\n",
    "- Insufficient paired data may produce missing entries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need standardized relationship (`corr`) instead of covariance?\n",
    "- Are scales comparable across variables?\n",
    "- Is sample size sufficient per pair?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cov()` when scale-sensitive co-variation is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inspect covariance matrix before portfolio-style risk analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'r1': [0.1, 0.2, -0.1], 'r2': [0.05, 0.1, -0.02]})\n",
    "print(df.cov())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.cumsum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.cumsum` computes cumulative sum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis direction for accumulation.\n",
    "- `skipna`: ignore missing values in accumulation where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like keeping a running sum as you traverse rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas processes values sequentially along the axis.\n",
    "- Each output cell reflects cumulative sum up to that position.\n",
    "- Result preserves original shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row order determines outcomes; sort intentionally first.\n",
    "- Missing values can interrupt accumulation semantics.\n",
    "- Cumulative metrics can be misread if index order is arbitrary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is row order meaningful for cumulative logic?\n",
    "- Should missing values be skipped or prefilled?\n",
    "- Do you need group-wise cumulative behavior instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cumsum()` for running metrics over ordered data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute cumulative sum for a daily metric series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [2, 3, 1, 4]})\n",
    "print(df.cumsum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.cumprod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.cumprod` computes cumulative product along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis direction for accumulation.\n",
    "- `skipna`: ignore missing values in accumulation where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like keeping a running product as you traverse rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas processes values sequentially along the axis.\n",
    "- Each output cell reflects cumulative product up to that position.\n",
    "- Result preserves original shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row order determines outcomes; sort intentionally first.\n",
    "- Missing values can interrupt accumulation semantics.\n",
    "- Cumulative metrics can be misread if index order is arbitrary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is row order meaningful for cumulative logic?\n",
    "- Should missing values be skipped or prefilled?\n",
    "- Do you need group-wise cumulative behavior instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cumprod()` for running metrics over ordered data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute cumulative product for a daily metric series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [2, 3, 1, 4]})\n",
    "print(df.cumprod())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.cummax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.cummax` computes cumulative maximum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis direction for accumulation.\n",
    "- `skipna`: ignore missing values in accumulation where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like keeping a running maximum as you traverse rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas processes values sequentially along the axis.\n",
    "- Each output cell reflects cumulative maximum up to that position.\n",
    "- Result preserves original shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row order determines outcomes; sort intentionally first.\n",
    "- Missing values can interrupt accumulation semantics.\n",
    "- Cumulative metrics can be misread if index order is arbitrary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is row order meaningful for cumulative logic?\n",
    "- Should missing values be skipped or prefilled?\n",
    "- Do you need group-wise cumulative behavior instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cummax()` for running metrics over ordered data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute cumulative maximum for a daily metric series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [2, 3, 1, 4]})\n",
    "print(df.cummax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.cummin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.cummin` computes cumulative minimum along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: axis direction for accumulation.\n",
    "- `skipna`: ignore missing values in accumulation where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like keeping a running minimum as you traverse rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas processes values sequentially along the axis.\n",
    "- Each output cell reflects cumulative minimum up to that position.\n",
    "- Result preserves original shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row order determines outcomes; sort intentionally first.\n",
    "- Missing values can interrupt accumulation semantics.\n",
    "- Cumulative metrics can be misread if index order is arbitrary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is row order meaningful for cumulative logic?\n",
    "- Should missing values be skipped or prefilled?\n",
    "- Do you need group-wise cumulative behavior instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cummin()` for running metrics over ordered data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute cumulative minimum for a daily metric series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'value': [2, 3, 1, 4]})\n",
    "print(df.cummin())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.diff` computes discrete differences between current and prior observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `periods`: lag steps to subtract (default `1`).\n",
    "- `axis`: axis along which difference is calculated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like measuring change from one row to the previous row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas subtracts shifted values from current values.\n",
    "- First `periods` positions become missing due to unavailable prior points.\n",
    "- Result keeps same shape as original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Order matters; unsorted data gives misleading changes.\n",
    "- Large lags increase leading missing blocks.\n",
    "- Non-numeric columns are not appropriate for numeric diff semantics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is the DataFrame sorted in meaningful order?\n",
    "- Do you need first difference or larger lag difference?\n",
    "- Should differencing be applied within groups?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `diff()` to convert levels into period-over-period changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute day-to-day sales deltas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120, 115, 130]})\n",
    "print(df.diff())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.boxplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.boxplot` draws box-and-whisker plots for numeric columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `column`: specific column(s) to plot.\n",
    "- `by`: grouping column for grouped boxplots.\n",
    "- `ax`: matplotlib axis object.\n",
    "- `grid`, `figsize`, `layout`, `return_type`: plotting controls.\n",
    "- `**kwargs`: forwarded plotting options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like showing median, spread, and outliers at a glance for distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas delegates plotting to matplotlib.\n",
    "- For each numeric series, quartiles and whiskers are computed.\n",
    "- Figure/axes objects are returned depending on configuration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires plotting backend availability in environment.\n",
    "- Outlier interpretation depends on whisker convention.\n",
    "- Grouped boxplots can become cluttered with many categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which columns and groupings provide readable plots?\n",
    "- Do you need plot object handles for customization?\n",
    "- Is boxplot the right visual for your audience?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `boxplot()` for compact distribution/outlier diagnostics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: visualize salary distribution by department.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'dept': ['A', 'A', 'B', 'B'],\n",
    "    'salary': [50, 55, 60, 80]\n",
    "})\n",
    "\n",
    "ax = df.boxplot(column='salary', by='dept')\n",
    "print(type(ax).__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.hist` draws histograms for numeric columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `column`: column subset to plot.\n",
    "- `by`: optional grouping key.\n",
    "- `bins`: number/edges of bins.\n",
    "- `figsize`, `layout`, `sharex`, `sharey`: subplot controls.\n",
    "- `**kwargs`: forwarded matplotlib histogram options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like viewing how values are distributed across value ranges (bins).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes bin counts per selected numeric column.\n",
    "- It builds one or multiple matplotlib histogram axes.\n",
    "- Useful for quick distribution shape checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bin choice strongly influences visual impression.\n",
    "- Highly skewed data may require log scaling or custom bins.\n",
    "- Many columns can generate crowded subplot grids.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are default bins appropriate for your data scale?\n",
    "- Do you need grouped histograms or separate plots?\n",
    "- Should you transform skewed data before plotting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `hist()` for quick numeric distribution inspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inspect the distribution of response times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'latency_ms': [80, 90, 95, 110, 140, 200]})\n",
    "axes = df.hist(bins=4)\n",
    "print(type(axes).__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4758933",
   "metadata": {},
   "source": [
    "## GroupBy and Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Master `groupby` split-apply-combine first.\n",
    "- Then learn window families in order: `rolling` -> `expanding` -> `ewm`.\n",
    "- Goal: distinguish segment-level metrics from time-local smoothing metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.groupby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.groupby` splits data into groups, applies operations per group, and combines results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `by`: grouping key(s).\n",
    "- `axis`, `level`: grouping axis/level.\n",
    "- `as_index`, `sort`, `group_keys`, `dropna`, `observed`: behavior controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like organizing records into buckets, then computing bucket summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas partitions rows by keys.\n",
    "- Aggregations/transforms/apply run inside each partition.\n",
    "- Outputs are recombined with grouping metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `apply` can be slower than `agg`/`transform`.\n",
    "- `as_index` choice affects schema.\n",
    "- Missing/category handling depends on config.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need reduced output or same-shape transform?\n",
    "- Should group keys remain columns?\n",
    "- Are missing-group keys handled intentionally?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `groupby()` as foundation for per-segment analytics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute average sales by region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'region': ['EU', 'EU', 'US'], 'sales': [10, 14, 20]})\n",
    "print(df.groupby('region', as_index=False)['sales'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rolling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rolling` creates rolling windows for moving calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `window`: window size/offset.\n",
    "- `min_periods`: minimum observations.\n",
    "- `center`, `on`, `axis`, `closed`, `step`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like sliding a fixed-size frame over data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas defines overlapping windows.\n",
    "- Aggregations are computed per window.\n",
    "- Leading windows may be missing until `min_periods` is met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Depends on sort order/index semantics.\n",
    "- Large windows can be expensive.\n",
    "- Time windows require proper datetime context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need count-based or time-based window?\n",
    "- Is `min_periods` set appropriately?\n",
    "- Is data sorted in intended order?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rolling()` for moving-average and local trend calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute 3-step rolling average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [10, 12, 11, 15, 14]})\n",
    "print(df.rolling(window=3).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.expanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.expanding` creates expanding windows from start to current row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `min_periods`: minimum observations.\n",
    "- `axis`: calculation axis.\n",
    "- `method`: engine option where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like cumulative analytics with growing history.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Windows increase as you move forward.\n",
    "- Aggregations use full history-to-date.\n",
    "- Useful for running statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Order sensitivity is critical.\n",
    "- Early estimates can be unstable.\n",
    "- May be slower than simpler cumulative methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need expanding or fixed rolling windows?\n",
    "- Is `min_periods` adequate?\n",
    "- Is data sorted correctly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `expanding()` for history-to-date metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute running average conversion rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'conv': [0.1, 0.2, 0.15, 0.3]})\n",
    "print(df.expanding(min_periods=1).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.ewm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.ewm` creates exponentially weighted windows emphasizing recent observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of `com`, `span`, `halflife`, or `alpha`.\n",
    "- `min_periods`, `adjust`, `ignore_na`, `axis`, `times`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like smoothing with stronger weight on recent points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes exponentially decayed weights.\n",
    "- Recent observations influence output more strongly.\n",
    "- Useful for EMA-like smoothing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decay choice strongly affects responsiveness.\n",
    "- `adjust` setting changes formula behavior.\n",
    "- Interpretation differs from simple rolling mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need fast-reacting or smoother trend?\n",
    "- Which decay parameterization fits domain?\n",
    "- Must formula match another system exactly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ewm()` for recency-weighted trend metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute exponentially weighted mean demand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'demand': [100, 110, 90, 120, 115]})\n",
    "print(df.ewm(span=3).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e6956",
   "metadata": {},
   "source": [
    "## Merge, Join and Reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Start with relational joins (`merge`, `join`), validating key cardinality.\n",
    "- Use `align`/`combine`/`compare` for table-to-table reconciliation.\n",
    "- End with long<->wide reshaping (`pivot`, `pivot_table`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.merge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.merge` joins two DataFrames using SQL-style key matching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `right`: right DataFrame.\n",
    "- `how`: `left/right/inner/outer/cross`.\n",
    "- `on`, `left_on`, `right_on`: join key specs.\n",
    "- `left_index`, `right_index`: index-based keys.\n",
    "- `suffixes`, `indicator`, `validate`, `sort`: join controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like combining two tables by shared key columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas matches key combinations across frames.\n",
    "- Rows are composed by join type semantics.\n",
    "- Overlapping non-key names are disambiguated with suffixes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many-to-many joins can explode row counts.\n",
    "- Key dtype mismatch prevents expected matches.\n",
    "- Duplicate keys can silently distort metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is join cardinality validated?\n",
    "- Are key dtypes aligned?\n",
    "- Should unmatched rows be preserved?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `merge()` for explicit relational joins with validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: enrich orders with customer segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.DataFrame({'customer_id': [1, 2], 'amount': [100, 120]})\n",
    "customers = pd.DataFrame({'customer_id': [1, 2], 'segment': ['A', 'B']})\n",
    "print(orders.merge(customers, on='customer_id', how='left'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.join` joins columns of another object, primarily by index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: DataFrame/Series or list.\n",
    "- `on`: caller key to match other's index.\n",
    "- `how`: join type.\n",
    "- `lsuffix`, `rsuffix`, `sort`, `validate`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like attaching extra columns by aligned row labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns indexes by default.\n",
    "- With `on`, caller column joins to right index.\n",
    "- Provides concise syntax for index-oriented joins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index quality drives correctness.\n",
    "- Overlapping names require suffix handling.\n",
    "- Implicit index assumptions can be overlooked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is join naturally index-based?\n",
    "- Are indexes unique where expected?\n",
    "- Would `merge` be clearer for explicit key joins?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `join()` for concise index-centric enrichment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: attach manager name by region index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'sales': [100, 120]}, index=['EU', 'US'])\n",
    "right = pd.DataFrame({'manager': ['Ana', 'Leo']}, index=['EU', 'US'])\n",
    "print(left.join(right))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.align\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.align` aligns two objects to the same index/column labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: object to align with.\n",
    "- `join`: `outer/inner/left/right`.\n",
    "- `axis`: align specific axis or both.\n",
    "- `level`, `copy`, `fill_value`, `method`, `limit`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like putting two maps on the same coordinate grid before comparing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes target labels by join rule.\n",
    "- Both objects are reindexed to that label space.\n",
    "- Returns two aligned objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alignment can introduce many NaNs.\n",
    "- Join choice changes retained label universe.\n",
    "- Easy to forget it returns a tuple, not one object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need union or intersection labels?\n",
    "- Should introduced gaps be filled?\n",
    "- Align rows, columns, or both?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `align()` before arithmetic/comparison to make alignment explicit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: align forecast and actual tables before error calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame({'x': [1, 2]}, index=['r1', 'r2'])\n",
    "b = pd.DataFrame({'x': [10]}, index=['r2'])\n",
    "a2, b2 = a.align(b, join='outer', fill_value=0)\n",
    "print(a2)\n",
    "print(b2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.combine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.combine` merges two DataFrames using a custom element-wise column function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: DataFrame to combine with.\n",
    "- `func`: binary function on aligned Series pairs.\n",
    "- `fill_value`: value for missing entries before combining.\n",
    "- `overwrite`: overwrite behavior for missing columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like zipping two tables and applying a custom merge rule per column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns both objects first.\n",
    "- `func` runs per aligned column pair.\n",
    "- Outputs are assembled into a new DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Custom Python functions can be slower than built-ins.\n",
    "- Alignment and missing handling need explicit care.\n",
    "- Inconsistent function outputs can break assembly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can built-in arithmetic cover this faster?\n",
    "- Are labels aligned to intended domain?\n",
    "- How should missing values be handled?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `combine()` when merge logic is custom and column-aware.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: choose element-wise maximum from two scenario tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame({'x': [1, 5], 'y': [3, 2]})\n",
    "b = pd.DataFrame({'x': [2, 4], 'y': [1, 6]})\n",
    "out = a.combine(b, lambda s1, s2: s1.where(s1 >= s2, s2))\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.compare` highlights differences between two DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `other`: DataFrame to compare with.\n",
    "- `align_axis`: align diff output by rows/columns.\n",
    "- `keep_shape`, `keep_equal`: output controls.\n",
    "- `result_names`: labels for compared sides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a side-by-side diff report for table versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas aligns both tables and detects unequal cells.\n",
    "- Returns structured self/other diff values.\n",
    "- Equal values can be omitted unless requested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires compatible labels/shapes.\n",
    "- Diff output can be sparse and MultiIndex-heavy.\n",
    "- Not tolerance-aware for tiny float noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are labels aligned before compare?\n",
    "- Need full-shape diff or only changed cells?\n",
    "- Need approximate equality handling first?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `compare()` for audit-friendly change inspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inspect deltas between old and new forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "new = pd.DataFrame({'a': [1, 5], 'b': [3, 4]})\n",
    "print(old.compare(new))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pivot` reshapes long data into wide form with unique index/column pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `index`: new row index column.\n",
    "- `columns`: new columns source.\n",
    "- `values`: value column(s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like turning transaction rows into a matrix layout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas maps each `(index, columns)` pair to one cell.\n",
    "- Values populate corresponding wide positions.\n",
    "- Requires unique combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duplicate key pairs raise errors.\n",
    "- Missing combinations become NaN.\n",
    "- Use `pivot_table` when duplicates require aggregation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are key combinations unique?\n",
    "- Need aggregation for duplicates?\n",
    "- Will wide format help downstream tasks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pivot()` for deterministic long-to-wide reshape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: reshape monthly records into one column per month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 1, 2, 2], 'month': ['Jan', 'Feb', 'Jan', 'Feb'], 'sales': [10, 12, 20, 18]})\n",
    "print(df.pivot(index='id', columns='month', values='sales'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pivot_table` creates aggregated spreadsheet-style pivot tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `values`: value column(s).\n",
    "- `index`, `columns`: grouping dimensions.\n",
    "- `aggfunc`: aggregation function(s).\n",
    "- `fill_value`, `margins`, `dropna`, `observed`, `sort`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like building an Excel pivot table with configurable summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas groups by specified dimensions.\n",
    "- Aggregates values using `aggfunc`.\n",
    "- Returns summarized wide table, handling duplicates naturally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can produce complex MultiIndex outputs.\n",
    "- Aggregation choice drives interpretation.\n",
    "- High-cardinality pivots can become large/sparse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which dimensions belong on rows vs columns?\n",
    "- Is default aggregation appropriate?\n",
    "- Need grand totals (`margins=True`)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pivot_table()` for robust aggregated reshape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: summarize average sales by region and quarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'region': ['EU', 'EU', 'US'], 'quarter': ['Q1', 'Q2', 'Q1'], 'sales': [10, 14, 20]})\n",
    "print(df.pivot_table(values='sales', index='region', columns='quarter', aggfunc='mean'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd7912",
   "metadata": {},
   "source": [
    "## Time Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Separate frequency conversion (`asfreq`, `resample`) from lookup (`asof`) and lag logic (`shift`, `pct_change`).\n",
    "- Then handle calendar/timezone semantics (`to_period`, `to_timestamp`, `tz_localize`, `tz_convert`).\n",
    "- Goal: avoid silent temporal misalignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.asfreq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.asfreq` converts a time index to a target frequency without aggregation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `freq`: target frequency.\n",
    "- `method`: fill method for introduced slots.\n",
    "- `how`, `normalize`, `fill_value`: conversion/fill controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like remapping timeline points to a new interval grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas reindexes timestamps to target frequency.\n",
    "- Existing points align to new grid; gaps are introduced.\n",
    "- Unlike resample, no aggregation is applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upsampling can create many NaNs.\n",
    "- Requires datetime/period index.\n",
    "- Not a replacement for aggregation-based frequency change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need pure reindexing or aggregation?\n",
    "- How should new gaps be filled?\n",
    "- Is index frequency/timezone clean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `asfreq()` for direct frequency alignment semantics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert daily series to 12-hour grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01', periods=3, freq='D')\n",
    "df = pd.DataFrame({'v': [10, 20, 30]}, index=idx)\n",
    "print(df.asfreq('12h'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.asof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.asof` returns last valid row(s) before a target timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `where`: timestamp or list-like targets.\n",
    "- `subset`: columns used for validity check.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like asking for the latest known snapshot up to a specific time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas searches backward from each target label.\n",
    "- Returns nearest prior non-missing row per query.\n",
    "- Designed for sorted time indexes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index must be sorted.\n",
    "- Subset-based validity can skip rows unexpectedly.\n",
    "- Not equivalent to nearest-neighbor both-direction lookup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is index sorted chronologically?\n",
    "- Should validity depend on specific columns?\n",
    "- Need backward-as-of semantics specifically?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `asof()` for point-in-time backward lookup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: retrieve latest known price before query time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.to_datetime(['2026-01-01 09:00', '2026-01-01 09:05', '2026-01-01 09:10'])\n",
    "df = pd.DataFrame({'price': [100, None, 103]}, index=idx)\n",
    "print(df.asof(pd.Timestamp('2026-01-01 09:07')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.shift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.shift` moves values by periods along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `periods`: shift steps.\n",
    "- `freq`: shift index labels by offset.\n",
    "- `axis`: shift axis.\n",
    "- `fill_value`: fill for introduced gaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like creating lag/lead columns by moving values in time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas offsets data positions by `periods`.\n",
    "- Vacated positions become missing or fill value.\n",
    "- With `freq`, labels shift in time rather than data movement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Direction sign can be confusing.\n",
    "- Improper shift can introduce data leakage.\n",
    "- `freq` semantics differ from positional shift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need lag or lead?\n",
    "- Should labels move or values move?\n",
    "- Is leakage controlled in modeling steps?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `shift()` for temporal offsets and lag features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: create one-step lag of sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [10, 12, 11, 15]})\n",
    "df['sales_lag1'] = df['sales'].shift(1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.resample` groups time-indexed data into frequency bins for aggregation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rule`: target frequency.\n",
    "- `axis`: resample axis.\n",
    "- `closed`, `label`, `origin`, `offset`: bin controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like grouping events into hourly/daily/monthly buckets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas creates bins from rule and datetime index.\n",
    "- Returns Resampler object for aggregate/transform methods.\n",
    "- Supports downsampling and upsampling workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires datetime-like index context.\n",
    "- Boundary settings affect bucket attribution.\n",
    "- Upsampling introduces gaps requiring fill strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are boundaries/labels configured to reporting conventions?\n",
    "- Need aggregation or interpolation afterward?\n",
    "- Is timezone normalized?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `resample()` for frequency-based time aggregation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: aggregate 15-minute hits to hourly totals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01 09:00', periods=6, freq='15min')\n",
    "df = pd.DataFrame({'hits': [5, 7, 6, 8, 9, 4]}, index=idx)\n",
    "print(df.resample('1h').sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pct_change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pct_change` computes percentage change versus prior values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `periods`: lag periods.\n",
    "- `fill_method`, `limit`, `freq`: behavior controls.\n",
    "- `axis`: calculation axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like measuring period-over-period growth rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes `(current / prior) - 1` with chosen lag.\n",
    "- Leading rows become missing due to unavailable prior value.\n",
    "- Operates element-wise on numeric data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zero baselines can create inf/NaN.\n",
    "- Ordering directly affects interpretation.\n",
    "- Outliers can dominate percentage metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is data chronologically sorted?\n",
    "- Should zero/missing baselines be pre-handled?\n",
    "- Need absolute diff instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pct_change()` for growth-rate analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute daily price returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'price': [100, 105, 102, 110]})\n",
    "print(df.pct_change())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_period` converts DatetimeIndex to PeriodIndex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `freq`: target period frequency.\n",
    "- `axis`: axis containing datetime index.\n",
    "- `copy`: copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like mapping exact timestamps into calendar periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas maps each datetime label to period label.\n",
    "- Index semantics shift from instants to periods.\n",
    "- Useful for period-based reporting/grouping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires datetime-like index.\n",
    "- Coarser periods discard intra-period detail.\n",
    "- Frequency choice changes reporting semantics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need period labels or exact timestamps?\n",
    "- Which period frequency matches business cadence?\n",
    "- Will loss of exact time detail matter?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_period()` for period-centric indexing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert daily index into monthly periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01', periods=3, freq='D')\n",
    "df = pd.DataFrame({'v': [1, 2, 3]}, index=idx)\n",
    "print(df.to_period('M'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_timestamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_timestamp` converts PeriodIndex back to DatetimeIndex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `freq`: target timestamp frequency.\n",
    "- `how`: `'start'` or `'end'` boundary.\n",
    "- `axis`: axis with PeriodIndex.\n",
    "- `copy`: copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like turning calendar periods back into concrete timestamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas maps each period to boundary timestamp.\n",
    "- Boundary choice determines resulting clock point.\n",
    "- Enables timestamp-level operations after period workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boundary choice can shift interpretation.\n",
    "- Requires PeriodIndex.\n",
    "- Implicit freq assumptions can surprise if not explicit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need start or end boundary mapping?\n",
    "- Is resulting frequency suitable downstream?\n",
    "- Need timezone handling afterward?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_timestamp()` to return from period to timestamp indexing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert monthly periods to month-start timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.period_range('2026-01', periods=3, freq='M')\n",
    "df = pd.DataFrame({'v': [10, 12, 11]}, index=idx)\n",
    "print(df.to_timestamp(how='start'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.tz_convert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.tz_convert` converts timezone-aware DatetimeIndex to another timezone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tz`: target timezone.\n",
    "- `axis`, `level`: axis/level containing datetime index.\n",
    "- `copy`: copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like translating UTC clock time to local office timezone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas converts aware timestamps to equivalent instants in target TZ.\n",
    "- Absolute moments stay same; displayed clock time changes.\n",
    "- Useful for localization and reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires timezone-aware index.\n",
    "- DST transitions can be non-intuitive.\n",
    "- Inconsistent source timezone handling causes errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is index already timezone-aware?\n",
    "- Which canonical timezone should pipeline use?\n",
    "- How are DST edge cases validated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tz_convert()` for timezone translation of aware timestamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: convert UTC events to Europe/Rome time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01 10:00', periods=2, freq='h', tz='UTC')\n",
    "df = pd.DataFrame({'v': [1, 2]}, index=idx)\n",
    "print(df.tz_convert('Europe/Rome'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.tz_localize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.tz_localize` assigns timezone to a timezone-naive DatetimeIndex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tz`: timezone to assign.\n",
    "- `axis`, `level`: target axis/level.\n",
    "- `ambiguous`, `nonexistent`: DST conflict handling.\n",
    "- `copy`: copy behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like declaring what timezone local clock stamps belong to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas attaches timezone metadata to naive timestamps.\n",
    "- No moment conversion is performed.\n",
    "- DST ambiguity handling can be configured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do not confuse with `tz_convert`.\n",
    "- DST ambiguous/nonexistent times can raise errors.\n",
    "- Wrong localization leads to lasting temporal misalignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are timestamps naive local times or already UTC?\n",
    "- How should DST ambiguities be resolved?\n",
    "- Will pipeline normalize to UTC afterward?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tz_localize()` to add timezone meaning to naive datetimes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: localize local-office timestamps before UTC conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2026-01-01 09:00', periods=2, freq='h')\n",
    "df = pd.DataFrame({'v': [1, 2]}, index=idx)\n",
    "print(df.tz_localize('Europe/Rome'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f89af8",
   "metadata": {},
   "source": [
    "## Sorting and Ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Use deterministic ordering first (`sort_index`, `sort_values`).\n",
    "- Then derive rank/top-k/bottom-k views (`rank`, `nlargest`, `nsmallest`).\n",
    "- Goal: separate ordering logic from business scoring logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sort_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sort_index` sorts rows or columns by index labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: rows (`0`) or columns (`1`).\n",
    "- `level`: MultiIndex level sort.\n",
    "- `ascending`, `inplace`, `kind`, `na_position`, `sort_remaining`, `ignore_index`, `key`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like alphabetically or chronologically ordering labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas orders labels on the target axis.\n",
    "- Values move with their labels.\n",
    "- Useful for deterministic output and time operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sorting labels differs from sorting by values.\n",
    "- MultiIndex sort can be subtle.\n",
    "- In-place sorting may hide prior order assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need label sort or value sort?\n",
    "- Is level config correct for MultiIndex?\n",
    "- Should NaNs appear first or last?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sort_index()` for deterministic label ordering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: enforce chronological row order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'v': [2, 1]}, index=['2026-01-02', '2026-01-01'])\n",
    "print(df.sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.sort_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.sort_values` sorts rows by one or more column values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `by`: column label(s) to sort by.\n",
    "- `axis`: sorting axis.\n",
    "- `ascending`, `inplace`, `kind`, `na_position`, `ignore_index`, `key`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like ranking records by business KPI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas computes order from selected key column(s).\n",
    "- Rows are rearranged while preserving row integrity.\n",
    "- Multi-key sorting applies lexicographic precedence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tie order depends on settings/algorithm.\n",
    "- NaN placement should be explicit.\n",
    "- Large sorts can be expensive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which columns define primary and tie-break order?\n",
    "- Should NaNs go top or bottom?\n",
    "- Is in-place sort acceptable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sort_values()` for value-driven ordering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: sort products by margin descending then name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'product': ['A', 'B', 'C'], 'margin': [0.2, 0.5, 0.5]})\n",
    "print(df.sort_values(by=['margin', 'product'], ascending=[False, True]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.rank` assigns rank numbers along an axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `axis`: ranking axis.\n",
    "- `method`: tie strategy.\n",
    "- `numeric_only`: include numeric columns.\n",
    "- `na_option`, `ascending`, `pct`: controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like assigning leaderboard positions with tie rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas maps values to rank order.\n",
    "- Tie method determines rank assignment for equals.\n",
    "- Output retains shape with rank values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tie method materially changes results.\n",
    "- NaN handling affects interpretation.\n",
    "- Mixed dtypes may need explicit numeric filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which tie policy matches business rules?\n",
    "- Need percentile or absolute ranks?\n",
    "- How should NaNs be handled?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `rank()` for flexible scoring/ordering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute percentile ranks of sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sales': [100, 120, 120, 90]})\n",
    "print(df.rank(method='dense', ascending=False, pct=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.nlargest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.nlargest` returns top `n` rows by specified columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n`: number of rows.\n",
    "- `columns`: ordering columns.\n",
    "- `keep`: tie handling (`first/last/all`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like getting top leaderboard entries quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs partial top-k selection.\n",
    "- Rows are selected by descending value order.\n",
    "- Usually faster than full sort for small top-k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tie handling can change selected rows.\n",
    "- Best suited to comparable numeric values.\n",
    "- Per-group top-k requires additional grouping logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need global or per-group top-k?\n",
    "- How should ties at cutoff be handled?\n",
    "- Are ordering columns correct?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `nlargest()` for efficient top-k extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: top 3 customers by revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'customer': ['A', 'B', 'C', 'D'], 'revenue': [100, 250, 180, 250]})\n",
    "print(df.nlargest(3, columns='revenue'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.nsmallest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.nsmallest` returns bottom `n` rows by specified columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n`: number of rows.\n",
    "- `columns`: ordering columns.\n",
    "- `keep`: tie handling (`first/last/all`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like quickly finding lowest values without full sort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas performs partial bottom-k selection.\n",
    "- Rows are selected by ascending order.\n",
    "- Useful for worst-case diagnostics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tie policy affects boundary rows.\n",
    "- Not all dtypes are suitable for ordering.\n",
    "- Per-group bottom-k requires extra grouping step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need global or segment-specific bottom-k?\n",
    "- How should ties be handled?\n",
    "- Could NaNs affect ordering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `nsmallest()` for fast bottom-k extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: find two endpoints with lowest latency performance score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'endpoint': ['a', 'b', 'c', 'd'], 'latency_ms': [80, 120, 60, 95]})\n",
    "print(df.nsmallest(2, columns='latency_ms'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17450a7a",
   "metadata": {},
   "source": [
    "## Function Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Prefer vectorized methods first; use this section for controlled custom logic.\n",
    "- Learn composability with `pipe`, then expression shortcuts (`eval`, `query`).\n",
    "- Goal: keep flexibility without sacrificing performance/readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.apply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.apply` applies a function along rows or columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: callable.\n",
    "- `axis`: apply per column (`0`) or per row (`1`).\n",
    "- `raw`, `result_type`, `args`, `**kwargs`: behavior controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like running one custom routine on each row/column unit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas iterates over axis units and calls `func`.\n",
    "- Output shape depends on function return values.\n",
    "- Very flexible, but often slower than vectorized alternatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python-level functions can be performance bottlenecks.\n",
    "- Unclear return shape can break downstream steps.\n",
    "- Row-wise apply is especially expensive on large data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can this be vectorized?\n",
    "- Is axis choice correct?\n",
    "- Is return shape predictable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `apply()` for custom logic when vectorized methods are impractical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute weighted row score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, 2], 'y': [3, 4]})\n",
    "score = df.apply(lambda r: 0.3 * r['x'] + 0.7 * r['y'], axis=1)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.map` applies a scalar function element-wise across the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: scalar function.\n",
    "- `na_action`: missing-value handling where supported.\n",
    "- `**kwargs`: extra function arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like passing each cell through the same converter function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies function to each cell individually.\n",
    "- Return values form a new DataFrame.\n",
    "- Useful for simple uniform scalar transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Element-wise Python functions can be slow.\n",
    "- Return-value types may coerce dtypes.\n",
    "- Vectorized methods are usually faster when available.\n",
    "- Availability/behavior may differ across pandas versions; older codebases may still use `applymap` patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is element-wise mapping necessary?\n",
    "- Can a vectorized method replace this?\n",
    "- Are NaNs handled intentionally?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map()` for uniform cell-level transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: format each numeric cell with unit suffix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(df.map(lambda x: f'{x} u'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.pipe` passes the DataFrame into a function for chain-friendly composition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: callable receiving DataFrame.\n",
    "- `*args`, `**kwargs`: extra arguments passed to callable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like inserting reusable named steps inside a method chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas calls function with DataFrame and provided args.\n",
    "- Function output is returned to continue the chain.\n",
    "- Helps separate complex logic into readable helpers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hidden side effects reduce chain transparency.\n",
    "- Return type changes can break subsequent steps.\n",
    "- Debugging is harder when helper logic is opaque.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Should this transformation be a named helper?\n",
    "- Is helper function pure and predictable?\n",
    "- Does output type stay chain-compatible?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pipe()` for modular and readable pipeline design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: inject margin computation into an ETL chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_margin(df, revenue_col, cost_col):\n",
    "    out = df.copy()\n",
    "    out['margin'] = out[revenue_col] - out[cost_col]\n",
    "    return out\n",
    "\n",
    "df = pd.DataFrame({'rev': [100, 120], 'cost': [70, 80]})\n",
    "print(df.pipe(add_margin, 'rev', 'cost'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.eval` evaluates expression strings over DataFrame columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `expr`: expression string.\n",
    "- `inplace`: allow assignment into frame.\n",
    "- `engine`, `parser`, `local_dict`, `global_dict`: evaluation context controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like spreadsheet formulas referencing column names directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas parses expression and resolves columns/variables.\n",
    "- Chosen engine evaluates expression efficiently where possible.\n",
    "- Can return computed result or assign new columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expression strings are less refactor-friendly.\n",
    "- Complex expressions can be harder to debug.\n",
    "- Scope/name collisions can cause subtle bugs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is string expression readable and maintainable?\n",
    "- Need in-place assignment behavior?\n",
    "- Are variable scopes unambiguous?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `eval()` for concise expression-based computations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: compute margin via expression syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'rev': [100, 120], 'cost': [70, 90]})\n",
    "print(df.eval('margin = rev - cost'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.query` filters rows using a boolean expression string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `expr`: boolean query expression.\n",
    "- `inplace`: mutate DataFrame if `True`.\n",
    "- `engine`, `parser`, `local_dict`, `global_dict`: evaluation controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like SQL WHERE filtering on DataFrame columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas evaluates expression row-wise.\n",
    "- Rows satisfying condition are returned.\n",
    "- External Python variables can be referenced with `@var`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- String queries are less lint/refactor friendly.\n",
    "- Columns with special chars require backticks.\n",
    "- Complex conditions may be clearer as explicit masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is query syntax clearer than explicit mask?\n",
    "- Do column names need escaping?\n",
    "- Are variable references unambiguous?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `query()` for readable declarative row filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: keep high-value US orders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'country': ['US', 'IT', 'US'], 'amount': [120, 80, 300]})\n",
    "print(df.query(\"country == 'US' and amount > 100\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.transform` applies function(s) and returns output aligned to original shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func`: callable/list/dict.\n",
    "- `axis`: transform axis.\n",
    "- `*args`, `**kwargs`: extra function args.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like normalizing data while keeping same table dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas applies function and aligns results back to source shape.\n",
    "- Unlike `agg`, it is shape-preserving.\n",
    "- Common in groupby workflows needing one output per input row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions must return shape-compatible outputs.\n",
    "- Often confused with reducing aggregations.\n",
    "- Custom Python transforms may be slow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need same-shape output or reduced summary?\n",
    "- Is function output length compatible?\n",
    "- Can vectorized expressions replace custom transform?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `transform()` when outputs must align one-to-one with original data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: z-score normalize columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [10, 11, 12]})\n",
    "z = df.transform(lambda s: (s - s.mean()) / s.std())\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ceb8d",
   "metadata": {},
   "source": [
    "## I/O and Serialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Start with universal text/binary exports (`to_csv`, `to_json`, `to_parquet`).\n",
    "- Then cover ecosystem-specific targets (SQL, Excel, Stata, XML, etc.).\n",
    "- Goal: choose format by interoperability, fidelity, and performance constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_clipboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_clipboard` copies table text to system clipboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `excel`: Excel-friendly output if `True`.\n",
    "- `sep`: delimiter.\n",
    "- `**kwargs`: formatting options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n",
    "- Clipboard support may be unavailable on headless environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_clipboard()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: quickly paste table into spreadsheet or chat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "# df.to_clipboard(index=False)\n",
    "print('clipboard export prepared')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_csv` writes table data to CSV text format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path_or_buf`: output destination.\n",
    "- `sep`, `na_rep`, `header`, `index`, `encoding`, `compression`: key options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_csv()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: export cleaned dataset for broad interoperability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_csv('out.csv', index=False)\n",
    "print('written out.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_dict` converts DataFrame into Python dictionary structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `orient`: output orientation.\n",
    "- `into`: mapping class.\n",
    "- `index`: include index where supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_dict()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: prepare API payload records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'score': [90, 80]})\n",
    "print(df.to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_excel` writes DataFrame to Excel workbook formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `excel_writer`: path or writer object.\n",
    "- `sheet_name`, `index`, `header`, `startrow`, `startcol`, `engine`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_excel()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: deliver analytics table as `.xlsx` report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'metric': ['sales', 'cost'], 'value': [100, 70]})\n",
    "df.to_excel('report.xlsx', index=False)\n",
    "print('written report.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_feather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_feather` writes DataFrame to Apache Feather (Arrow) format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path`: output file.\n",
    "- `compression`, `compression_level`, `chunksize`, `version`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_feather()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: fast interchange with Arrow-compatible tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_feather('data.feather')\n",
    "print('written data.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_hdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_hdf` writes DataFrame into HDF5 storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path_or_buf`: HDF file path.\n",
    "- `key`: dataset key.\n",
    "- `mode`, `format`, `complevel`, `complib`, `append`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_hdf()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: persist medium/large snapshots with optional compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_hdf('data.h5', key='tbl', mode='w')\n",
    "print('written data.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_html` renders DataFrame as HTML table text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `buf`: output destination.\n",
    "- `columns`, `index`, `na_rep`, `escape`, `classes`, `table_id`: render options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_html()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: embed table in web page/report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'city': ['NY', 'Rome'], 'sales': [100, 120]})\n",
    "html = df.to_html(index=False)\n",
    "print(html[:80])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_iceberg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_iceberg` writes DataFrame into an Apache Iceberg table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Table identifier/catalog parameters (signature may vary by pandas/backend).\n",
    "- Backend-specific kwargs as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n",
    "- API and dependencies vary significantly by engine/catalog setup.\n",
    "- API shape is backend- and version-dependent; verify against your target pandas + catalog stack.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_iceberg()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: publish transformed data to lakehouse Iceberg table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'value': [10, 20]})\n",
    "# Example signature varies by backend/version\n",
    "# df.to_iceberg('catalog.db.table')\n",
    "print('iceberg export depends on environment configuration')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_json` serializes DataFrame to JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path_or_buf`: destination or return string.\n",
    "- `orient`, `date_format`, `date_unit`, `double_precision`, `force_ascii`, `lines`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_json()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: send table payload to API endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'score': [0.8, 0.9]})\n",
    "print(df.to_json(orient='records'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_latex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_latex` renders DataFrame as LaTeX tabular code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `buf`: destination.\n",
    "- `columns`, `header`, `index`, `caption`, `label`, `escape`: formatting options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_latex()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: include result table in scientific report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'metric': ['acc', 'f1'], 'value': [0.91, 0.88]})\n",
    "latex = df.to_latex(index=False)\n",
    "print(latex.splitlines()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_markdown` renders DataFrame as Markdown table text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `buf`: destination.\n",
    "- `mode`, `index`, `tablefmt`: formatting controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting a table into a target format for another system/tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes DataFrame values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method returns serialized object or writes to destination depending on API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip behavior should be validated for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this target format required downstream?\n",
    "- Do you need index/dtype fidelity preserved?\n",
    "- Are optional dependencies installed in runtime environment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_markdown()` when downstream consumers require this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: paste table into README documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'k': ['a', 'b'], 'v': [1, 2]})\n",
    "print(df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_numpy` returns DataFrame values as NumPy ndarray.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dtype`: target dtype.\n",
    "- `copy`: force copy behavior.\n",
    "- `na_value`: replacement for missing values in output array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_numpy()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: feed matrix into NumPy-only routine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "arr = df.to_numpy()\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_orc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_orc` writes DataFrame to Apache ORC format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path`: output file path.\n",
    "- `engine`, `index`, and backend-specific kwargs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_orc()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: export to ORC for columnar analytics ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_orc('data.orc')\n",
    "print('written data.orc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_parquet` writes DataFrame to Parquet columnar format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path`: output path.\n",
    "- `engine`, `compression`, `index`, `partition_cols`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_parquet()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: save dataset for efficient data lake querying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_parquet('data.parquet', index=False)\n",
    "print('written data.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_pickle` serializes DataFrame using Python pickle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path`: output path.\n",
    "- `compression`, `protocol`, `storage_options`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n",
    "- Pickle is unsafe for untrusted inputs and Python-specific.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_pickle()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: persist intermediate pandas object for Python-only reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df.to_pickle('data.pkl')\n",
    "print('written data.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_records` converts DataFrame into NumPy record array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `index`: include index fields.\n",
    "- `column_dtypes`, `index_dtypes`: dtype overrides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_records()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: pass structured rows to legacy NumPy/C interfaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': [1, 2], 'y': [3, 4]})\n",
    "rec = df.to_records(index=False)\n",
    "print(rec.dtype.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_sql` writes DataFrame rows into a SQL table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `name`: table name.\n",
    "- `con`: SQLAlchemy connection/engine.\n",
    "- `if_exists`, `index`, `chunksize`, `dtype`, `method`: load controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_sql()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: load transformed data into warehouse table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///example.db')\n",
    "df = pd.DataFrame({'id': [1, 2], 'val': [10, 20]})\n",
    "df.to_sql('metrics', con=engine, if_exists='replace', index=False)\n",
    "print('written table metrics')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_stata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_stata` exports DataFrame to Stata `.dta` format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path`: output path.\n",
    "- `convert_dates`, `write_index`, `version`, `variable_labels`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_stata()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: share dataset with Stata-based econometrics workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'income': [50000, 60000]})\n",
    "df.to_stata('data.dta', write_index=False)\n",
    "print('written data.dta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_string` returns plain-text table representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `buf`: destination.\n",
    "- `columns`, `index`, `na_rep`, `max_rows`, `max_cols`, `line_width`: formatting controls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_string()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: print stable table snapshot into logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_xarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_xarray` converts DataFrame to xarray Dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No major parameters for base conversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_xarray()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: hand off table to xarray scientific pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'temp': [20, 22], 'humidity': [0.3, 0.4]})\n",
    "ds = df.to_xarray()\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.to_xml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_xml` serializes DataFrame into XML text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `path_or_buffer`: destination.\n",
    "- `index`, `root_name`, `row_name`, `na_rep`, `attr_cols`, `elem_cols`, `parser`: options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like exporting table content into a format required by another system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas serializes values and metadata into target representation.\n",
    "- Output behavior depends on format capabilities and optional engines.\n",
    "- Method either returns serialized object or writes to destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format fidelity depends on dtype support and backend versions.\n",
    "- Path/permission/environment issues can fail writes.\n",
    "- Round-trip validation is recommended for production pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this format required downstream?\n",
    "- Do you need strict index/dtype fidelity?\n",
    "- Are optional dependencies installed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `to_xml()` for format-specific export/interchange workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: export table for legacy XML integration endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': [1, 2], 'status': ['ok', 'fail']})\n",
    "xml = df.to_xml(index=False)\n",
    "print(xml.splitlines()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba0f7f1",
   "metadata": {},
   "source": [
    "## Special Methods (dunder methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Path**\n",
    "- Treat this section as advanced runtime/interoperability behavior.\n",
    "- Use these methods only when integrating with protocol-aware libraries or Python iteration internals.\n",
    "- Goal: understand internals without overusing low-level hooks in daily analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.__dataframe__` (listed as `DataFrame.dataframe`) exposes the DataFrame Interchange Protocol object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `nan_as_null`: null representation hint.\n",
    "- `allow_copy`: allow implementation to copy data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like handing another library a standard adapter to read DataFrame buffers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas returns an interchange protocol object.\n",
    "- Consumer libraries can inspect schema/buffers in a standardized way.\n",
    "- Designed for cross-library interoperability beyond pandas-only APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Less common in everyday analysis code.\n",
    "- Consumer support varies across library versions.\n",
    "- Behavior depends on backend and copy constraints.\n",
    "- Interchange protocol maturity depends on pandas version and consuming library support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you need protocol-level interoperability?\n",
    "- Is consumer library protocol-compatible?\n",
    "- Can zero/low-copy constraints be met?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this when integrating with dataframe-interchange-aware libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: verify protocol object availability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2]})\n",
    "obj = df.__dataframe__()\n",
    "print(type(obj).__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.iter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In plain language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.__iter__` (listed as `DataFrame.iter`) iterates over column labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like reading header names one by one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterating over a DataFrame yields column names, not rows.\n",
    "- Equivalent to iterating over `df.columns`.\n",
    "- Common in simple dynamic column loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Often confused with row iteration.\n",
    "- Python loops can be slow for large-scale operations.\n",
    "- Mutating columns while iterating can cause logic issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you intend column or row iteration?\n",
    "- Can vectorized column operations replace explicit loops?\n",
    "- Is schema stable during iteration?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataFrame iteration when you specifically need column label traversal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: print all column names before type checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a': [1], 'b': [2]})\n",
    "for col in df:\n",
    "    print(col)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
