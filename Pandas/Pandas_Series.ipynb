{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba9e626",
   "metadata": {},
   "source": [
    "### Pandas \n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like Series and DataFrame, which allow for efficient handling of structured data. With Pandas, you can easily perform operations such as filtering, grouping, and aggregating data, making it an essential tool for data scientists and analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b4755",
   "metadata": {},
   "source": [
    "# Importing Pandas\n",
    "To use Pandas in your Python code, you need to import it first. The common convention is to import it as `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "dd5dcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd97dac",
   "metadata": {},
   "source": [
    "# Basic Data Structures in Pandas\n",
    "Pandas provides two primary data structures: Series and DataFrame.\n",
    "- Series: A one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a database table.\n",
    "- DataFrame: A two-dimensional labeled data structure with columns of potentially different types. It is similar to a table in a relational database or a spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "765dda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "dataframe = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': ['a', 'b', 'c']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc84cbe",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f4b8f",
   "metadata": {},
   "source": [
    "When a series is created, it automatically assigns an index to each element. You can also specify your own index if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "819a9fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2826456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070b97a",
   "metadata": {},
   "source": [
    "### When to use a series:\n",
    "- When you have a single column of data that you want to work with.\n",
    "- When you want to perform operations on a single column, such as calculating the mean or sum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0a496",
   "metadata": {},
   "source": [
    "### Methods and Attributes of Series\n",
    "\n",
    "**Core attributes**:\n",
    "- [series.values](#seriesvalues): Returns the underlying data of the series as a NumPy array.\n",
    "- [series.array](#seriesarray): Returns the underlying data as a pandas ExtensionArray (often preferred over `series.values`).\n",
    "- [series.index](#seriesindex): Returns the index of the series.\n",
    "- [series.name](#seriesname): Returns the name of the series.\n",
    "- [series.size](#seriessize): Returns the number of elements in the series.\n",
    "- [series.shape](#seriesshape): Returns the shape of the series as a tuple.\n",
    "- [series.dtype](#seriesdtype): Returns the data type of the series.\n",
    "- [series.ndim](#seriesndim): Returns the number of dimensions of the series (always 1 for a Series).\n",
    "\n",
    "**Data Inspection**:\n",
    "- [series.head(n)](#seriesheadn): Returns the first n elements of the series.\n",
    "- [series.tail(n)](#seriestailn): Returns the last n elements of the series.\n",
    "- [series.describe()](#seriesdescribe): Provides a summary of statistics for the series.\n",
    "- [series.value_counts()](#seriesvalue_counts): Returns a count of unique values in the series.\n",
    "- [series.unique()](#seriesunique): Returns the unique values in the series.\n",
    "- [series.nunique()](#seriesnunique): Returns the number of unique values in the series.\n",
    "- [series.sample(n)](#seriessamplen): Returns a random sample of n elements from the series.\n",
    "- [series.memory_usage()](#seriesmemory_usage): Returns the memory usage of the series.\n",
    "- [series.items()](#seriesitems): Lazily iterates over (index, value) pairs.\n",
    "- [series.keys()](#serieskeys): Alias for `series.index`.\n",
    "\n",
    "**Indexing and Selection**:\n",
    "- [series.loc\\[label\\]](#seriesloclabel): Accesses elements by label.\n",
    "- [series.iloc\\[position\\]](#seriesilocposition): Accesses elements by integer position.\n",
    "- [series.at\\[label\\]](#seriesatlabel): Accesses a single element by label.\n",
    "- [series.iat\\[position\\]](#seriesiatposition): Accesses a single element by integer position.\n",
    "- [series.get(key, default=None)](#seriesgetkey-defaultnone): Returns the value for `key` if it exists, otherwise returns `default`.\n",
    "\n",
    "**Boolean Indexing**:\n",
    "- [series\\[condition\\]](#seriescondition): Returns a series that meets the specified condition.\n",
    "\n",
    "**Aggregation and Reduction**:\n",
    "- [series.sum()](#seriessum): Returns the sum of the series.\n",
    "- [series.mean()](#seriesmean): Returns the mean of the series.\n",
    "- [series.median()](#seriesmedian): Returns the median of the series.\n",
    "- [series.mode()](#seriesmode): Returns the mode(s) of the series.\n",
    "- [series.std()](#seriesstd): Returns the standard deviation of the series.\n",
    "- [series.var()](#seriesvar): Returns the variance of the series.\n",
    "- [series.min()](#seriesmin): Returns the minimum value of the series.\n",
    "- [series.max()](#seriesmax): Returns the maximum value of the series.\n",
    "- [series.count()](#seriescount): Returns the number of non-missing values in the series.\n",
    "- [series.quantile(q)](#seriesquantileq): Returns the q-th quantile of the series.\n",
    "- [series.skew()](#seriesskew): Returns the skewness of the series.\n",
    "- [series.kurt()](#serieskurt): Returns the kurtosis of the series.\n",
    "- [series.prod()](#seriesprod): Returns the product of the series.\n",
    "- [series.sem()](#seriessem): Returns the standard error of the mean of the series.\n",
    "- [series.idxmax()](#seriesidxmax): Returns the index label of the maximum value.\n",
    "- [series.idxmin()](#seriesidxmin): Returns the index label of the minimum value.\n",
    "- [series.corr(other)](#seriescorrother): Computes the correlation between the series and another series.\n",
    "- [series.cov(other)](#seriescovother): Computes the covariance between the series and another series.\n",
    "\n",
    "**Logical and Comparison Operations**:\n",
    "- [series.gt(value)](#seriesgtvalue): Returns a boolean series where elements are greater than the specified value.\n",
    "- [series.ge(value)](#seriesgevalue): Returns a boolean series where elements are greater than or equal to the specified value.\n",
    "- [series.lt(value)](#seriesltvalue): Returns a boolean series where elements are less than the specified value.\n",
    "- [series.le(value)](#serieslevalue): Returns a boolean series where elements are less than or equal to the specified value.\n",
    "- [series.eq(value)](#serieseqvalue): Returns a boolean series where elements are equal to the specified value.\n",
    "- [series.ne(value)](#seriesnevalue): Returns a boolean series where elements are not equal to the specified value.\n",
    "- [series.all()](#seriesall): Returns True if all elements in the series are True.\n",
    "- [series.any()](#seriesany): Returns True if any element in the series is True.\n",
    "- [series.isin(values)](#seriesisinvalues): Returns a boolean series indicating whether each element is in the specified values.\n",
    "- [series.between(left, right)](#seriesbetweenleft-right): Returns a boolean series indicating whether each element is between the left and right values.\n",
    "- [series.equals(other)](#seriesequalsother): Returns True if the series is equal to another series.\n",
    "\n",
    "**Missing Data Handling**:\n",
    "- [series.isna()](#seriesisna): Returns a boolean series indicating missing values.\n",
    "- [series.notna()](#seriesnotna): Returns a boolean series indicating non-missing values.\n",
    "- [series.dropna()](#seriesdropna): Returns a series with missing values removed.\n",
    "- [series.fillna(value)](#seriesfillnavalue): Fills missing values with a specified value.\n",
    "- [series.ffill()](#seriesffill): Fills missing values forward.\n",
    "- [series.bfill()](#seriesbfill): Fills missing values backward.\n",
    "- [series.interpolate()](#seriesinterpolate): Interpolates missing values in the series.\n",
    "\n",
    "**Sorting & Ranking**:\n",
    "- [series.sort_values()](#seriessort_values): Sorts the series by its values.\n",
    "- [series.sort_index()](#seriessort_index): Sorts the series by its index.\n",
    "- [series.rank()](#seriesrank): Returns the rank of each element in the series.\n",
    "- [series.nlargest(n)](#seriesnlargestn): Returns the n largest values in the series.\n",
    "- [series.nsmallest(n)](#seriesnsmallestn): Returns the n smallest values in the series.\n",
    "\n",
    "**Transformation and element-wise operations**:\n",
    "- [series.apply(func)](#seriesapplyfunc): Applies a function to each element of the series.\n",
    "- [series.map(func)](#seriesmapfunc): Maps a function to each element of the series.\n",
    "- [series.astype(dtype)](#seriesastypedtype): Casts the series to a specified data type.\n",
    "- [series.transform(func)](#seriestransformfunc): Applies a function element-wise and returns a Series aligned to the original index (no grouping unless used with `groupby`).\n",
    "- [series.aggregate(func)](#seriesaggregatefunc): Aggregates using one or more functions and returns a scalar or a Series (no grouping unless used with `groupby`).\n",
    "- [series.pipe(func)](#seriespipefunc): Applies a function to the series and returns the result.\n",
    "- [series.replace(to_replace, value)](#seriesreplaceto_replace-value): Replaces specified values in the series with new values.\n",
    "- [series.round(decimals)](#seriesrounddecimals): Rounds the values in the series to a specified number of decimal places.\n",
    "- [series.clip(lower, upper)](#seriescliplower-upper): Clips the values in the series to a specified range.\n",
    "- [series.abs()](#seriesabs): Returns the absolute values of the series.\n",
    "- [series.where(condition)](#serieswherecondition): Returns a series where elements that do not meet the condition are replaced with NaN (or another value).\n",
    "- [series.mask(condition)](#seriesmaskcondition): Returns a series where elements that meet the condition are replaced with NaN (or another value).\n",
    "- [series.copy(deep=True)](#seriescopydeeptrue): Returns a copy of the Series.\n",
    "- [series.drop(labels)](#seriesdroplabels): Drops specified index labels from the Series.\n",
    "- [series.explode()](#seriesexplode): Transforms each element of a list-like into a row (index is duplicated accordingly).\n",
    "- [series.compare(other)](#seriescompareother): Compares with another Series and shows differences.\n",
    "- [series.cumsum()](#seriescumsum): Returns the cumulative sum of the series.\n",
    "- [series.cumprod()](#seriescumprod): Returns the cumulative product of the series.\n",
    "- [series.cummax()](#seriescummax): Returns the cumulative maximum of the series.\n",
    "- [series.cummin()](#seriescummin): Returns the cumulative minimum of the series.\n",
    "- [series.diff(periods=1)](#seriesdiffperiods1): Returns the difference between consecutive elements in the series.\n",
    "- [series.pct_change(periods=1)](#seriespct_changeperiods1): Returns the percentage change between the current and a prior element in the series.\n",
    "- [series.add(other)](#seriesaddother): Adds the series to another series or a scalar value.\n",
    "- [series.sub(other)](#seriessubother): Subtracts another series or a scalar value from the series.\n",
    "- [series.mul(other)](#seriesmulother): Multiplies the series by another series or a scalar value.\n",
    "- [series.div(other)](#seriesdivother): Divides the series by another series or a scalar value.\n",
    "- [series.pow(other)](#seriespowother): Raises the series to the power of another series or a scalar value.\n",
    "- [series.mod(other)](#seriesmodother): Returns the modulus of the series by another series or a scalar value.\n",
    "\n",
    "**Window Operations**:\n",
    "- [series.rolling(window)](#seriesrollingwindow): Provides rolling window calculations on the series.\n",
    "- [series.expanding()](#seriesexpanding): Provides expanding window calculations on the series.\n",
    "- [series.ewm(span=None, com=None, halflife=None, alpha=None, ...)](#seriesewmspan): Provides exponential weighted functions on the series.\n",
    "\n",
    "**Time Series (if the series has a datetime index)**:\n",
    "- [series.resample(rule)](#seriesresamplerule): Resamples time-series data according to a specified frequency.\n",
    "- [series.asfreq(freq)](#seriesasfreqfreq): Converts the series to a specified frequency.\n",
    "- [series.shift(periods)](#seriesshiftperiods1): Shifts the series by a specified number of periods.\n",
    "- [series.diff(periods=1)](#seriesdiffperiods1-1): Returns the difference between the current and a prior element in the series.\n",
    "- [series.pct_change(periods=1)](#seriespct_changeperiods1-1): Returns the percentage change between the current and a prior element in the series.\n",
    "- [series.to_period(freq)](#seriesto_periodfreq): Converts the index to a PeriodIndex with the specified frequency (when applicable).\n",
    "- [series.to_timestamp(freq=None, how=\"start\")](#seriesto_timestampfreqnone-howstart): Converts a PeriodIndex to a DatetimeIndex (when applicable).\n",
    "\n",
    "**Reindexing and Alignment**:\n",
    "- [series.reindex(new_index)](#seriesreindexnew_index): Conforms the series to a new index.\n",
    "- [series.align(other)](#seriesalignother): Aligns the series with another series.\n",
    "- [series.update(other)](#seriesupdateother): Updates the series with values from another series, aligning on the index (in-place).\n",
    "- [series.combine_first(other)](#seriescombine_firstother): Combines the series with another series, filling missing values in the original series with values from the other series.\n",
    "- [series.rename(new_name)](#seriesrenamenew_name): Renames the series (or applies a function to index labels).\n",
    "- [series.rename_axis(new_name)](#seriesrename_axisnew_name): Renames the index of the series.\n",
    "- [series.reset_index()](#seriesreset_index): Resets the index of the series (returns a DataFrame).\n",
    "- [series.set_axis(labels)](#seriesset_axislabels): Sets the axis labels of the series.\n",
    "\n",
    "**Grouping**:\n",
    "- [series.groupby(by=None, level=None, ...)](#seriesgroupbybynone-levelnone): Groups values for split-apply-combine workflows (returns a SeriesGroupBy).\n",
    "\n",
    "**Duplicates**:\n",
    "- [series.duplicated()](#seriesduplicatedkeepfirst): Returns a boolean series indicating duplicate values.\n",
    "- [series.drop_duplicates()](#seriesdrop_duplicates): Returns a series with duplicate values removed.\n",
    "\n",
    "**Conversion Methods**:\n",
    "- [series.to_list()](#seriesto_list): Converts the series to a list.\n",
    "- [series.to_dict()](#seriesto_dict): Converts the series to a dictionary.\n",
    "- [series.to_frame()](#seriesto_frame): Converts the series to a DataFrame.\n",
    "- [series.to_numpy()](#seriesto_numpy): Converts the series to a NumPy array.\n",
    "- [series.to_csv(filename)](#seriesto_csvpath_or_buf): Writes the series to a CSV file.\n",
    "- [series.to_json(filename)](#seriesto_jsonpath_or_buf): Writes the series to a JSON file.\n",
    "- [series.to_excel(filename)](#seriesto_excelexcel_writer): Writes the series to an Excel file.\n",
    "- [series.to_sql(table_name, con)](#seriesto_sqlname-con): Writes the series to a SQL database.\n",
    "- [series.to_string()](#seriesto_string): Converts the series to a string representation.\n",
    "- [series.to_clipboard()](#seriesto_clipboard): Copies the series to the clipboard.\n",
    "- [series.to_pickle(path)](#seriesto_picklepath): Pickle (serialize) the Series to a file.\n",
    "\n",
    "**String accessor methods (if the series contains string data)**:\n",
    "- [series.str.lower()](#seriesstrlower): Converts all string values in the series to lowercase.\n",
    "- [series.str.upper()](#seriesstrupper): Converts all string values in the series to uppercase.\n",
    "- [series.str.title()](#seriesstrtitle): Converts all string values in the series to title case.\n",
    "- [series.str.strip()](#seriesstrstripto_stripnone): Removes leading and trailing whitespace from string values in the series.\n",
    "- [series.str.replace(pat, repl)](#seriesstrreplacepat-repl): Replaces occurrences of a substring/regex pattern in string values with a replacement string.\n",
    "- [series.str.contains(pattern)](#seriesstrcontainspattern): Returns a boolean series indicating whether each string value contains a specified pattern.\n",
    "- [series.str.startswith(prefix)](#seriesstrstartswithprefix): Returns a boolean series indicating whether each string value starts with a specified prefix.\n",
    "- [series.str.endswith(suffix)](#seriesstrendswithsuffix): Returns a boolean series indicating whether each string value ends with a specified suffix.\n",
    "- [series.str.len()](#seriesstrlen): Returns the length of each string value in the series.\n",
    "- [series.str.split(sep)](#seriesstrsplitsep): Splits each string value by a specified separator and returns list-like elements.\n",
    "- [series.str.get(i)](#seriesstrgeti): Returns the i-th element of each list-like string result.\n",
    "- [series.str.join(sep)](#seriesstrjoinsep): Joins the elements of each list-like string using a specified separator.\n",
    "- [series.str.extract(pattern)](#seriesstrextractpattern): Extracts capture groups from each string using a specified regex pattern.\n",
    "- [series.str.findall(pattern)](#seriesstrfindallpattern): Finds all occurrences of a regex pattern in each string and returns list-like matches.\n",
    "\n",
    "**Datetime accessor methods (if the series contains datetime data)**:\n",
    "- [series.dt.year](#seriesdtyear): Returns the year of each datetime value.\n",
    "- [series.dt.month](#seriesdtmonth): Returns the month of each datetime value.\n",
    "- [series.dt.day](#seriesdtday): Returns the day of the month of each datetime value.\n",
    "- [series.dt.hour](#seriesdthour): Returns the hour of each datetime value.\n",
    "- [series.dt.minute](#seriesdtminute): Returns the minute of each datetime value.\n",
    "- [series.dt.second](#seriesdtsecond): Returns the second of each datetime value.\n",
    "- [series.dt.weekday](#seriesdtweekday): Returns the day of the week (0=Monday, 6=Sunday).\n",
    "- [series.dt.isocalendar().week](#seriesdtisocalendar): Returns the ISO week number (preferred over deprecated `weekofyear`).\n",
    "- [series.dt.is_month_start](#seriesdtis_month_start): Returns a boolean series indicating whether each datetime is the first day of the month.\n",
    "- [series.dt.is_month_end](#seriesdtis_month_end): Returns a boolean series indicating whether each datetime is the last day of the month.\n",
    "- [series.dt.is_quarter_start](#seriesdtis_quarter_start): Returns a boolean series indicating whether each datetime is the first day of a quarter.\n",
    "- [series.dt.is_quarter_end](#seriesdtis_quarter_end): Returns a boolean series indicating whether each datetime is the last day of a quarter.\n",
    "- [series.dt.is_year_start](#seriesdtis_year_start): Returns a boolean series indicating whether each datetime is the first day of the year.\n",
    "- [series.dt.is_year_end](#seriesdtis_year_end): Returns a boolean series indicating whether each datetime is the last day of the year.\n",
    "- [series.dt.tz_localize(tz)](#seriesdttz_localizetz): Localizes naive datetimes to a specified time zone.\n",
    "- [series.dt.tz_convert(tz)](#seriesdttz_converttz): Converts timezone-aware datetimes to another time zone.\n",
    "- [series.dt.strftime(format)](#seriesdtstrftimeformat): Formats datetimes according to a format string.\n",
    "- [series.dt.to_period(freq)](#seriesdtto_periodfreq): Converts datetimes to a PeriodIndex representation.\n",
    "- [series.dt.to_timestamp(freq=None, how=\"start\")](#seriesdtto_timestampfreqnone-howstart): Converts period-like datetimes to timestamps (when applicable).\n",
    "- [series.dt.round(freq)](#seriesdtroundfreq): Rounds datetimes to a specified frequency.\n",
    "\n",
    "**Category accessor methods (if the series contains categorical data)**:\n",
    "- [series.cat.categories](#seriescatcategories): Returns the categories of the categorical series.\n",
    "- [series.cat.codes](#seriescatcodes): Returns the category codes of the categorical series.\n",
    "- [series.cat.ordered](#seriescatordered): Returns whether the categorical series is ordered.\n",
    "- [series.cat.add_categories(new_categories)](#seriescatadd_categoriesnew_categories): Adds new categories to the categorical series.\n",
    "- [series.cat.remove_categories(categories)](#seriescatremove_categoriescategories): Removes specified categories from the categorical series.\n",
    "- [series.cat.rename_categories(new_categories)](#seriescatrename_categoriesnew_categories): Renames the categories of the categorical series.\n",
    "- [series.cat.reorder_categories(new_categories)](#seriescatreorder_categoriesnew_categories): Reorders the categories of the categorical series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1fa56",
   "metadata": {},
   "source": [
    "#### Core Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fb906",
   "metadata": {},
   "source": [
    "##### Series.values\n",
    "The `values` attribute of a Pandas Series returns the underlying data of the series as a NumPy array. This can be useful when you want to perform operations that require a NumPy array or when you want to convert the series data into a different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "924416ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "33b27fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51c8aa",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b9c66",
   "metadata": {},
   "source": [
    "`series.values` is the “raw data” inside a pandas Series, returned as a NumPy array (or array-like). You use it when you need to pass the data to code that doesn’t understand pandas, only plain arrays. Ambiguity: people often use values thinking it’s always a NumPy `ndarray`; with some dtypes it may be an object array or an extension-backed array. For strict NumPy, `to_numpy()` is more explicit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51772b27",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8205c82",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.values` to get the underlying array-like values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6ed7b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780dacf",
   "metadata": {},
   "source": [
    "Think of a `Series` as a spreadsheet column with row labels.\n",
    "\n",
    "- The index = the row labels\n",
    "\n",
    "- The values = the cells in the column\n",
    "\n",
    "Some tools only accept “cells” and don’t care about labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53a42b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f81b3b",
   "metadata": {},
   "source": [
    "- Many scientific/ML functions (SciPy, scikit-learn, custom NumPy code, Numba/C extensions) expect a 1D array.\n",
    "\n",
    "- `series.values` strips away pandas metadata (mostly the index) and exposes the underlying data buffer, which those libraries can consume efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f10505",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de99e2",
   "metadata": {},
   "source": [
    "- You lose the index alignment semantics. If you later combine results with another Series, you must be careful because you’re back to “position-based” logic.\n",
    "\n",
    "- With extension dtypes (nullable integers, strings, categoricals, timezone-aware datetimes), values may be object dtype or behave differently than you expect.\n",
    "\n",
    "- If your goal is “give me a NumPy array”, prefer series.to_numpy() (clearer and more predictable). Still, values is common in legacy code and quick prototyping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c9a74",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02bdab",
   "metadata": {},
   "source": [
    "- Are you passing the data to a library that expects a NumPy array (SciPy / scikit-learn / statsmodels / custom C/Numba)?\n",
    "\n",
    "- Do you need to preserve the index meaning (timestamps, IDs), or is position enough?\n",
    "\n",
    "- Is the Series dtype numeric and clean, or does it include missing values / categories / strings?\n",
    "\n",
    "- Do you need a copy of the data, or is a view OK?\n",
    "\n",
    "- Is performance the reason, or compatibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c98efb",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556084b8",
   "metadata": {},
   "source": [
    "Use `series.values` when you need the Series as a plain array for external functions. Keep the index separately if you’ll need to map results back to labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adb92c",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Detect peaks in a time series with SciPy\n",
    "\n",
    "Scenario: you have website traffic per minute (timestamp index) and you want to detect spikes using scipy.signal.find_peaks, which expects an array-like input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e9f0c0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak timestamps: [Timestamp('2026-02-16 09:03:00'), Timestamp('2026-02-16 09:07:00')]\n",
      "Peak values: [40, 35]\n",
      "Peak heights: [40. 35.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Example: traffic per minute with a datetime index\n",
    "s = pd.Series(\n",
    "    [12, 11, 13, 40, 14, 12, 11, 35, 13, 12],\n",
    "    index=pd.date_range(\"2026-02-16 09:00\", periods=10, freq=\"min\"),\n",
    "    name=\"traffic\"\n",
    ")\n",
    "\n",
    "# SciPy expects array-like; use .values to feed it\n",
    "peaks_pos, props = find_peaks(s.values, height=30, distance=2)\n",
    "\n",
    "# Map peak positions back to timestamps using the index\n",
    "peak_times = s.index[peaks_pos]\n",
    "peak_values = s.iloc[peaks_pos]\n",
    "\n",
    "print(\"Peak timestamps:\", list(peak_times))\n",
    "print(\"Peak values:\", list(peak_values))\n",
    "print(\"Peak heights:\", props[\"peak_heights\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188107cb",
   "metadata": {},
   "source": [
    "##### Series.array\n",
    "The `array` attribute returns Series data as a pandas `ExtensionArray`. It preserves pandas-native dtype behavior, including nullable values and dtype-specific rules. Use it when dtype semantics matter more than forcing plain NumPy output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "24a9508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "608d7ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NumpyExtensionArray>\n",
       "[10, 20, 30]\n",
       "Length: 3, dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5327b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf9c4f",
   "metadata": {},
   "source": [
    "`series.array` is the values container with pandas dtype rules intact. It keeps behaviors like `pd.NA` handling that can be altered when converting directly to NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3599e63",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd82b2",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.array` to get the pandas ExtensionArray view of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c98190",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88783f7",
   "metadata": {},
   "source": [
    "Think of a labeled spreadsheet column stored in a special container.\n",
    "\n",
    "- `Series` = labels + container.\n",
    "\n",
    "- `.array` = just the container, still using pandas rules.\n",
    "\n",
    "You get the cells without throwing away the column's data type logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7530f1",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263ba49",
   "metadata": {},
   "source": [
    "- Pandas stores many dtypes using extension arrays (nullable ints, strings, categoricals, timezone-aware datetimes).\n",
    "\n",
    "- `.array` exposes that extension-backed data structure directly.\n",
    "\n",
    "- Because the extension array carries dtype metadata/masks, missing-value behavior stays consistent with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcb9a0",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5932582",
   "metadata": {},
   "source": [
    "- Some external libraries only accept NumPy `ndarray`, not extension arrays.\n",
    "\n",
    "- Returned array class depends on dtype, so behavior is not identical across all Series types.\n",
    "\n",
    "- For heavy numeric computation, NumPy arrays are often faster and more widely supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e819d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d7c38",
   "metadata": {},
   "source": [
    "- Do you need to preserve `pd.NA` semantics exactly?\n",
    "\n",
    "- Does downstream code accept extension arrays, or does it require NumPy?\n",
    "\n",
    "- Is the dtype nullable/categorical/string where conversion could change behavior?\n",
    "\n",
    "- Are you relying on dtype-specific methods from the extension array?\n",
    "\n",
    "- Would `to_numpy()` be simpler for this step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94a912",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d2336",
   "metadata": {},
   "source": [
    "Use `series.array` when you want raw values but still want pandas dtype behavior, especially around missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e129f9",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prepare nullable integer features without losing missing-value meaning.\n",
    "\n",
    "Scenario: a scoring column should stay nullable integer (`Int64`) during feature QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7ab572e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array dtype: Int64\n",
      "Array values: [np.int64(10), <NA>, np.int64(30)]\n",
      "Missing labels: ['cust_b']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = pd.Series(\n",
    "    [10, None, 30],\n",
    "    index=[\"cust_a\", \"cust_b\", \"cust_c\"],\n",
    "    dtype=\"Int64\",\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "arr = scores.array\n",
    "missing_customers = scores.index[scores.isna()]\n",
    "\n",
    "print(\"Array dtype:\", arr.dtype)\n",
    "print(\"Array values:\", list(arr))\n",
    "print(\"Missing labels:\", list(missing_customers))\n",
    "\n",
    "assert str(arr.dtype) == \"Int64\"\n",
    "assert pd.isna(arr[1])\n",
    "assert list(missing_customers) == [\"cust_b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bb7be",
   "metadata": {},
   "source": [
    "##### Series.index\n",
    "The `index` attribute returns the label axis of a pandas Series. These labels drive how pandas aligns data in joins, arithmetic, and reindexing. Checking `series.index` is a fast QA step before any label-based workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0d086",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649a018",
   "metadata": {},
   "source": [
    "`series.index` gives you the row labels, not the values. It returns an immutable `Index` object that you can inspect, compare, and reuse in other pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b048b2",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e969348",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.index` to retrieve row labels (`Index`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "88dc841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e8d9997e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c'], dtype='str')"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae55cde",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b45ccf",
   "metadata": {},
   "source": [
    "Think of a spreadsheet column where every row has a name.\n",
    "\n",
    "- The values are the cell contents.\n",
    "\n",
    "- The index is the row-name strip on the left.\n",
    "\n",
    "When pandas combines data, it matches by those row names first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd20fd",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be17c4d",
   "metadata": {},
   "source": [
    "- A Series stores two linked parts: data values and index labels.\n",
    "\n",
    "- During alignment operations, pandas uses index labels to decide what matches what.\n",
    "\n",
    "- Accessing `.index` exposes the label object, so you can validate or transform labels before downstream operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd9b65",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7b0cd",
   "metadata": {},
   "source": [
    "- Duplicate labels are allowed, so one label lookup may return multiple rows.\n",
    "\n",
    "- Index objects are immutable; you usually replace the full index instead of editing one label in place.\n",
    "\n",
    "- Large object/string indexes can add noticeable memory overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500627b",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533c7c3",
   "metadata": {},
   "source": [
    "- Are these labels unique, or do duplicates exist?\n",
    "\n",
    "- Do labels encode business meaning (IDs, timestamps) that must be preserved?\n",
    "\n",
    "- Are you about to merge/align with another object that expects the same index?\n",
    "\n",
    "- Should you normalize label format first (case, whitespace, prefixes)?\n",
    "\n",
    "- Do you need label order to stay exactly as-is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec904a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8dcfc",
   "metadata": {},
   "source": [
    "Use `series.index` when you need to inspect or validate labels before any operation that depends on alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a677f36",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate expected store IDs before joining daily KPI tables.\n",
    "\n",
    "Scenario: you receive revenue by store and want to catch missing stores before reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "553b39d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index labels: ['store_101', 'store_102', 'store_103']\n",
      "Missing stores: ['store_104']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.Series(\n",
    "    [1200, 980, 1430],\n",
    "    index=[\"store_101\", \"store_102\", \"store_103\"],\n",
    "    name=\"revenue\",\n",
    ")\n",
    "\n",
    "expected_stores = pd.Index([\"store_101\", \"store_102\", \"store_103\", \"store_104\"])\n",
    "missing_stores = expected_stores.difference(revenue.index)\n",
    "\n",
    "print(\"Index labels:\", list(revenue.index))\n",
    "print(\"Missing stores:\", list(missing_stores))\n",
    "\n",
    "assert isinstance(revenue.index, pd.Index)\n",
    "assert \"store_104\" in missing_stores\n",
    "assert revenue.loc[\"store_102\"] == 980"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f47b5f",
   "metadata": {},
   "source": [
    "##### Series.name\n",
    "The `name` attribute stores the label of a Series itself, not the row labels. That label is used in outputs like plots, joins, and DataFrame column names. Setting a clear series name improves readability and prevents ambiguous downstream tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c62935ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "45cc5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476fd05",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28ee20",
   "metadata": {},
   "source": [
    "`series.name` is the title of the whole column. It helps pandas keep a meaningful label when the Series is combined with other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017a920",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd35f7",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.name` to read/set the Series metadata name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636854c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ec2e2",
   "metadata": {},
   "source": [
    "Think of a spreadsheet with one column.\n",
    "\n",
    "- The index is the row labels.\n",
    "\n",
    "- The values are the cells.\n",
    "\n",
    "- The name is the column header at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a5616",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77d140",
   "metadata": {},
   "source": [
    "- A Series carries metadata, and `name` is one metadata field.\n",
    "\n",
    "- When you convert a Series to a DataFrame, pandas uses `name` as the column name.\n",
    "\n",
    "- When combining Series objects, names help identify which metric each result represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da47da",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c4d29",
   "metadata": {},
   "source": [
    "- `name` can be `None`, which may create unnamed or generic columns later.\n",
    "\n",
    "- Reusing the same name for different metrics can make merged outputs confusing.\n",
    "\n",
    "- Renaming a Series does not change index labels or values, only metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eafbdd",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65fc6a",
   "metadata": {},
   "source": [
    "- Is the current Series name meaningful for reporting?\n",
    "\n",
    "- Will this Series be converted to a DataFrame column soon?\n",
    "\n",
    "- Could this name clash with another metric in a merge/concat step?\n",
    "\n",
    "- Do you need to preserve the original name for traceability?\n",
    "\n",
    "- Are you accidentally relying on a default `None` name?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd57e1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ade9d",
   "metadata": {},
   "source": [
    "Use `series.name` to give the entire Series a clear metric label so downstream tables and charts stay readable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c63c75",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Turn a KPI Series into a report-ready DataFrame with a clear column name.\n",
    "\n",
    "Scenario: monthly revenue by region needs a stable metric name before export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "bce2e76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series name: monthly_revenue_usd\n",
      "Report columns: ['monthly_revenue_usd']\n",
      "Top region: West\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.Series(\n",
    "    [12000, 9800, 14300],\n",
    "    index=[\"North\", \"South\", \"West\"],\n",
    "    name=\"monthly_revenue_usd\",\n",
    ")\n",
    "\n",
    "report = revenue.to_frame()\n",
    "top_region = revenue.idxmax()\n",
    "\n",
    "print(\"Series name:\", revenue.name)\n",
    "print(\"Report columns:\", report.columns.tolist())\n",
    "print(\"Top region:\", top_region)\n",
    "\n",
    "assert revenue.name == \"monthly_revenue_usd\"\n",
    "assert report.columns.tolist() == [\"monthly_revenue_usd\"]\n",
    "assert top_region == \"West\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1f6d1",
   "metadata": {},
   "source": [
    "##### Series.size\n",
    "The `size` attribute returns the total number of elements in a Series. Unlike `count()`, it includes missing values. This makes it useful for quick shape checks and missing-data QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b633d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "146de5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cca142",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ef535",
   "metadata": {},
   "source": [
    "`series.size` tells you how many rows are in the Series. It counts every row, even if the value is `NaN` or `pd.NA`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f570f14",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618503ad",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.size` to get total element count (including missing values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb4b60",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512f919",
   "metadata": {},
   "source": [
    "Think of counting rows in a spreadsheet column.\n",
    "\n",
    "- `size` counts all row slots.\n",
    "\n",
    "- `count()` counts only rows with a real value.\n",
    "\n",
    "So `size - count()` gives missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8a919",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bcc62",
   "metadata": {},
   "source": [
    "- A Series stores a fixed-length 1D array plus an index.\n",
    "\n",
    "- `.size` reads that length directly, so it is constant-time and includes nulls.\n",
    "\n",
    "- `count()` applies a non-missing filter first, so it can be smaller than `.size`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff538f38",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bdf28",
   "metadata": {},
   "source": [
    "- `size` does not tell you how many valid observations you have.\n",
    "\n",
    "- Duplicate index labels still count as separate rows.\n",
    "\n",
    "- It is easy to confuse `.size` with `len(series)`; they are equal for Series but differ across other objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468759a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc8505",
   "metadata": {},
   "source": [
    "- Do you need total rows (`size`) or non-missing rows (`count()`)?\n",
    "\n",
    "- Are missing values expected in this metric?\n",
    "\n",
    "- Are duplicate labels inflating your perceived data coverage?\n",
    "\n",
    "- Should this QA check fail if missing rate exceeds a threshold?\n",
    "\n",
    "- Are you checking both row count and index integrity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c2c48",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed7413",
   "metadata": {},
   "source": [
    "Use `series.size` to get total row count fast, then compare with `count()` to quantify missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231efb04",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Monitor daily sensor completeness before computing KPI aggregates.\n",
    "\n",
    "Scenario: you need to know how many readings are present vs missing each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a7ed4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4\n",
      "Valid rows: 3\n",
      "Missing labels: ['sensor_B']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "readings = pd.Series(\n",
    "    [21.5, None, 20.8, 22.1],\n",
    "    index=[\"sensor_A\", \"sensor_B\", \"sensor_C\", \"sensor_D\"],\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "total_rows = readings.size\n",
    "valid_rows = readings.count()\n",
    "missing_labels = readings.index[readings.isna()]\n",
    "\n",
    "print(\"Total rows:\", total_rows)\n",
    "print(\"Valid rows:\", valid_rows)\n",
    "print(\"Missing labels:\", list(missing_labels))\n",
    "\n",
    "assert total_rows == 4\n",
    "assert valid_rows == 3\n",
    "assert list(missing_labels) == [\"sensor_B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb166b",
   "metadata": {},
   "source": [
    "##### Series.shape\n",
    "The `shape` attribute returns the dimensions of a Series as a tuple. For a Series, it always has one element: `(number_of_rows,)`. It is a quick way to verify record count before merges, modeling, or QA checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "97814124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3d3904c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b0c7e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ab6e9",
   "metadata": {},
   "source": [
    "`series.shape` tells you how many items are in the Series, packaged as a tuple like `(5,)`. It is similar to `len(series)`, but in dimensional form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb91413",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03a4bd",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.shape` to get dimensions as a tuple, e.g. `(n,)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd150c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc8e62",
   "metadata": {},
   "source": [
    "Think of a spreadsheet with one column.\n",
    "\n",
    "- `shape` tells you the table size.\n",
    "\n",
    "- For one column, you get only the row count.\n",
    "\n",
    "So `(5,)` means five rows in that single column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b784e5a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2a047",
   "metadata": {},
   "source": [
    "- A Series is a 1D container, so pandas stores one axis length.\n",
    "\n",
    "- `.shape` exposes that length as a tuple to stay consistent with NumPy/pandas objects.\n",
    "\n",
    "- Downstream code can use the tuple to validate expected input size before processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853fd0f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c3db5",
   "metadata": {},
   "source": [
    "- `shape` does not tell you how many values are missing; use `count()` for non-missing rows.\n",
    "\n",
    "- It is easy to forget the trailing comma in `(n,)`, since Series is 1D.\n",
    "\n",
    "- Duplicate index labels do not change `shape`; each row still counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15333c0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722b0f2",
   "metadata": {},
   "source": [
    "- Are you validating total rows or valid (non-null) rows?\n",
    "\n",
    "- Does the pipeline expect an exact row count at this step?\n",
    "\n",
    "- Could filtering earlier have changed shape unexpectedly?\n",
    "\n",
    "- Are duplicate labels hiding data-quality issues despite correct shape?\n",
    "\n",
    "- Do you also need to confirm index labels, not only length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31206942",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec5f68",
   "metadata": {},
   "source": [
    "Use `series.shape` for a fast dimension check before running transformations that assume a specific input size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe244f66",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate that a daily KPI extract has the expected number of rows before publishing.\n",
    "\n",
    "Scenario: a weekday report should include exactly three business days in this mini sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "1d65e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3,)\n",
      "Labels: ['Mon', 'Tue', 'Wed']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "daily_kpi = pd.Series(\n",
    "    [120, 135, 128],\n",
    "    index=[\"Mon\", \"Tue\", \"Wed\"],\n",
    "    name=\"orders\",\n",
    ")\n",
    "\n",
    "actual_shape = daily_kpi.shape\n",
    "expected_rows = 3\n",
    "\n",
    "print(\"Shape:\", actual_shape)\n",
    "print(\"Labels:\", list(daily_kpi.index))\n",
    "\n",
    "assert actual_shape == (3,)\n",
    "assert actual_shape[0] == expected_rows\n",
    "assert daily_kpi.index[actual_shape[0] - 1] == \"Wed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12f5b8",
   "metadata": {},
   "source": [
    "##### Series.dtype\n",
    "The `dtype` attribute shows the data type of values stored in a Series. Checking dtype early helps prevent silent type issues in arithmetic, aggregations, and feature engineering. It is one of the first QA checks when data comes from CSVs or APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "66cbdd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ab0f60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7a515",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed22af",
   "metadata": {},
   "source": [
    "`series.dtype` tells you what kind of values the Series holds (for example `int64`, `float64`, `object`, `datetime64[ns]`). It helps you decide what operations are safe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba64d84",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ba800",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.dtype` to inspect the value data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821a133",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e719add6",
   "metadata": {},
   "source": [
    "Think of a spreadsheet column format.\n",
    "\n",
    "- Number format means math will work directly.\n",
    "\n",
    "- Text format may need cleaning first.\n",
    "\n",
    "`dtype` is the pandas version of checking that format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d161044",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661c55b",
   "metadata": {},
   "source": [
    "- Pandas assigns a dtype based on the values it sees and how data is loaded.\n",
    "\n",
    "- `.dtype` exposes that inferred or explicit type for inspection.\n",
    "\n",
    "- Numeric operations and memory behavior depend on dtype, so correct dtype directly affects correctness and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3105e8b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacb3c2",
   "metadata": {},
   "source": [
    "- Mixed values often become `object`, which can hide numeric problems.\n",
    "\n",
    "- Nullable extension dtypes (like `Int64`) differ from NumPy dtypes (`int64`) in missing-value behavior.\n",
    "\n",
    "- Automatic inference may vary by input source, so explicit conversion is often safer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a27015",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa0779",
   "metadata": {},
   "source": [
    "- Is this dtype what downstream math/model code expects?\n",
    "\n",
    "- Could string contamination force `object` dtype?\n",
    "\n",
    "- Do you need nullable dtypes to preserve missing values?\n",
    "\n",
    "- Should you cast now to avoid repeated conversion later?\n",
    "\n",
    "- Are parsing errors being surfaced or silently coerced?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a770f7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458f914",
   "metadata": {},
   "source": [
    "Use `series.dtype` to confirm value type before analysis, then convert explicitly if the type is not suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a15c6",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Detect non-numeric transaction values before computing totals.\n",
    "\n",
    "Scenario: amounts arrived as text, and one bad token must be identified by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f725f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dtype: object\n",
      "Numeric dtype: float64\n",
      "Invalid labels: ['txn_3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount_raw = pd.Series(\n",
    "    [\"10.5\", \"8.0\", \"bad\", \"12.0\"],\n",
    "    index=[\"txn_1\", \"txn_2\", \"txn_3\", \"txn_4\"],\n",
    "    name=\"amount\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "\n",
    "amount_num = pd.to_numeric(amount_raw, errors=\"coerce\")\n",
    "invalid_labels = amount_raw.index[amount_num.isna()]\n",
    "\n",
    "print(\"Raw dtype:\", amount_raw.dtype)\n",
    "print(\"Numeric dtype:\", amount_num.dtype)\n",
    "print(\"Invalid labels:\", list(invalid_labels))\n",
    "\n",
    "assert str(amount_raw.dtype) == \"object\"\n",
    "assert str(amount_num.dtype) == \"float64\"\n",
    "assert list(invalid_labels) == [\"txn_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bef36",
   "metadata": {},
   "source": [
    "##### Series.ndim\n",
    "The `ndim` attribute returns the number of dimensions of a Series. For Series, this value is always `1` because Series is one-dimensional. It is useful in reusable functions that may receive either Series or DataFrame inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "19c034a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "44665604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075aa20",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be85658",
   "metadata": {},
   "source": [
    "`series.ndim` tells you how many axes the object has. A Series has one axis (rows), so `ndim` is `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca121c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833af51e",
   "metadata": {},
   "source": [
    "- No parameters (attribute access).\n",
    "\n",
    "- Use as `series.ndim` to get number of dimensions (`1` for Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85372548",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49253fab",
   "metadata": {},
   "source": [
    "Imagine data laid out on paper.\n",
    "\n",
    "- A Series is a single line of values with labels: one direction only.\n",
    "\n",
    "- A DataFrame is a grid: rows and columns.\n",
    "\n",
    "`ndim` is the count of those directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc3da9",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b85d38",
   "metadata": {},
   "source": [
    "- Pandas objects expose dimensional metadata for compatibility with NumPy-style APIs.\n",
    "\n",
    "- Series is defined as 1D, so `.ndim` is fixed at `1` regardless of index type or dtype.\n",
    "\n",
    "- Guard clauses can use `.ndim` to reject inputs with unexpected dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55968f2d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a1474",
   "metadata": {},
   "source": [
    "- For Series, `ndim` is always `1`, so it does not provide detail about row count or missing values.\n",
    "\n",
    "- It is a shape/type guard, not a data-quality check.\n",
    "\n",
    "- Confusing `ndim` with `shape` is common; use `shape` when you need size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c536f3",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84103305",
   "metadata": {},
   "source": [
    "- Is your function designed for 1D inputs only?\n",
    "\n",
    "- Could callers pass a DataFrame by mistake?\n",
    "\n",
    "- Do you need to validate row count in addition to dimensions?\n",
    "\n",
    "- Are downstream NumPy operations assuming a 1D vector?\n",
    "\n",
    "- Should input validation fail fast with a clear error message?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f5332",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7bb17",
   "metadata": {},
   "source": [
    "Use `series.ndim` as a fast guard to confirm you are working with a 1D object before vector-style operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc12440",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Add an input validation check in a feature function that expects a single metric Series.\n",
    "\n",
    "Scenario: fail fast if input is not 1D, then continue with label-aware analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e0a14702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 1\n",
      "Peak label: t4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signal = pd.Series(\n",
    "    [0.2, 0.4, 0.1, 0.5],\n",
    "    index=[\"t1\", \"t2\", \"t3\", \"t4\"],\n",
    "    name=\"sensor_signal\",\n",
    ")\n",
    "\n",
    "if signal.ndim != 1:\n",
    "    raise ValueError(\"Expected a 1D Series input\")\n",
    "\n",
    "peak_label = signal.idxmax()\n",
    "\n",
    "print(\"ndim:\", signal.ndim)\n",
    "print(\"Peak label:\", peak_label)\n",
    "\n",
    "assert signal.ndim == 1\n",
    "assert signal.shape == (4,)\n",
    "assert peak_label == \"t4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959374ba",
   "metadata": {},
   "source": [
    "#### Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee1f12",
   "metadata": {},
   "source": [
    "##### Series.head(n)\n",
    "`head(n)` returns the first `n` rows of a Series. It is usually the first inspection step after loading or transforming data. Use it to quickly confirm value patterns and index-label order at the top of the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8476129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ae219609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15779034",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3672d55",
   "metadata": {},
   "source": [
    "`series.head(n)` shows the top part of your Series. If you skip `n`, pandas returns 5 items by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802272d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95244a01",
   "metadata": {},
   "source": [
    "- `n` (`int`, default `5`): number of rows to return from the start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9111febd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fb9d1",
   "metadata": {},
   "source": [
    "Think of scanning the first few cells in a spreadsheet column.\n",
    "\n",
    "- You check whether values look plausible.\n",
    "\n",
    "- You confirm row labels are in expected order.\n",
    "\n",
    "It is a quick top-of-column sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5920d1",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51ba74",
   "metadata": {},
   "source": [
    "- Pandas slices the Series by position from the top (`0` to `n-1`).\n",
    "\n",
    "- The returned object is still a Series and keeps original index labels.\n",
    "\n",
    "- Because only a small slice is produced, this is fast even on large data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321e0c8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a5070",
   "metadata": {},
   "source": [
    "- `head()` can look clean while issues exist deeper in the Series.\n",
    "\n",
    "- If the Series is unsorted, the first rows may not represent earliest business events.\n",
    "\n",
    "- It is inspection, not full validation; add explicit checks when quality matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b974df6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae462c94",
   "metadata": {},
   "source": [
    "- Is index order meaningful for this dataset (time, IDs, rank)?\n",
    "\n",
    "- Do top values and labels match ingestion expectations?\n",
    "\n",
    "- Should you inspect both `head` and `tail` to catch edge issues?\n",
    "\n",
    "- Are there duplicates in early labels that could break alignment later?\n",
    "\n",
    "- Do you also need assert-based QA, not just visual preview?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f38f6",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99320d",
   "metadata": {},
   "source": [
    "Use `head(n)` to quickly preview the beginning of a Series and confirm the top labels/values before deeper analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01697aa7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate the first events in a time-indexed KPI Series before feeding it to a dashboard.\n",
    "\n",
    "Scenario: you want to confirm the earliest timestamps and values were loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "cdd27971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-01 09:00:00    120\n",
      "2026-02-01 09:05:00     98\n",
      "2026-02-01 09:10:00    135\n",
      "Name: visits, dtype: int64\n",
      "Top index labels: [Timestamp('2026-02-01 09:00:00'), Timestamp('2026-02-01 09:05:00'), Timestamp('2026-02-01 09:10:00')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [120, 98, 135, 110, 142],\n",
    "    index=pd.to_datetime([\n",
    "        \"2026-02-01 09:00\",\n",
    "        \"2026-02-01 09:05\",\n",
    "        \"2026-02-01 09:10\",\n",
    "        \"2026-02-01 09:15\",\n",
    "        \"2026-02-01 09:20\",\n",
    "    ]),\n",
    "    name=\"visits\",\n",
    ")\n",
    "\n",
    "top = kpi.head(3)\n",
    "\n",
    "print(top)\n",
    "print(\"Top index labels:\", list(top.index))\n",
    "\n",
    "assert top.shape == (3,)\n",
    "assert top.index[0] == pd.Timestamp(\"2026-02-01 09:00\")\n",
    "assert int(top.iloc[-1]) == 135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac1f30",
   "metadata": {},
   "source": [
    "##### Series.tail(n)\n",
    "`tail(n)` returns the last `n` rows of a Series. It is useful for checking recent records after appends or incremental loads. Use it when the newest labels and values are most important to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "151fc5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "abf9b766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7b2f8",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd09588",
   "metadata": {},
   "source": [
    "`series.tail(n)` shows the bottom part of your Series. If `n` is omitted, pandas returns the last 5 items by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff691e8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54d99d",
   "metadata": {},
   "source": [
    "- `n` (`int`, default `5`): number of rows to return from the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f1e0c23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "1f8b25d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce645f61",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8165bea",
   "metadata": {},
   "source": [
    "Think of checking the last lines of a spreadsheet column.\n",
    "\n",
    "- You confirm the newest entries are present.\n",
    "\n",
    "- You catch truncation or bad final records.\n",
    "\n",
    "It is a quick end-of-column health check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b37b4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54227d36",
   "metadata": {},
   "source": [
    "- Pandas slices by position from the bottom (`len(series)-n` to end).\n",
    "\n",
    "- Returned data remains a Series with original index labels intact.\n",
    "\n",
    "- This small positional slice is efficient and ideal for quick QA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc99dfb",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568579f9",
   "metadata": {},
   "source": [
    "- If index order is not business order, \"last\" may be misleading.\n",
    "\n",
    "- `tail()` does not prove full completeness; middle gaps can still exist.\n",
    "\n",
    "- Visual checks can miss subtle anomalies without explicit assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649f129",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c21b86",
   "metadata": {},
   "source": [
    "- Is the Series sorted the way business users interpret \"latest\"?\n",
    "\n",
    "- Do final labels and values match expected load cutoff?\n",
    "\n",
    "- Should missing latest labels trigger a pipeline alert?\n",
    "\n",
    "- Do you need to compare beginning vs end (`head` vs `tail`)?\n",
    "\n",
    "- Are duplicate labels hiding true sequence problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b35a8d",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db6832",
   "metadata": {},
   "source": [
    "Use `tail(n)` to inspect the end of a Series and confirm the most recent labels/values are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cfb0f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Check latest sensor readings before publishing a near-real-time metric.\n",
    "\n",
    "Scenario: verify that the newest timestamps are present and not stale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "1db806dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 10:15:00    21.5\n",
      "2026-02-10 10:20:00    21.6\n",
      "Name: temp_c, dtype: float64\n",
      "Tail index labels: [Timestamp('2026-02-10 10:15:00'), Timestamp('2026-02-10 10:20:00')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "readings = pd.Series(\n",
    "    [21.0, 21.3, 21.1, 21.5, 21.6],\n",
    "    index=pd.to_datetime([\n",
    "        \"2026-02-10 10:00\",\n",
    "        \"2026-02-10 10:05\",\n",
    "        \"2026-02-10 10:10\",\n",
    "        \"2026-02-10 10:15\",\n",
    "        \"2026-02-10 10:20\",\n",
    "    ]),\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "latest = readings.tail(2)\n",
    "\n",
    "print(latest)\n",
    "print(\"Tail index labels:\", list(latest.index))\n",
    "\n",
    "assert latest.shape == (2,)\n",
    "assert latest.index[0] == pd.Timestamp(\"2026-02-10 10:15\")\n",
    "assert float(latest.iloc[-1]) == 21.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ab738",
   "metadata": {},
   "source": [
    "##### Series.describe\n",
    "`describe()` computes summary statistics for a Series. For numeric Series, it returns count, mean, std, min, quartiles, and max. It is a fast profiling step to understand distribution and detect suspicious values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "cce520de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "fd380f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3.0\n",
       "mean     20.0\n",
       "std      10.0\n",
       "min      10.0\n",
       "25%      15.0\n",
       "50%      20.0\n",
       "75%      25.0\n",
       "max      30.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dbefe",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505553cd",
   "metadata": {},
   "source": [
    "`series.describe()` gives a compact statistical summary of one Series so you can quickly understand central tendency and spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9145837",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405866b",
   "metadata": {},
   "source": [
    "- `percentiles` (`list-like` or `None`, default `None`): additional percentiles to include (e.g. `[0.1, 0.9]`).\n",
    "\n",
    "- `include` (`str`, list-like, or `None`, default `None`): dtype filters; mainly relevant for DataFrame/mixed dtypes.\n",
    "\n",
    "- `exclude` (`str`, list-like, or `None`, default `None`): dtypes to exclude from summary output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e4497",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2046e36",
   "metadata": {},
   "source": [
    "Think of a one-page health report for a single spreadsheet column.\n",
    "\n",
    "- It shows typical values (mean/median).\n",
    "\n",
    "- It shows spread and extremes (quartiles/min/max).\n",
    "\n",
    "You quickly see if the column looks normal or risky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6be8b2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc38d5e",
   "metadata": {},
   "source": [
    "- Pandas applies predefined aggregations to the Series values.\n",
    "\n",
    "- Missing values are excluded from numeric summary calculations.\n",
    "\n",
    "- Output is a Series indexed by statistic names, which supports direct programmatic checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d3a4b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf84501",
   "metadata": {},
   "source": [
    "- Summary stats can hide multimodal patterns and time effects.\n",
    "\n",
    "- Mean/std are sensitive to outliers.\n",
    "\n",
    "- Non-numeric Series return different summary fields, so interpretation depends on dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d219c03",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7001b1",
   "metadata": {},
   "source": [
    "- Is this Series numeric, and does that match your intended analysis?\n",
    "\n",
    "- Do count values reveal missing-data issues?\n",
    "\n",
    "- Are min/max values plausible for business rules?\n",
    "\n",
    "- Should you supplement with robust checks (median/IQR-based)?\n",
    "\n",
    "- Are you validating by labels after detecting suspicious extremes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb31ee7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d11a37",
   "metadata": {},
   "source": [
    "Use `series.describe()` for a fast statistical snapshot, then investigate any suspicious ranges with targeted rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840addb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Profile session duration before feature engineering for churn modeling.\n",
    "\n",
    "Scenario: verify average and max session length before scaling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "578319d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     5.0\n",
      "mean     42.0\n",
      "50%      40.0\n",
      "max      60.0\n",
      "Name: session_length_min, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "session_minutes = pd.Series(\n",
    "    [30, 45, 60, 40, 35],\n",
    "    index=[\"u1\", \"u2\", \"u3\", \"u4\", \"u5\"],\n",
    "    name=\"session_length_min\",\n",
    ")\n",
    "\n",
    "stats = session_minutes.describe()\n",
    "print(stats[[\"count\", \"mean\", \"50%\", \"max\"]])\n",
    "\n",
    "assert float(stats[\"count\"]) == 5.0\n",
    "assert round(float(stats[\"mean\"]), 2) == 42.0\n",
    "assert float(stats[\"max\"]) == 60.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895d10c",
   "metadata": {},
   "source": [
    "##### Series.value_counts\n",
    "`value_counts()` counts how many times each distinct value appears in a Series. It is one of the fastest ways to inspect categorical distributions and class imbalance. The result is a Series where the index is the observed value and the value is its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "c6f1de79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "bffb643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    1\n",
       "20    1\n",
       "30    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40994a7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787528c",
   "metadata": {},
   "source": [
    "`series.value_counts()` answers: \"How many times does each value occur?\" By default, it sorts counts descending and ignores missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb43944",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33477f3b",
   "metadata": {},
   "source": [
    "- `normalize` (`bool`, default `False`): return proportions instead of raw counts.\n",
    "\n",
    "- `sort` (`bool`, default `True`): sort by counts (if `False`, keep value order behavior).\n",
    "\n",
    "- `ascending` (`bool`, default `False`): sort counts low-to-high when `True`.\n",
    "\n",
    "- `bins` (`int` or `None`, default `None`): group numeric data into interval bins before counting.\n",
    "\n",
    "- `dropna` (`bool`, default `True`): exclude missing values unless set to `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beff6c9",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad658d12",
   "metadata": {},
   "source": [
    "Think of tallying responses in a survey column.\n",
    "\n",
    "- Each distinct response becomes a row in the tally.\n",
    "\n",
    "- The number beside it is how often it appears.\n",
    "\n",
    "You immediately see the most common and rare categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d70e1",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e2589",
   "metadata": {},
   "source": [
    "- Pandas groups identical values together and computes group sizes.\n",
    "\n",
    "- The output index stores distinct values; output values store frequencies.\n",
    "\n",
    "- Sorting by count helps prioritize dominant categories in inspection and QA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376da7f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1302a",
   "metadata": {},
   "source": [
    "- Missing values are excluded unless `dropna=False`.\n",
    "\n",
    "- High-cardinality columns can produce very long outputs.\n",
    "\n",
    "- Default sorting by frequency can hide natural order (time/order-defined categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ebe86",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024cfca0",
   "metadata": {},
   "source": [
    "- Are missing values important enough to include with `dropna=False`?\n",
    "\n",
    "- Is class imbalance acceptable for your downstream model/report?\n",
    "\n",
    "- Do you need normalized proportions instead of raw counts?\n",
    "\n",
    "- Is category cardinality too large for direct display?\n",
    "\n",
    "- Should categories be standardized before counting (case/spacing)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca74df",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac193b98",
   "metadata": {},
   "source": [
    "Use `value_counts()` to quickly profile category frequency and spot imbalance or unexpected values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0001b6",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Audit customer order channels before campaign allocation.\n",
    "\n",
    "Scenario: count channel usage and confirm the most frequent channel labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3d9b9431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'web': 3, 'store': 2, 'app': 1}\n",
      "Top channel: web\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "channel = pd.Series(\n",
    "    [\"web\", \"store\", \"web\", \"app\", \"web\", \"store\"],\n",
    "    index=[\"o1\", \"o2\", \"o3\", \"o4\", \"o5\", \"o6\"],\n",
    "    name=\"order_channel\",\n",
    ")\n",
    "\n",
    "counts = channel.value_counts()\n",
    "\n",
    "print(\"Counts:\", counts.to_dict())\n",
    "print(\"Top channel:\", counts.index[0])\n",
    "\n",
    "assert counts.loc[\"web\"] == 3\n",
    "assert counts.loc[\"store\"] == 2\n",
    "assert counts.index[0] == \"web\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3c982",
   "metadata": {},
   "source": [
    "##### Series.unique\n",
    "`unique()` returns the distinct values in a Series, keeping first-seen order. It is useful when you need the set of observed categories without counting them. This helps quick domain checks before encoding, mapping, or validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "1176074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1a76cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d80cfc",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3487c3f",
   "metadata": {},
   "source": [
    "`series.unique()` gives one copy of each value present in the Series. Unlike sorting-based approaches, it keeps the order values first appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b614d48",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78941657",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Returns distinct values in first-seen order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d0b9f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcad72",
   "metadata": {},
   "source": [
    "Imagine reading a column top-to-bottom and writing each new label only once.\n",
    "\n",
    "- First time you see a value, keep it.\n",
    "\n",
    "- If you see it again, skip it.\n",
    "\n",
    "The final list is your unique values in encounter order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606f908",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c396b8",
   "metadata": {},
   "source": [
    "- Pandas scans values and tracks which ones have already been seen.\n",
    "\n",
    "- New unseen values are appended to the result in arrival order.\n",
    "\n",
    "- The returned array-like object contains distinct values only, without frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe8a9a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd951a44",
   "metadata": {},
   "source": [
    "- Result type is array-like (often NumPy array), not a Series with index labels.\n",
    "\n",
    "- It does not provide counts; pair with `value_counts()` when frequency matters.\n",
    "\n",
    "- Missing-value representation can vary by dtype (`NaN` vs `pd.NA`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568b49e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d29a24",
   "metadata": {},
   "source": [
    "- Do you need only distinct values, or also their frequencies?\n",
    "\n",
    "- Does first-seen order matter for your downstream mapping?\n",
    "\n",
    "- Should missing values be cleaned before uniqueness checks?\n",
    "\n",
    "- Are category labels standardized (case/spaces) before calling `unique()`?\n",
    "\n",
    "- Is the column high-cardinality, requiring sampling or filtering first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e25e11",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c819c8",
   "metadata": {},
   "source": [
    "Use `unique()` to quickly list the distinct values that appear in a Series, in the order they first occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84209ed1",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate allowed shipment statuses in an operations pipeline.\n",
    "\n",
    "Scenario: list observed statuses and map each one to the first row label where it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "a21f3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['packed', 'shipped', 'delivered']\n",
      "First-seen labels: {'r1': 'packed', 'r2': 'shipped', 'r4': 'delivered'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "status = pd.Series(\n",
    "    [\"packed\", \"shipped\", \"packed\", \"delivered\", \"shipped\"],\n",
    "    index=[\"r1\", \"r2\", \"r3\", \"r4\", \"r5\"],\n",
    "    name=\"shipment_status\",\n",
    ")\n",
    "\n",
    "u = status.unique()\n",
    "first_seen = status[~status.duplicated()]\n",
    "\n",
    "print(\"Unique values:\", u.tolist())\n",
    "print(\"First-seen labels:\", first_seen.to_dict())\n",
    "\n",
    "assert u.tolist() == [\"packed\", \"shipped\", \"delivered\"]\n",
    "assert list(first_seen.index) == [\"r1\", \"r2\", \"r4\"]\n",
    "assert first_seen.loc[\"r4\"] == \"delivered\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05296c91",
   "metadata": {},
   "source": [
    "##### Series.nunique\n",
    "`nunique()` returns the number of distinct values in a Series. It is useful for cardinality checks in feature engineering and data-quality monitoring. By default, missing values are excluded from the unique count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e0fbb310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7ea35931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48330e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebb066",
   "metadata": {},
   "source": [
    "`series.nunique()` tells you how many different values exist. It is the count-version of `unique()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e767f",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44efb03",
   "metadata": {},
   "source": [
    "- `dropna` (`bool`, default `True`): exclude missing values from unique count; set `False` to include them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d68d1",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718db7e",
   "metadata": {},
   "source": [
    "Think of counting how many distinct labels appear in a spreadsheet column.\n",
    "\n",
    "- You do not care how often each label appears.\n",
    "\n",
    "- You only care how many different labels exist.\n",
    "\n",
    "That number is the column cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ae785",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786a872",
   "metadata": {},
   "source": [
    "- Pandas identifies distinct values and returns their count as an integer.\n",
    "\n",
    "- With `dropna=True` (default), missing values are ignored in that count.\n",
    "\n",
    "- Setting `dropna=False` includes missing as an extra distinct category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350c077",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c5b04",
   "metadata": {},
   "source": [
    "- Default behavior excludes missing values, which can hide data-quality issues.\n",
    "\n",
    "- Very high cardinality may signal noisy IDs or uncleaned free text.\n",
    "\n",
    "- String formatting inconsistencies (case/whitespace) can inflate unique counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3458cb9",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e414246",
   "metadata": {},
   "source": [
    "- Should missing values be included with `dropna=False`?\n",
    "\n",
    "- Is the observed cardinality expected for this business field?\n",
    "\n",
    "- Could formatting issues be creating fake extra categories?\n",
    "\n",
    "- Are you tracking cardinality drift over time?\n",
    "\n",
    "- Does downstream modeling need capped or encoded categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80819599",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f559c5",
   "metadata": {},
   "source": [
    "Use `nunique()` to measure how many distinct values a Series has, then decide if that cardinality is healthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69764667",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Monitor product-category cardinality in a daily ingestion job.\n",
    "\n",
    "Scenario: compare unique-category count with and without missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ff2a45b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique(dropna=True): 3\n",
      "nunique(dropna=False): 4\n",
      "Missing labels: ['p4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "category = pd.Series(\n",
    "    [\"A\", \"B\", \"A\", None, \"C\", \"B\"],\n",
    "    index=[\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\"],\n",
    "    name=\"product_category\",\n",
    ")\n",
    "\n",
    "n_without_na = category.nunique()\n",
    "n_with_na = category.nunique(dropna=False)\n",
    "missing_labels = category.index[category.isna()]\n",
    "\n",
    "print(\"nunique(dropna=True):\", n_without_na)\n",
    "print(\"nunique(dropna=False):\", n_with_na)\n",
    "print(\"Missing labels:\", list(missing_labels))\n",
    "\n",
    "assert n_without_na == 3\n",
    "assert n_with_na == 4\n",
    "assert list(missing_labels) == [\"p4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4b863",
   "metadata": {},
   "source": [
    "##### Series.sample(n)\n",
    "`sample()` returns a random subset of rows from a Series. It is useful for fast spot-checks, QA, and small manual reviews without scanning the full data. Use `random_state` to keep results reproducible across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "709c9729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "9a885524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sample(2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc349b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec65f6",
   "metadata": {},
   "source": [
    "`series.sample(n)` picks `n` random labeled rows from the Series. With a fixed `random_state`, you get the same sample every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcf3d1",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e88236",
   "metadata": {},
   "source": [
    "- `n` (`int` or `None`, default `None`): number of rows to sample.\n",
    "\n",
    "- `frac` (`float` or `None`, default `None`): fraction of rows to sample (mutually exclusive with `n`).\n",
    "\n",
    "- `replace` (`bool`, default `False`): sample with replacement when `True`.\n",
    "\n",
    "- `weights` (array-like, `str`, or `None`, default `None`): sampling probabilities.\n",
    "\n",
    "- `random_state` (`int`, `np.random.RandomState`, or `None`): seed/state for reproducible sampling.\n",
    "\n",
    "- `axis` (`0` or `'index'`, optional): axis to sample (for Series, row axis).\n",
    "\n",
    "- `ignore_index` (`bool`, default `False`): reset sampled result index to `0..n-1` when `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e81cc",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0839d",
   "metadata": {},
   "source": [
    "Think of drawing a few random entries from a spreadsheet column.\n",
    "\n",
    "- You do not read every row.\n",
    "\n",
    "- You inspect a small, random subset quickly.\n",
    "\n",
    "It helps detect obvious data issues early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500c126",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7926f9a0",
   "metadata": {},
   "source": [
    "- Pandas randomly selects row positions (or a fraction with `frac`).\n",
    "\n",
    "- Selected rows are returned as a Series, preserving original index labels.\n",
    "\n",
    "- `random_state` seeds the RNG so the same input yields repeatable samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf80a1",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f04628",
   "metadata": {},
   "source": [
    "- Without `random_state`, sampled rows change each run.\n",
    "\n",
    "- Small samples can miss rare but important edge cases.\n",
    "\n",
    "- Sampling with replacement (`replace=True`) can duplicate labels in output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe23a77",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662bfab9",
   "metadata": {},
   "source": [
    "- Do you need reproducible sampling for debugging?\n",
    "\n",
    "- Is the sample size large enough for your QA goal?\n",
    "\n",
    "- Should sampling be stratified instead of fully random?\n",
    "\n",
    "- Are duplicate sampled rows acceptable (`replace=True`)?\n",
    "\n",
    "- Are you preserving sampled labels for follow-up investigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeddca1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cccda",
   "metadata": {},
   "source": [
    "Use `sample()` to inspect a quick random slice of a Series while keeping index labels and reproducibility controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6618f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Take a reproducible QA sample of customer transaction amounts.\n",
    "\n",
    "Scenario: analysts review a few random records and need original transaction IDs for follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "799e73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txn_4     60.0\n",
      "txn_6     95.0\n",
      "txn_1    120.5\n",
      "Name: amount, dtype: float64\n",
      "Sample labels: ['txn_4', 'txn_6', 'txn_1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount = pd.Series(\n",
    "    [120.5, 80.0, 150.0, 60.0, 200.0, 95.0],\n",
    "    index=[\"txn_1\", \"txn_2\", \"txn_3\", \"txn_4\", \"txn_5\", \"txn_6\"],\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "qa_sample = amount.sample(n=3, random_state=7)\n",
    "\n",
    "print(qa_sample)\n",
    "print(\"Sample labels:\", list(qa_sample.index))\n",
    "\n",
    "assert len(qa_sample) == 3\n",
    "assert qa_sample.index.isin(amount.index).all()\n",
    "assert qa_sample.name == \"amount\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa4565",
   "metadata": {},
   "source": [
    "##### Series.memory_usage\n",
    "`memory_usage()` reports how many bytes a Series uses in memory. It helps estimate footprint when optimizing pipelines or debugging memory spikes. Use `deep=True` for more accurate accounting with object/string data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "d2df2b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "8e1bd331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd98ed",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4f75a",
   "metadata": {},
   "source": [
    "`series.memory_usage()` tells you how much RAM the Series consumes. You can include or exclude index memory and request deep estimation for object data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1baa36",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d183d9",
   "metadata": {},
   "source": [
    "- `index` (`bool`, default `True`): include index memory in total bytes.\n",
    "\n",
    "- `deep` (`bool`, default `False`): do deeper introspection for object/string memory estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd53a6f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ae6fd",
   "metadata": {},
   "source": [
    "Think of checking storage size for a spreadsheet column in memory.\n",
    "\n",
    "- Values take space.\n",
    "\n",
    "- Row labels (index) also take space.\n",
    "\n",
    "`memory_usage()` measures both depending on options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67053d59",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efde16",
   "metadata": {},
   "source": [
    "- Pandas sums the bytes used by the Series data buffer.\n",
    "\n",
    "- With `index=True`, index storage is added to the total.\n",
    "\n",
    "- With `deep=True`, pandas inspects Python object contents for more realistic string/object estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f29dd2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df3c9a",
   "metadata": {},
   "source": [
    "- `deep=False` can underestimate object/string memory.\n",
    "\n",
    "- Reported bytes are estimates, not full process-level memory usage.\n",
    "\n",
    "- Index type strongly affects totals; RangeIndex is much cheaper than object indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faf159",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6cfcc",
   "metadata": {},
   "source": [
    "- Do you need index memory included for this analysis?\n",
    "\n",
    "- Are strings/objects present, requiring `deep=True`?\n",
    "\n",
    "- Is index design inflating memory unexpectedly?\n",
    "\n",
    "- Should dtype conversion reduce memory safely?\n",
    "\n",
    "- Are you measuring one Series or full pipeline objects?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d38ca",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda6484",
   "metadata": {},
   "source": [
    "Use `memory_usage()` to quantify Series footprint and decide whether index/dtype changes are worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c71956",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Estimate memory overhead of string-heavy ID columns in an ETL step.\n",
    "\n",
    "Scenario: compare memory with and without index to understand where bytes are spent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c08a541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with index: 432\n",
      "without index: 216\n",
      "index only: 216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "customer_id = pd.Series(\n",
    "    [\"A-100\", \"B-220\", \"A-100\", \"C-330\"],\n",
    "    index=[\"row_1\", \"row_2\", \"row_3\", \"row_4\"],\n",
    "    name=\"customer_id\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "\n",
    "bytes_with_index = customer_id.memory_usage(index=True, deep=True)\n",
    "bytes_without_index = customer_id.memory_usage(index=False, deep=True)\n",
    "index_bytes = customer_id.index.memory_usage(deep=True)\n",
    "\n",
    "print(\"with index:\", bytes_with_index)\n",
    "print(\"without index:\", bytes_without_index)\n",
    "print(\"index only:\", index_bytes)\n",
    "\n",
    "assert bytes_with_index >= bytes_without_index > 0\n",
    "assert bytes_with_index - bytes_without_index == index_bytes\n",
    "assert customer_id.index[2] == \"row_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb41fb",
   "metadata": {},
   "source": [
    "##### Series.items\n",
    "`items()` iterates through a Series as `(index, value)` pairs. It is useful when you need explicit label-value loops for custom logic, reporting, or rule checks. This keeps label context attached to each value during iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "458c6249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "021c70f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 10), ('b', 20), ('c', 30)]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(series.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11dbe7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c89ddc",
   "metadata": {},
   "source": [
    "`series.items()` gives you each row as `(label, value)`. It is the direct way to loop with both index and value together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01350595",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcc62a",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Returns an iterator of `(index_label, value)` pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25263ed2",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2717b",
   "metadata": {},
   "source": [
    "Think of reading a spreadsheet column row by row and saying both the row name and cell value aloud.\n",
    "\n",
    "- Label tells you which entity it is.\n",
    "\n",
    "- Value tells you the measurement.\n",
    "\n",
    "Together they enable targeted rule logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09518c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bedba",
   "metadata": {},
   "source": [
    "- Pandas yields one tuple per row in index order.\n",
    "\n",
    "- Each tuple contains the index label first and the value second.\n",
    "\n",
    "- Because iteration is Python-level, it is best for small control-flow tasks, not heavy vectorized computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f4e0c",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d449878",
   "metadata": {},
   "source": [
    "- Iteration is slower than vectorized pandas operations on large Series.\n",
    "\n",
    "- Duplicate labels can make downstream dictionary-based logic ambiguous.\n",
    "\n",
    "- Converting entire iterator to a list can use extra memory for big Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d318067",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b427398",
   "metadata": {},
   "source": [
    "- Do you truly need row-wise control flow, or can you vectorize?\n",
    "\n",
    "- Are labels unique for your downstream lookup logic?\n",
    "\n",
    "- Is preserving index order important for this loop?\n",
    "\n",
    "- Could list conversion of iterator be too memory-heavy?\n",
    "\n",
    "- Are you logging enough context when a rule fails?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820afc46",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f8e51",
   "metadata": {},
   "source": [
    "Use `items()` when you need to loop through a Series with both labels and values for small, custom checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8cac5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Flag sensor readings above a threshold while keeping sensor IDs in the result.\n",
    "\n",
    "Scenario: produce an alert list of `(sensor_id, reading)` pairs for operations review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "4897d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alerts: [('sensor_B', 82.5), ('sensor_D', 91.2)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "readings = pd.Series(\n",
    "    [67.0, 82.5, 74.0, 91.2],\n",
    "    index=[\"sensor_A\", \"sensor_B\", \"sensor_C\", \"sensor_D\"],\n",
    "    name=\"pressure\",\n",
    ")\n",
    "\n",
    "threshold = 80\n",
    "alerts = [(sid, val) for sid, val in readings.items() if val > threshold]\n",
    "\n",
    "print(\"Alerts:\", alerts)\n",
    "\n",
    "assert alerts == [(\"sensor_B\", 82.5), (\"sensor_D\", 91.2)]\n",
    "assert all(sid in readings.index for sid, _ in alerts)\n",
    "assert len(alerts) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f8a76",
   "metadata": {},
   "source": [
    "##### Series.keys\n",
    "`keys()` returns the index labels of a Series (same idea as `.index`). It is commonly used for API symmetry with dictionaries and DataFrames. In practice, it is a label-inspection tool for validation and alignment checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "2d8c12d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d773b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c'], dtype='str')"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bb9a7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542923f",
   "metadata": {},
   "source": [
    "`series.keys()` gives the row labels of the Series. For Series, it is effectively an alias for `series.index`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c76f5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440155b",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Alias for `series.index`; returns the index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc8397",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56911fde",
   "metadata": {},
   "source": [
    "Think of listing all row names in a spreadsheet column.\n",
    "\n",
    "- The keys are the row identifiers.\n",
    "\n",
    "- Values are stored separately in cells.\n",
    "\n",
    "You can use keys to confirm expected entities are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c5c53",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01e1db",
   "metadata": {},
   "source": [
    "- A Series stores an index object for label alignment.\n",
    "\n",
    "- `keys()` returns that index object directly.\n",
    "\n",
    "- This makes label checks easy before merges, reindexing, or dictionary-like lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca1329",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae11d0",
   "metadata": {},
   "source": [
    "- `keys()` and `.index` are redundant for Series, so using both can be noisy.\n",
    "\n",
    "- Duplicate keys are allowed and may break assumptions of uniqueness.\n",
    "\n",
    "- Keys alone do not validate value quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538c4cf",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e72b35",
   "metadata": {},
   "source": [
    "- Are the keys unique and aligned with business IDs?\n",
    "\n",
    "- Are expected labels missing before a merge/reindex step?\n",
    "\n",
    "- Do you need label order preserved exactly?\n",
    "\n",
    "- Would `.index` be clearer in your team style guide?\n",
    "\n",
    "- Are you validating both labels and values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17fb10",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846352f",
   "metadata": {},
   "source": [
    "Use `keys()` to inspect Series labels quickly, especially when writing dictionary-style validation logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141342e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Check whether all expected KPI IDs exist before report assembly.\n",
    "\n",
    "Scenario: compare expected labels with actual keys and list missing IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "57720b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['kpi_101', 'kpi_102', 'kpi_103']\n",
      "Missing: ['kpi_104']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [0.84, 0.79, 0.91],\n",
    "    index=[\"kpi_101\", \"kpi_102\", \"kpi_103\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "expected = pd.Index([\"kpi_101\", \"kpi_102\", \"kpi_103\", \"kpi_104\"])\n",
    "missing = expected.difference(kpi.keys())\n",
    "\n",
    "print(\"Keys:\", list(kpi.keys()))\n",
    "print(\"Missing:\", list(missing))\n",
    "\n",
    "assert kpi.keys().equals(kpi.index)\n",
    "assert list(missing) == [\"kpi_104\"]\n",
    "assert kpi.loc[\"kpi_103\"] == 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47351a1",
   "metadata": {},
   "source": [
    "#### Indexing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654907d",
   "metadata": {},
   "source": [
    "##### Series.loc[label]\n",
    "`loc` is the label-based indexer for a Series. You use it when labels (IDs, timestamps, codes) carry business meaning and must drive selection. It supports single labels, label lists, label slices, and boolean masks aligned by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d242ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "dede76a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.loc['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9707f",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ec48c",
   "metadata": {},
   "source": [
    "`series.loc[...]` selects rows by label name, not by numeric position. If your index is meaningful, `loc` is usually the safest accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3483649",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e4571",
   "metadata": {},
   "source": [
    "- `label` (`scalar`): select one index label.\n",
    "\n",
    "- `labels` (`list-like`): select multiple labels in requested order.\n",
    "\n",
    "- `label_slice` (`start:stop`): label-based slice, inclusive of both ends when labels exist.\n",
    "\n",
    "- `mask/callable`: boolean mask aligned on index, or callable returning a valid `loc` indexer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e1111",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d93442",
   "metadata": {},
   "source": [
    "Think of a spreadsheet where each row has a name.\n",
    "\n",
    "- With `loc`, you ask for rows by those names.\n",
    "\n",
    "- You are not counting row positions.\n",
    "\n",
    "You are selecting by label identity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da136f27",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c992c",
   "metadata": {},
   "source": [
    "- Pandas resolves your selector against the Series index labels.\n",
    "\n",
    "- Matching labels are returned with their original index/value pairing.\n",
    "\n",
    "- Because alignment is label-driven, this reduces position-based mistakes in joins and QA logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be8f63",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709bcaa",
   "metadata": {},
   "source": [
    "- Missing labels raise `KeyError` unless handled explicitly.\n",
    "\n",
    "- Duplicate labels can return multiple rows when you expected one.\n",
    "\n",
    "- Integer-like labels can be confused with positional logic; `loc` still treats them as labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d50aa1",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93bb5b",
   "metadata": {},
   "source": [
    "- Are labels unique for this Series?\n",
    "\n",
    "- Should missing labels fail loudly or be tolerated?\n",
    "\n",
    "- Are you selecting by business ID or by row position?\n",
    "\n",
    "- Do you need label order preserved in output?\n",
    "\n",
    "- Are label slices intended to be inclusive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d752e008",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831a3a1",
   "metadata": {},
   "source": [
    "Use `loc` whenever labels matter, so selection stays tied to real IDs/timestamps instead of row number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b2bdc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Select priority customer IDs for manual risk review.\n",
    "\n",
    "Scenario: analysts provide a label list and need scores in that exact label order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f9fc5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority scores: {'cust_104': 0.91, 'cust_101': 0.82}\n",
      "Single label score: 0.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "risk = pd.Series(\n",
    "    [0.82, 0.31, 0.67, 0.91],\n",
    "    index=[\"cust_101\", \"cust_102\", \"cust_103\", \"cust_104\"],\n",
    "    name=\"risk_score\",\n",
    ")\n",
    "\n",
    "priority_ids = [\"cust_104\", \"cust_101\"]\n",
    "priority_scores = risk.loc[priority_ids]\n",
    "single_score = risk.loc[\"cust_103\"]\n",
    "\n",
    "print(\"Priority scores:\", priority_scores.to_dict())\n",
    "print(\"Single label score:\", single_score)\n",
    "\n",
    "assert list(priority_scores.index) == priority_ids\n",
    "assert float(single_score) == 0.67\n",
    "assert float(priority_scores.loc[\"cust_104\"]) == 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a93274",
   "metadata": {},
   "source": [
    "##### Series.iloc[position]\n",
    "`iloc` is the integer-position indexer for a Series. You use it when row order matters and you want positional selection independent of label names. It supports integer scalars, lists, and Python slicing rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b3a86396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "1a52d82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3779e6b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca5226",
   "metadata": {},
   "source": [
    "`series.iloc[...]` selects rows by numeric position (`0`, `1`, `2`, ...). It ignores index labels and uses row order only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cef34",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6cf902",
   "metadata": {},
   "source": [
    "- `position` (`int`): select one row by zero-based position.\n",
    "\n",
    "- `positions` (`list-like` of `int`): select multiple positions in given order.\n",
    "\n",
    "- `position_slice` (`start:stop`): positional slice with stop-exclusive behavior.\n",
    "\n",
    "- `mask/callable`: boolean positional mask or callable returning a valid `iloc` indexer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438df94",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e616a5",
   "metadata": {},
   "source": [
    "Think of saying \"give me row 2\" in a table preview.\n",
    "\n",
    "- You are counting rows from the top.\n",
    "\n",
    "- Row names do not affect selection.\n",
    "\n",
    "It is pure position-based access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be9f98",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d17fc",
   "metadata": {},
   "source": [
    "- Pandas maps your indexer to row offsets in the underlying 1D data buffer.\n",
    "\n",
    "- Output preserves original labels for selected rows, even though selection was positional.\n",
    "\n",
    "- Slice semantics follow Python/NumPy conventions (end excluded)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c48495",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc1e46",
   "metadata": {},
   "source": [
    "- Out-of-bounds integer access raises `IndexError`.\n",
    "\n",
    "- Reordering or filtering upstream changes positions, which can silently change meaning.\n",
    "\n",
    "- `iloc` can be risky when business logic depends on stable IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7800f",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa1c9c",
   "metadata": {},
   "source": [
    "- Is position the correct business logic, or should labels drive access?\n",
    "\n",
    "- Could prior filtering/sorting change row positions unexpectedly?\n",
    "\n",
    "- Are slice boundaries correct with stop-exclusive behavior?\n",
    "\n",
    "- Do you need deterministic ordering before applying `iloc`?\n",
    "\n",
    "- Should you assert expected labels after positional selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b5c24",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685ebdb",
   "metadata": {},
   "source": [
    "Use `iloc` for explicit positional access, especially after controlled sorting where row order is intentional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f27d7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Pick top-N highest-risk rows after sorting scores descending.\n",
    "\n",
    "Scenario: model output is sorted, then analysts review first few rows by position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "d9575b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top2 by position: {'cust_104': 0.91, 'cust_101': 0.82}\n",
      "Second value: 0.82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "risk = pd.Series(\n",
    "    [0.82, 0.31, 0.67, 0.91],\n",
    "    index=[\"cust_101\", \"cust_102\", \"cust_103\", \"cust_104\"],\n",
    "    name=\"risk_score\",\n",
    ")\n",
    "\n",
    "ranked = risk.sort_values(ascending=False)\n",
    "top2 = ranked.iloc[:2]\n",
    "second_value = ranked.iloc[1]\n",
    "\n",
    "print(\"Top2 by position:\", top2.to_dict())\n",
    "print(\"Second value:\", second_value)\n",
    "\n",
    "assert list(top2.index) == [\"cust_104\", \"cust_101\"]\n",
    "assert float(second_value) == 0.82\n",
    "assert float(ranked.iloc[0]) == float(risk.loc[\"cust_104\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3547438",
   "metadata": {},
   "source": [
    "##### Series.at[label]\n",
    "`at` is the fast scalar label accessor for a Series. Use it when you need one specific value by label and want explicit scalar get/set behavior. It is commonly used in targeted corrections and rule-based updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "bddb3654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "99b690fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.at['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea7bcf",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd795b1e",
   "metadata": {},
   "source": [
    "`series.at[label]` retrieves or updates one value using exactly one label. It is built for single-cell label operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad7c24",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb6b44",
   "metadata": {},
   "source": [
    "- `label` (`scalar`): the index label of the single value to access.\n",
    "\n",
    "- `value` (assignment target, optional): value to write when using `series.at[label] = value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e03e7",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fef2af",
   "metadata": {},
   "source": [
    "Think of editing one known cell in a spreadsheet by row name.\n",
    "\n",
    "- You point to one row label.\n",
    "\n",
    "- You read or update that single cell.\n",
    "\n",
    "No list or slice behavior is involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb801222",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c0c7",
   "metadata": {},
   "source": [
    "- Pandas performs a direct scalar label lookup in the index.\n",
    "\n",
    "- For reads, it returns one scalar value; for writes, it updates that exact label location.\n",
    "\n",
    "- This path avoids some overhead of broader indexers when only one element is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ae148",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631fd99",
   "metadata": {},
   "source": [
    "- Missing labels raise `KeyError`.\n",
    "\n",
    "- Not suitable for multi-row selection; use `loc` for lists/slices/masks.\n",
    "\n",
    "- With duplicate labels, scalar assumptions can become ambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484166e2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05e98f",
   "metadata": {},
   "source": [
    "- Are you truly updating a single known label?\n",
    "\n",
    "- Could the label be missing in some runs?\n",
    "\n",
    "- Is label uniqueness guaranteed?\n",
    "\n",
    "- Should this update be logged for auditability?\n",
    "\n",
    "- Would vectorized update logic be safer for many rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02fe8e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85057a6a",
   "metadata": {},
   "source": [
    "Use `at` for fast, explicit single-label reads/writes when you are handling one specific row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e880df",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Apply a manual correction to one SKU stock value after QC review.\n",
    "\n",
    "Scenario: one known label is wrong and must be fixed without touching other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "7f110794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 30\n",
      "After: 28\n",
      "Current stock: {'sku_A': 45, 'sku_B': 28, 'sku_C': 12}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stock = pd.Series(\n",
    "    [45, 30, 12],\n",
    "    index=[\"sku_A\", \"sku_B\", \"sku_C\"],\n",
    "    name=\"inventory\",\n",
    ")\n",
    "\n",
    "before = stock.at[\"sku_B\"]\n",
    "stock.at[\"sku_B\"] = 28\n",
    "after = stock.at[\"sku_B\"]\n",
    "\n",
    "print(\"Before:\", before)\n",
    "print(\"After:\", after)\n",
    "print(\"Current stock:\", stock.to_dict())\n",
    "\n",
    "assert before == 30\n",
    "assert after == 28\n",
    "assert int(stock.loc[\"sku_B\"]) == 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68179345",
   "metadata": {},
   "source": [
    "##### Series.iat[position]\n",
    "`iat` is the fast scalar integer-position accessor for a Series. Use it when you need exactly one value by row position and want explicit scalar read/write behavior. It is ideal for targeted positional fixes after deterministic sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6bd86e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "b9b00506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.iat[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb7ba3e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385d98b",
   "metadata": {},
   "source": [
    "`series.iat[position]` reads or updates one value at a zero-based position. It is the positional scalar counterpart of `at`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea0297",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df97fb9",
   "metadata": {},
   "source": [
    "- `position` (`int`): zero-based row position for a single scalar access.\n",
    "\n",
    "- `value` (assignment target, optional): value to write when using `series.iat[position] = value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6850dd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae7ce3",
   "metadata": {},
   "source": [
    "Think of editing one spreadsheet cell by row number, not row name.\n",
    "\n",
    "- You count rows from the top.\n",
    "\n",
    "- You read or change one exact position.\n",
    "\n",
    "Labels are preserved in the Series, but selection is positional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e165106",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127085b3",
   "metadata": {},
   "source": [
    "- Pandas resolves the integer offset directly against the 1D value buffer.\n",
    "\n",
    "- For reads, it returns one scalar; for writes, it updates that exact buffer location.\n",
    "\n",
    "- This scalar path is lightweight and efficient for single-position operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ce723",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd13f5",
   "metadata": {},
   "source": [
    "- Out-of-bounds positions raise `IndexError`.\n",
    "\n",
    "- Position meaning can change after filtering/sorting, causing subtle bugs.\n",
    "\n",
    "- Not suitable for multi-row selection; use `iloc` for slices/lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427b1ef",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b1775",
   "metadata": {},
   "source": [
    "- Is positional access truly intended, or should label access be used?\n",
    "\n",
    "- Could upstream operations have changed row order?\n",
    "\n",
    "- Are you validating bounds before access?\n",
    "\n",
    "- Do you need to map position back to label for audit logs?\n",
    "\n",
    "- Should repeated updates be vectorized instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0c081",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68599b6",
   "metadata": {},
   "source": [
    "Use `iat` for quick single-cell positional reads/writes when index labels are not the selection key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c405ee9",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Apply a one-off correction to the 3rd ranked item after sorted QA review.\n",
    "\n",
    "Scenario: rankings are positional, but you still log the label tied to that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "cc7ee13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label: item_C\n",
      "Before/After: 0.84 0.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ranked_score = pd.Series(\n",
    "    [0.95, 0.90, 0.84, 0.79],\n",
    "    index=[\"item_A\", \"item_B\", \"item_C\", \"item_D\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "target_pos = 2\n",
    "target_label = ranked_score.index[target_pos]\n",
    "before = ranked_score.iat[target_pos]\n",
    "ranked_score.iat[target_pos] = 0.85\n",
    "after = ranked_score.iat[target_pos]\n",
    "\n",
    "print(\"Target label:\", target_label)\n",
    "print(\"Before/After:\", before, after)\n",
    "\n",
    "assert target_label == \"item_C\"\n",
    "assert float(before) == 0.84\n",
    "assert float(after) == 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758254c",
   "metadata": {},
   "source": [
    "##### Series.get(key, default=None)\n",
    "`get` performs a safe label lookup with a fallback value when the key is missing. It is useful in production pipelines where some labels may legitimately be absent. This avoids `KeyError` and keeps control flow explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "f0233a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "368cfd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.get('a', 'missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b047b3",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43408027",
   "metadata": {},
   "source": [
    "`series.get(key, default)` returns the value for `key` if it exists; otherwise it returns `default`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4567c8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1770c68",
   "metadata": {},
   "source": [
    "- `key` (`label`): index label to retrieve.\n",
    "\n",
    "- `default` (any type, default `None`): value returned if the key is not found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb995f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17538c",
   "metadata": {},
   "source": [
    "It works like a dictionary lookup with a fallback.\n",
    "\n",
    "- Ask for a row label.\n",
    "\n",
    "- If present, you get its value.\n",
    "\n",
    "- If missing, you get your default instead of an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b5d43",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83423e51",
   "metadata": {},
   "source": [
    "- Pandas attempts label resolution against the Series index.\n",
    "\n",
    "- On success, it returns the matched result for that key.\n",
    "\n",
    "- On failure, it returns `default`, enabling resilient lookup logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341b61e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa45121",
   "metadata": {},
   "source": [
    "- Defaults can hide upstream data-quality issues if used blindly.\n",
    "\n",
    "- With duplicate labels, returned shape/type may differ from scalar expectations.\n",
    "\n",
    "- Repeated per-key calls can be slower than vectorized reindex/map patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0118088",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c9813",
   "metadata": {},
   "source": [
    "- Is a missing key expected or a pipeline error?\n",
    "\n",
    "- Is the chosen default semantically correct (`0`, `None`, `pd.NA`)?\n",
    "\n",
    "- Are labels unique for this lookup logic?\n",
    "\n",
    "- Should missing keys be logged for monitoring?\n",
    "\n",
    "- Would batch retrieval be cleaner than repeated `get` calls?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200abb6",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5defd",
   "metadata": {},
   "source": [
    "Use `get` when missing labels are acceptable and you need an explicit fallback value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b968",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build a complete channel budget dict even when some channels are absent.\n",
    "\n",
    "Scenario: reporting requires fixed keys, but source Series may miss categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "6ada2237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved budget: {'search': np.int64(1200), 'affiliate': 0, 'email': np.int64(300)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "budget = pd.Series(\n",
    "    {\"search\": 1200, \"email\": 300, \"social\": 800},\n",
    "    name=\"monthly_budget\",\n",
    ")\n",
    "\n",
    "required = [\"search\", \"affiliate\", \"email\"]\n",
    "resolved = {k: budget.get(k, 0) for k in required}\n",
    "\n",
    "print(\"Resolved budget:\", resolved)\n",
    "\n",
    "assert resolved[\"search\"] == 1200\n",
    "assert resolved[\"affiliate\"] == 0\n",
    "assert resolved[\"email\"] == 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f9aa5",
   "metadata": {},
   "source": [
    "#### Boolean Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff0707",
   "metadata": {},
   "source": [
    "##### Series[condition]\n",
    "Boolean indexing filters a Series using a True/False condition. Rows where the condition is `True` are kept, and rows where it is `False` are removed. It is a core pattern for fast data cleaning, rule-based selection, and feature filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "afa7c326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "229dda59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[series > 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d1f3b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27af09",
   "metadata": {},
   "source": [
    "`series[condition]` keeps only the rows that satisfy your condition. The result is another Series with the original index labels for the kept rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbcaca",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68b623",
   "metadata": {},
   "source": [
    "- `condition` (`Series`/array-like of `bool`): mask indicating which rows to keep (`True`) or drop (`False`).\n",
    "\n",
    "- Condition length/index must align with the Series being filtered; otherwise pandas raises an error.\n",
    "\n",
    "- You can build conditions with comparisons (e.g., `series > 0`) or combined logic (`&`, `|`, `~`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d64106",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036cecf",
   "metadata": {},
   "source": [
    "Think of putting a yes/no filter on a spreadsheet column.\n",
    "\n",
    "- `True` means keep this row.\n",
    "\n",
    "- `False` means hide/remove this row from the result.\n",
    "\n",
    "Only rows passing the rule remain visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afd4c3",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c35a0",
   "metadata": {},
   "source": [
    "- Pandas first evaluates the condition to produce a boolean mask aligned to the Series index.\n",
    "\n",
    "- The mask is applied row by row: `True` rows are selected, `False` rows are dropped.\n",
    "\n",
    "- Selected rows keep their original labels, which preserves traceability to source entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f31ec",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94155c",
   "metadata": {},
   "source": [
    "- Misaligned mask length/index raises errors.\n",
    "\n",
    "- Complex chained conditions need parentheses to avoid operator-precedence bugs.\n",
    "\n",
    "- Nullable boolean masks may require explicit handling (`fillna(False)`) to avoid ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b18bc8",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d5e88",
   "metadata": {},
   "source": [
    "- Is your condition aligned to the same index as the Series?\n",
    "\n",
    "- Are threshold values business-approved and documented?\n",
    "\n",
    "- Did you use parentheses around each condition when combining with `&`/`|`?\n",
    "\n",
    "- Are you intentionally keeping or dropping missing values?\n",
    "\n",
    "- Do you verify which labels were removed after filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd7ef2",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb06c41",
   "metadata": {},
   "source": [
    "Use `series[condition]` to keep only rows that satisfy a boolean rule, while preserving the original index labels for the kept rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6d482",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Filter high-quality production batches before downstream release reporting.\n",
    "\n",
    "Scenario: only batches with quality score >= 0.80 should be included in the release set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "5d44f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition mask: {'batch_A': True, 'batch_B': False, 'batch_C': True, 'batch_D': False}\n",
      "Selected batches: {'batch_A': 0.91, 'batch_C': 0.88}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quality = pd.Series(\n",
    "    [0.91, 0.73, 0.88, 0.64],\n",
    "    index=[\"batch_A\", \"batch_B\", \"batch_C\", \"batch_D\"],\n",
    "    name=\"quality_score\",\n",
    ")\n",
    "\n",
    "condition = quality >= 0.80\n",
    "selected = quality[condition]\n",
    "\n",
    "print(\"Condition mask:\", condition.to_dict())\n",
    "print(\"Selected batches:\", selected.to_dict())\n",
    "\n",
    "assert list(selected.index) == [\"batch_A\", \"batch_C\"]\n",
    "assert float(selected.loc[\"batch_C\"]) == 0.88\n",
    "assert bool(condition.loc[\"batch_B\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3642715",
   "metadata": {},
   "source": [
    "#### Aggregation and reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f84be7",
   "metadata": {},
   "source": [
    "##### Series.sum()\n",
    "`sum()` adds the values in a Series and returns a single total. It is widely used for KPI totals, quality checks, and aggregation before reporting. Missing-value behavior and `min_count` make it reliable for production rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "a3e83063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "71a096e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(60)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3a7cb",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfbdbac",
   "metadata": {},
   "source": [
    "`series.sum()` gives the total of all values in the Series. By default it ignores missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a68ecc",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b1c1c",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `None`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when summing.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `min_count` (`int`, default `0`): require at least this many non-missing values, else return missing.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to the underlying reduction machinery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d240b6",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffda08",
   "metadata": {},
   "source": [
    "Think of adding all numbers in a spreadsheet column.\n",
    "\n",
    "- Each row contributes to a grand total.\n",
    "\n",
    "- Missing rows can be ignored or made strict with rules.\n",
    "\n",
    "You end up with one final total value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316d435",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969106cf",
   "metadata": {},
   "source": [
    "- Pandas scans the Series values and accumulates them into one scalar.\n",
    "\n",
    "- If `skipna=True`, missing entries are skipped during accumulation.\n",
    "\n",
    "- `min_count` adds a validity threshold so totals are returned only when enough real values exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f30505",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9dbad",
   "metadata": {},
   "source": [
    "- Summing nullable or mixed dtypes can trigger dtype conversions.\n",
    "\n",
    "- `skipna=True` may hide missing-data issues if you expected strict completeness.\n",
    "\n",
    "- For non-numeric/object data, results may be surprising without explicit casting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98410d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f227a91",
   "metadata": {},
   "source": [
    "- Should missing values be ignored or should they fail aggregation?\n",
    "\n",
    "- Is `min_count` needed to enforce data completeness?\n",
    "\n",
    "- Are values definitely numeric before summing?\n",
    "\n",
    "- Does total need to be grouped first by label/date/entity?\n",
    "\n",
    "- Do you need to trace which labels contributed to the total?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f42b1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a067b43",
   "metadata": {},
   "source": [
    "Use `sum()` for totals, and configure `skipna`/`min_count` so the result matches your data-quality expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec1b92",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute weekly sales total with a minimum-data rule.\n",
    "\n",
    "Scenario: report total sales only if at least three daily records are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "152b7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total (min_count=3): 300.0\n",
      "Total (min_count=4): nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weekly_sales = pd.Series(\n",
    "    [120, 80, None, 100],\n",
    "    index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\"],\n",
    "    name=\"sales\",\n",
    ")\n",
    "\n",
    "total = weekly_sales.sum(skipna=True, min_count=3)\n",
    "strict_total = weekly_sales.sum(skipna=True, min_count=4)\n",
    "\n",
    "print(\"Total (min_count=3):\", total)\n",
    "print(\"Total (min_count=4):\", strict_total)\n",
    "\n",
    "assert float(total) == 300.0\n",
    "assert pd.isna(strict_total)\n",
    "assert list(weekly_sales.dropna().index) == [\"Mon\", \"Tue\", \"Thu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f4d31",
   "metadata": {},
   "source": [
    "##### Series.mean()\n",
    "`mean()` returns the arithmetic average of Series values. It is a baseline metric for central tendency in analytics, QA, and feature engineering. By default, missing values are excluded from the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "808e70f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "0092eb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(20.0)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ac11f",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7686a06",
   "metadata": {},
   "source": [
    "`series.mean()` gives the average value. It is the total divided by the number of non-missing observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43822d6",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfada933",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values in the mean calculation.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to the underlying reduction machinery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d6847",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8c0fd",
   "metadata": {},
   "source": [
    "Think of finding the typical value in a spreadsheet column.\n",
    "\n",
    "- Add valid numbers.\n",
    "\n",
    "- Divide by how many valid numbers you had.\n",
    "\n",
    "That gives your average level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d48c27",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ca6fe",
   "metadata": {},
   "source": [
    "- Pandas computes the sum of valid values and divides by valid count.\n",
    "\n",
    "- Missing values are dropped first when `skipna=True`.\n",
    "\n",
    "- Output is a scalar capturing central tendency but sensitive to extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241010f8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3c002",
   "metadata": {},
   "source": [
    "- Mean is sensitive to outliers and skewed distributions.\n",
    "\n",
    "- If all values are missing, result is missing (`NaN`).\n",
    "\n",
    "- Non-numeric contamination can break or distort aggregation without cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5d2f3",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c25c3c",
   "metadata": {},
   "source": [
    "- Is mean the right metric, or would median be more robust?\n",
    "\n",
    "- Are outliers expected and acceptable in this average?\n",
    "\n",
    "- Are missing values being handled intentionally?\n",
    "\n",
    "- Do you need weighted mean instead of simple mean?\n",
    "\n",
    "- Should you compare average by segments rather than globally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749dabac",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80fa84",
   "metadata": {},
   "source": [
    "Use `mean()` for a quick average, then validate outliers and missing-data handling so the number is trustworthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91927919",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Track average fulfillment time while ignoring missing records.\n",
    "\n",
    "Scenario: estimate typical delivery duration from observed orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "0c8b217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average days: 3.0\n",
      "Used labels: ['ord_1', 'ord_2', 'ord_4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fulfillment_days = pd.Series(\n",
    "    [2.0, 3.0, None, 4.0],\n",
    "    index=[\"ord_1\", \"ord_2\", \"ord_3\", \"ord_4\"],\n",
    "    name=\"fulfillment_days\",\n",
    ")\n",
    "\n",
    "avg_days = fulfillment_days.mean()\n",
    "valid_labels = fulfillment_days.dropna().index\n",
    "\n",
    "print(\"Average days:\", round(float(avg_days), 2))\n",
    "print(\"Used labels:\", list(valid_labels))\n",
    "\n",
    "assert round(float(avg_days), 2) == 3.0\n",
    "assert list(valid_labels) == [\"ord_1\", \"ord_2\", \"ord_4\"]\n",
    "assert pd.isna(fulfillment_days.loc[\"ord_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce2430",
   "metadata": {},
   "source": [
    "##### Series.median()\n",
    "`median()` returns the middle value of a sorted Series (or midpoint of two middle values). It is robust to outliers and often preferred for skewed business metrics. This makes it a strong central-tendency measure for noisy real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "749fd438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "06b64f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(20.0)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e323c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aab88a",
   "metadata": {},
   "source": [
    "`series.median()` gives the middle value after sorting numbers. Extreme highs/lows affect it much less than mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453fcbff",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd588f5",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when computing the median.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to the underlying reduction machinery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86f1ef",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3f71e",
   "metadata": {},
   "source": [
    "Think of lining up values from smallest to largest and picking the center.\n",
    "\n",
    "- One extreme value on either end does not move the center much.\n",
    "\n",
    "- You get a stable ?typical? value.\n",
    "\n",
    "That is why median is outlier-resistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13e86c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4df39",
   "metadata": {},
   "source": [
    "- Pandas sorts valid numeric values conceptually and finds the center position.\n",
    "\n",
    "- For even counts, it averages the two central values.\n",
    "\n",
    "- Since only rank position matters, extreme tail values have limited influence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1d788",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe4a10",
   "metadata": {},
   "source": [
    "- Median ignores distribution tails, so it may hide large-risk extremes.\n",
    "\n",
    "- If all values are missing, result is missing (`NaN`).\n",
    "\n",
    "- For some reporting contexts, stakeholders expect mean and may misread median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddedc93",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4605c9",
   "metadata": {},
   "source": [
    "- Is your data skewed or outlier-heavy enough to prefer median?\n",
    "\n",
    "- Do you also need mean to communicate full context?\n",
    "\n",
    "- Are missing values handled as intended?\n",
    "\n",
    "- Could segmentation (by region/product) change median insights?\n",
    "\n",
    "- Do stakeholders understand median vs mean interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f65ed2",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755446af",
   "metadata": {},
   "source": [
    "Use `median()` when you need a robust center value that is less distorted by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72568e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Measure typical delivery time in presence of one severe delay outlier.\n",
    "\n",
    "Scenario: compare median against mean to show outlier impact clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "bf25d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 12.0\n",
      "Mean: 25.6\n",
      "Outlier label: ord_D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "delivery_minutes = pd.Series(\n",
    "    [12, 11, 13, 80, 12],\n",
    "    index=[\"ord_A\", \"ord_B\", \"ord_C\", \"ord_D\", \"ord_E\"],\n",
    "    name=\"delivery_minutes\",\n",
    ")\n",
    "\n",
    "med = delivery_minutes.median()\n",
    "avg = delivery_minutes.mean()\n",
    "outlier_label = delivery_minutes.idxmax()\n",
    "\n",
    "print(\"Median:\", med)\n",
    "print(\"Mean:\", round(float(avg), 2))\n",
    "print(\"Outlier label:\", outlier_label)\n",
    "\n",
    "assert float(med) == 12.0\n",
    "assert round(float(avg), 2) == 25.6\n",
    "assert outlier_label == \"ord_D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f02d6",
   "metadata": {},
   "source": [
    "##### Series.mode()\n",
    "`mode()` returns the most frequent value(s) in a Series. Unlike many reductions, it can return multiple results when frequencies tie. This makes it useful for dominant-category checks and anomaly context in categorical or discrete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "4356f77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "57d72af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfeaa0",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ee1df",
   "metadata": {},
   "source": [
    "`series.mode()` gives the value(s) that appear most often. If two or more values tie for top frequency, all are returned as a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562551b3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e6cd5",
   "metadata": {},
   "source": [
    "- `dropna` (`bool`, default `True`): exclude missing values when finding modes; set `False` to allow missing as a candidate mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd2102",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be582b",
   "metadata": {},
   "source": [
    "Think of counting survey answers and asking \"which answer was most common?\".\n",
    "\n",
    "- If one answer wins, you get one mode.\n",
    "\n",
    "- If answers tie, you keep all winners.\n",
    "\n",
    "So the result may have one or many values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e0e52",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc1ee6",
   "metadata": {},
   "source": [
    "- Pandas computes frequency counts across Series values.\n",
    "\n",
    "- It identifies the maximum count and returns all values with that count.\n",
    "\n",
    "- Output is always a Series to consistently support multi-mode results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b958e06",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35a714",
   "metadata": {},
   "source": [
    "- Result may contain multiple values, so scalar assumptions can break code.\n",
    "\n",
    "- High-cardinality data may have weakly informative modes.\n",
    "\n",
    "- Missing-value handling changes results when `dropna=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5bfc0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f776d",
   "metadata": {},
   "source": [
    "- Do you expect one mode or possible ties?\n",
    "\n",
    "- Should missing values be considered as valid outcomes?\n",
    "\n",
    "- Is mode meaningful for this variable type?\n",
    "\n",
    "- Do you need frequencies too (`value_counts`) and not only winners?\n",
    "\n",
    "- Are you mapping mode values back to labels for follow-up checks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1139f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cfb82",
   "metadata": {},
   "source": [
    "Use `mode()` to find the most frequent value(s), and always handle the possibility of multiple winners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8952be8",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Identify the most common support ticket priorities and locate related ticket IDs.\n",
    "\n",
    "Scenario: operations wants the dominant priority levels and where they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "bce1e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modes: ['high', 'low']\n",
      "Labels with mode values: ['t1', 't2', 't3', 't5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "priority = pd.Series(\n",
    "    [\"high\", \"low\", \"high\", \"medium\", \"low\"],\n",
    "    index=[\"t1\", \"t2\", \"t3\", \"t4\", \"t5\"],\n",
    "    name=\"priority\",\n",
    ")\n",
    "\n",
    "modes = priority.mode()\n",
    "mode_labels = priority[priority.isin(modes)].index\n",
    "\n",
    "print(\"Modes:\", modes.tolist())\n",
    "print(\"Labels with mode values:\", list(mode_labels))\n",
    "\n",
    "assert modes.tolist() == [\"high\", \"low\"]\n",
    "assert list(mode_labels) == [\"t1\", \"t2\", \"t3\", \"t5\"]\n",
    "assert priority.loc[\"t4\"] == \"medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea02cdf",
   "metadata": {},
   "source": [
    "##### Series.std()\n",
    "`std()` computes the standard deviation of Series values. It measures spread around the mean and is a core variability metric for QA and feature scaling. By default it uses sample standard deviation (`ddof=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "ab724a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c787e13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10.0)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90435947",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cb948",
   "metadata": {},
   "source": [
    "`series.std()` tells you how far values typically vary from the average. Higher values mean more dispersion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9210c5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516896b8",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `None`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values in computation.\n",
    "\n",
    "- `ddof` (`int`, default `1`): delta degrees of freedom (`N - ddof` divisor); `1` gives sample std, `0` gives population std.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03beac2a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ab758",
   "metadata": {},
   "source": [
    "Think of how tightly values cluster around a center line.\n",
    "\n",
    "- Tight cluster -> low standard deviation.\n",
    "\n",
    "- Wide spread -> high standard deviation.\n",
    "\n",
    "It quantifies consistency vs variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f71153",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a20202",
   "metadata": {},
   "source": [
    "- Pandas computes deviations from the mean, squares them, averages with divisor `N-ddof`, then takes square root.\n",
    "\n",
    "- Missing values are excluded when `skipna=True`.\n",
    "\n",
    "- `ddof` choice directly changes scale (sample vs population estimate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77409c",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c234a",
   "metadata": {},
   "source": [
    "- Sensitive to outliers because squared deviations amplify extremes.\n",
    "\n",
    "- Small samples can be unstable; ddof choice matters.\n",
    "\n",
    "- Non-numeric contamination must be cleaned/cast before interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f2ded",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210ab54",
   "metadata": {},
   "source": [
    "- Do you need sample (`ddof=1`) or population (`ddof=0`) std?\n",
    "\n",
    "- Are outliers inflating variability?\n",
    "\n",
    "- Are missing values handled intentionally?\n",
    "\n",
    "- Should variability be compared across segments?\n",
    "\n",
    "- Do stakeholders understand units of standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28116f18",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d5b1",
   "metadata": {},
   "source": [
    "Use `std()` to quantify spread, and set `ddof` explicitly so your definition (sample vs population) is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16cf89",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Measure volatility of daily demand before setting safety stock buffers.\n",
    "\n",
    "Scenario: compare sample and population dispersion for the same demand series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "4bff6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std (ddof=1): 2.582\n",
      "std (ddof=0): 2.2361\n",
      "Max-demand label: d4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "demand = pd.Series(\n",
    "    [10, 12, 14, 16],\n",
    "    index=[\"d1\", \"d2\", \"d3\", \"d4\"],\n",
    "    name=\"daily_demand\",\n",
    ")\n",
    "\n",
    "std_sample = demand.std(ddof=1)\n",
    "std_population = demand.std(ddof=0)\n",
    "max_label = demand.idxmax()\n",
    "\n",
    "print(\"std (ddof=1):\", round(float(std_sample), 4))\n",
    "print(\"std (ddof=0):\", round(float(std_population), 4))\n",
    "print(\"Max-demand label:\", max_label)\n",
    "\n",
    "assert round(float(std_sample), 4) == 2.582\n",
    "assert round(float(std_population), 4) == 2.2361\n",
    "assert max_label == \"d4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cdb47",
   "metadata": {},
   "source": [
    "##### Series.var()\n",
    "`var()` computes the variance of Series values, i.e., average squared deviation from the mean. It is used in statistical diagnostics, volatility analysis, and downstream formulas that depend on variance directly. Like `std()`, it defaults to sample variance (`ddof=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5c9dde8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b34a2da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100.0)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db00532",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab01eb8",
   "metadata": {},
   "source": [
    "`series.var()` measures how spread out values are, but in squared units. It is the square of standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9b721",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3aa917",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `None`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values in computation.\n",
    "\n",
    "- `ddof` (`int`, default `1`): divisor is `N - ddof`; controls sample vs population variance.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8c9e0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37077cb1",
   "metadata": {},
   "source": [
    "Imagine measuring how far values are from the center, but squaring distances first.\n",
    "\n",
    "- Big deviations get much larger weight.\n",
    "\n",
    "- Small deviations matter less.\n",
    "\n",
    "Variance emphasizes dispersion intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef67b89",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e3106",
   "metadata": {},
   "source": [
    "- Pandas computes mean, then squared deviations for each valid value.\n",
    "\n",
    "- It averages those squares using divisor `N - ddof`.\n",
    "\n",
    "- Because deviations are squared, variance is always non-negative and in squared units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffd1ce",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a555f",
   "metadata": {},
   "source": [
    "- Squared units are less interpretable than original units.\n",
    "\n",
    "- Outliers can dominate variance quickly.\n",
    "\n",
    "- `ddof` changes results noticeably for small samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328f4ce",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7a4b2",
   "metadata": {},
   "source": [
    "- Do you need variance directly, or is std easier to communicate?\n",
    "\n",
    "- Is `ddof` choice aligned with your statistical definition?\n",
    "\n",
    "- Are missing values and outliers handled before measuring spread?\n",
    "\n",
    "- Should variance be compared across homogeneous groups only?\n",
    "\n",
    "- Are units/squared-units implications clear in reports?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631a8a4",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f65be",
   "metadata": {},
   "source": [
    "Use `var()` when you need squared-spread magnitude (or downstream formulas), and make `ddof` explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe71e8e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Quantify batch-to-batch variability of process yield for QC monitoring.\n",
    "\n",
    "Scenario: compare sample and population variance from the same small batch series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ed25ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var (ddof=1): 6.6667\n",
      "var (ddof=0): 5.0\n",
      "ratio: 1.3333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yield_pct = pd.Series(\n",
    "    [90, 92, 88, 94],\n",
    "    index=[\"b1\", \"b2\", \"b3\", \"b4\"],\n",
    "    name=\"yield_pct\",\n",
    ")\n",
    "\n",
    "var_sample = yield_pct.var(ddof=1)\n",
    "var_population = yield_pct.var(ddof=0)\n",
    "spread_ratio = var_sample / var_population\n",
    "\n",
    "print(\"var (ddof=1):\", round(float(var_sample), 4))\n",
    "print(\"var (ddof=0):\", round(float(var_population), 4))\n",
    "print(\"ratio:\", round(float(spread_ratio), 4))\n",
    "\n",
    "assert round(float(var_sample), 4) == 6.6667\n",
    "assert round(float(var_population), 4) == 5.0\n",
    "assert round(float(spread_ratio), 4) == 1.3333"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26940d7e",
   "metadata": {},
   "source": [
    "##### Series.min()\n",
    "`min()` returns the smallest value in a Series. It is useful for threshold validation, floor checks, and early anomaly detection. For numeric metrics, it quickly identifies the lowest observed point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "59933f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "684ee14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd5c9b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf632e",
   "metadata": {},
   "source": [
    "`series.min()` gives the lowest value in the Series. By default it ignores missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68844f6a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755df33",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when finding the minimum.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to the reduction implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68cf19",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa4a2d",
   "metadata": {},
   "source": [
    "Think of scanning a spreadsheet column to find the lowest cell.\n",
    "\n",
    "- You compare all values.\n",
    "\n",
    "- Keep the smallest one.\n",
    "\n",
    "That final number is the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a6b2d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f782f",
   "metadata": {},
   "source": [
    "- Pandas iterates through valid values and tracks the current smallest value.\n",
    "\n",
    "- Missing values are skipped when `skipna=True`.\n",
    "\n",
    "- Output is a scalar representing the lower bound seen in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e85e6",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c8364",
   "metadata": {},
   "source": [
    "- One bad outlier can dominate the minimum and trigger false alarms.\n",
    "\n",
    "- If all values are missing, result is missing (`NaN`).\n",
    "\n",
    "- Mixed/object dtype can produce confusing comparisons without cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056dcc01",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553eb17c",
   "metadata": {},
   "source": [
    "- Should missing values be ignored or treated as invalid input?\n",
    "\n",
    "- Is the minimum plausible by business constraints?\n",
    "\n",
    "- Do you need the label of the minimum too (`idxmin`)?\n",
    "\n",
    "- Could unit/scale errors create artificial low values?\n",
    "\n",
    "- Should you winsorize or cap outliers before min checks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e955b74",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3c738",
   "metadata": {},
   "source": [
    "Use `min()` to get the lower bound quickly, then pair it with label tracing to investigate suspicious lows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9ec5f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find the lowest daily temperature and identify which station recorded it.\n",
    "\n",
    "Scenario: weather QA flags unusually low values for manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "40389a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: 2.8\n",
      "Minimum label: station_B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp_c = pd.Series(\n",
    "    [5.2, 2.8, None, 4.1],\n",
    "    index=[\"station_A\", \"station_B\", \"station_C\", \"station_D\"],\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "min_value = temp_c.min(skipna=True)\n",
    "min_label = temp_c.idxmin(skipna=True)\n",
    "\n",
    "print(\"Minimum value:\", min_value)\n",
    "print(\"Minimum label:\", min_label)\n",
    "\n",
    "assert float(min_value) == 2.8\n",
    "assert min_label == \"station_B\"\n",
    "assert float(temp_c.loc[min_label]) == float(min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eec7a8",
   "metadata": {},
   "source": [
    "##### Series.max()\n",
    "`max()` returns the largest value in a Series. It is used for peak detection, ceiling checks, and KPI monitoring. For operational data, it helps locate the highest observed load or risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1c95ad9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d931cd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(30)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0be450",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958feb4",
   "metadata": {},
   "source": [
    "`series.max()` gives the highest value in the Series, usually ignoring missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d2e60",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39222805",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when finding the maximum.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to the reduction implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ad366",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c91da2",
   "metadata": {},
   "source": [
    "Think of checking a spreadsheet column for the highest value.\n",
    "\n",
    "- Compare all entries.\n",
    "\n",
    "- Keep the largest one.\n",
    "\n",
    "That is the column peak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd3ecb",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fa985",
   "metadata": {},
   "source": [
    "- Pandas scans valid values and maintains the current largest value.\n",
    "\n",
    "- Missing values are skipped when `skipna=True`.\n",
    "\n",
    "- Result is a scalar upper bound, often paired with `idxmax` for label context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a84b83",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d195dc",
   "metadata": {},
   "source": [
    "- A single spike/outlier can dominate the maximum.\n",
    "\n",
    "- All-missing input returns missing (`NaN`).\n",
    "\n",
    "- Mixed dtype may require explicit cleaning/casting before reliable comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cc279",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a5373",
   "metadata": {},
   "source": [
    "- Is the peak value realistic by business limits?\n",
    "\n",
    "- Do you need the source label of the max (`idxmax`)?\n",
    "\n",
    "- Are spikes true events or data errors?\n",
    "\n",
    "- Should max be computed after filtering known bad rows?\n",
    "\n",
    "- Do you need percentile-based peaks instead of raw max?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3b897",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be09782",
   "metadata": {},
   "source": [
    "Use `max()` for a quick peak check, then map it back to labels for root-cause analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227925c",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find the highest hourly traffic load and identify the exact timestamp label.\n",
    "\n",
    "Scenario: capacity planning needs the observed peak hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6439665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 210\n",
      "Maximum label: 12:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "traffic = pd.Series(\n",
    "    [120, 180, 160, 210],\n",
    "    index=[\"09:00\", \"10:00\", \"11:00\", \"12:00\"],\n",
    "    name=\"requests\",\n",
    ")\n",
    "\n",
    "max_value = traffic.max()\n",
    "max_label = traffic.idxmax()\n",
    "\n",
    "print(\"Maximum value:\", max_value)\n",
    "print(\"Maximum label:\", max_label)\n",
    "\n",
    "assert int(max_value) == 210\n",
    "assert max_label == \"12:00\"\n",
    "assert int(traffic.loc[max_label]) == int(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3acb6d8",
   "metadata": {},
   "source": [
    "##### Series.count()\n",
    "`count()` returns how many non-missing values exist in a Series. It is a core completeness metric for QA and pipeline monitoring. Unlike `size`, it excludes `NaN`/`pd.NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7533daad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2c2d1f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddcd76",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf15c3",
   "metadata": {},
   "source": [
    "`series.count()` tells you how many valid (non-missing) entries you have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141aee7a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd78b53",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Use `series.count()` to get the non-missing row count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beea1e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a00fe0",
   "metadata": {},
   "source": [
    "Think of counting only filled cells in a spreadsheet column.\n",
    "\n",
    "- Filled cells count.\n",
    "\n",
    "- Empty cells do not.\n",
    "\n",
    "The result is data completeness in one number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8a9e4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa109a",
   "metadata": {},
   "source": [
    "- Pandas evaluates each row for missingness.\n",
    "\n",
    "- It increments the counter only for non-missing values.\n",
    "\n",
    "- Result is an integer coverage metric often compared against `size`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf55f8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2e102",
   "metadata": {},
   "source": [
    "- It does not indicate where missing values occur, only how many.\n",
    "\n",
    "- A high count can still hide biased missingness patterns by label/time.\n",
    "\n",
    "- For complete QA, pair with missing-label inspection (`isna`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad612f",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba184e9",
   "metadata": {},
   "source": [
    "- Is current non-missing count above the required threshold?\n",
    "\n",
    "- Which labels are missing, not just how many?\n",
    "\n",
    "- Has count drifted compared to prior runs?\n",
    "\n",
    "- Should pipeline fail if count is below expectation?\n",
    "\n",
    "- Do you need count by segment/time, not global only?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ffef0",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3978687",
   "metadata": {},
   "source": [
    "Use `count()` to measure usable observations quickly, then inspect missing labels for root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26024cb2",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Monitor daily KPI completeness before publishing dashboards.\n",
    "\n",
    "Scenario: report run is blocked if too many daily values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "642111be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid count: 3\n",
      "Missing labels: ['d2', 'd4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [1.2, None, 1.5, None, 1.1],\n",
    "    index=[\"d1\", \"d2\", \"d3\", \"d4\", \"d5\"],\n",
    "    name=\"ctr\",\n",
    ")\n",
    "\n",
    "valid_count = kpi.count()\n",
    "missing_labels = kpi.index[kpi.isna()]\n",
    "\n",
    "print(\"Valid count:\", valid_count)\n",
    "print(\"Missing labels:\", list(missing_labels))\n",
    "\n",
    "assert valid_count == 3\n",
    "assert list(missing_labels) == [\"d2\", \"d4\"]\n",
    "assert kpi.size - valid_count == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b122181",
   "metadata": {},
   "source": [
    "##### Series.quantile(q)\n",
    "`quantile(q)` returns value thresholds at specified cumulative proportions. It is useful for percentile-based monitoring, robust feature scaling, and outlier rules. You can request one quantile or multiple quantiles in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "913e0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "396e1636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(20.0)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c9b10",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac46ca6",
   "metadata": {},
   "source": [
    "`series.quantile(q)` answers: \"Which value sits at percentile `q`?\" For example, `q=0.5` is the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd391843",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3098d2aa",
   "metadata": {},
   "source": [
    "- `q` (`float` or sequence of float, default `0.5`): quantile(s) to compute in `[0, 1]` (e.g., `0.25`, `0.5`, `0.75`).\n",
    "\n",
    "- `interpolation` (`str`, default `'linear'`): rule used when quantile position falls between two points (`'linear'`, `'lower'`, `'higher'`, `'nearest'`, `'midpoint'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0799a0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccc173",
   "metadata": {},
   "source": [
    "Think of sorting values and marking cut points.\n",
    "\n",
    "- 25% cut gives lower-quartile threshold.\n",
    "\n",
    "- 50% cut gives median.\n",
    "\n",
    "These cuts summarize distribution without using mean alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2b6ec",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85967c",
   "metadata": {},
   "source": [
    "- Pandas orders valid values and locates position(s) implied by `q`.\n",
    "\n",
    "- If position is between two values, `interpolation` decides the returned threshold.\n",
    "\n",
    "- Output is a scalar for single `q` or a Series indexed by quantiles for multiple `q`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6966b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01d316",
   "metadata": {},
   "source": [
    "- Different interpolation methods yield different results on small datasets.\n",
    "\n",
    "- Quantiles do not reveal which label produced the threshold directly.\n",
    "\n",
    "- Heavy missingness can distort percentile interpretation if coverage is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15857c99",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0325a9",
   "metadata": {},
   "source": [
    "- Which quantile levels are meaningful for your KPI (p50, p90, p95)?\n",
    "\n",
    "- Is interpolation choice documented and consistent?\n",
    "\n",
    "- Are there enough valid points for stable percentile estimates?\n",
    "\n",
    "- Should quantiles be computed per segment/time window instead of globally?\n",
    "\n",
    "- Do you need to map thresholds back to nearest labels for investigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee543f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403ccf8",
   "metadata": {},
   "source": [
    "Use `quantile(q)` to get percentile thresholds, then apply them for robust alerts or distribution-aware decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4b0c4",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Define latency alert thresholds from quartiles and map the 75th threshold to nearest observed label.\n",
    "\n",
    "Scenario: SRE team uses percentile cut points instead of averages to track user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "9d542ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles: {0.25: 20.0, 0.5: 30.0, 0.75: 40.0}\n",
      "Nearest label to Q75: m4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency_ms = pd.Series(\n",
    "    [10, 20, 30, 40, 50],\n",
    "    index=[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\"],\n",
    "    name=\"latency_ms\",\n",
    ")\n",
    "\n",
    "q_values = latency_ms.quantile([0.25, 0.5, 0.75], interpolation=\"linear\")\n",
    "nearest_q75_label = (latency_ms - q_values.loc[0.75]).abs().idxmin()\n",
    "\n",
    "print(\"Quantiles:\", q_values.to_dict())\n",
    "print(\"Nearest label to Q75:\", nearest_q75_label)\n",
    "\n",
    "assert q_values.loc[0.25] == 20.0\n",
    "assert q_values.loc[0.5] == 30.0\n",
    "assert nearest_q75_label == \"m4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a770c05",
   "metadata": {},
   "source": [
    "##### Series.skew()\n",
    "`skew()` measures asymmetry of the Series distribution around its mean. Positive skew means a longer right tail; negative skew means a longer left tail. It is useful for feature diagnostics and for deciding whether transformations are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "dc4fea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "deb7ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2378189",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c1bed",
   "metadata": {},
   "source": [
    "`series.skew()` tells you whether values lean more to one side. Near zero means roughly symmetric; large positive/negative values indicate asymmetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b33c15",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8747bd",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when computing skewness.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to underlying reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa85c15",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73943f9",
   "metadata": {},
   "source": [
    "Think of balancing a distribution on a center point.\n",
    "\n",
    "- If one side has a long tail, balance shifts.\n",
    "\n",
    "- Right-heavy tail gives positive skew.\n",
    "\n",
    "It quantifies directional imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91376d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681373d",
   "metadata": {},
   "source": [
    "- Pandas computes a moment-based skewness statistic from centered values.\n",
    "\n",
    "- Missing values are removed first when `skipna=True`.\n",
    "\n",
    "- Large tail values influence skew direction and magnitude strongly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25ceed",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953437b",
   "metadata": {},
   "source": [
    "- Skewness is unstable on very small samples.\n",
    "\n",
    "- Outliers can dominate the metric and overstate asymmetry.\n",
    "\n",
    "- Skew alone does not describe multimodality or full shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb6816",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4024c",
   "metadata": {},
   "source": [
    "- Is sample size large enough for reliable skew interpretation?\n",
    "\n",
    "- Are outliers true events or data errors?\n",
    "\n",
    "- Should you transform values (log/Box-Cox) before modeling?\n",
    "\n",
    "- Do different segments have different skew direction?\n",
    "\n",
    "- Are you pairing skew with quantiles/histograms for fuller context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab1749",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0dda5e",
   "metadata": {},
   "source": [
    "Use `skew()` to detect distribution imbalance, then decide whether robust metrics or transformations are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c949a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Check whether request latency is right-skewed before choosing robust alert metrics.\n",
    "\n",
    "Scenario: one long-tail latency spike can bias mean-based thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "d3335930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: 1.9129\n",
      "Right-tail label: req_5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency = pd.Series(\n",
    "    [1, 1, 2, 3, 9],\n",
    "    index=[\"req_1\", \"req_2\", \"req_3\", \"req_4\", \"req_5\"],\n",
    "    name=\"latency_s\",\n",
    ")\n",
    "\n",
    "skew_val = latency.skew()\n",
    "tail_label = latency.idxmax()\n",
    "\n",
    "print(\"Skewness:\", round(float(skew_val), 4))\n",
    "print(\"Right-tail label:\", tail_label)\n",
    "\n",
    "assert round(float(skew_val), 4) == 1.9129\n",
    "assert skew_val > 0\n",
    "assert tail_label == \"req_5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03953aaf",
   "metadata": {},
   "source": [
    "##### Series.kurt()\n",
    "`kurt()` measures tail heaviness and peak shape using excess kurtosis. Values near 0 indicate normal-like tail behavior; higher values indicate heavier tails. It is useful for risk diagnostics where extreme outcomes matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "445c5489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "31a90e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e4de1",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdadb5",
   "metadata": {},
   "source": [
    "`series.kurt()` tells you how extreme the tails are compared with a normal-like baseline. Higher kurtosis often means more outlier-prone behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464de24e",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6edc70",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `0`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when computing kurtosis.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to underlying reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5ddf0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37462b32",
   "metadata": {},
   "source": [
    "Imagine comparing two hills with tails on both sides.\n",
    "\n",
    "- One has calm tails (few extremes).\n",
    "\n",
    "- One has heavy tails (more extremes).\n",
    "\n",
    "Kurtosis quantifies that tail heaviness difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553cd72",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6fa0a",
   "metadata": {},
   "source": [
    "- Pandas computes a moment-based kurtosis statistic from centered values.\n",
    "\n",
    "- Because high powers are used, extreme values influence the result strongly.\n",
    "\n",
    "- Output is excess kurtosis, where normal-like behavior is around `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b740e1",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9767b69",
   "metadata": {},
   "source": [
    "- Very sensitive to outliers and small-sample noise.\n",
    "\n",
    "- Interpretation is less intuitive than median/quantiles for many stakeholders.\n",
    "\n",
    "- Kurtosis alone cannot describe skew direction or multimodal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c222299",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032ce72",
   "metadata": {},
   "source": [
    "- Are extreme values real or data-quality problems?\n",
    "\n",
    "- Is sample size sufficient for stable kurtosis interpretation?\n",
    "\n",
    "- Do you need tail-focused policies (caps, winsorization, robust loss)?\n",
    "\n",
    "- Should kurtosis be compared per segment/time bucket?\n",
    "\n",
    "- Are additional diagnostics (quantiles, boxplots) also used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d2cf0",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdc8fd",
   "metadata": {},
   "source": [
    "Use `kurt()` to detect heavy-tail risk, then confirm with percentile diagnostics and outlier review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c91b96",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Assess whether claims data has heavy tails before selecting a robust pricing model.\n",
    "\n",
    "Scenario: one extreme claim can materially affect risk estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "9e4abdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kurtosis: 5.0\n",
      "Extreme label: c5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "claim_size = pd.Series(\n",
    "    [1, 1, 1, 1, 10],\n",
    "    index=[\"c1\", \"c2\", \"c3\", \"c4\", \"c5\"],\n",
    "    name=\"claim_size\",\n",
    ")\n",
    "\n",
    "kurt_val = claim_size.kurt()\n",
    "extreme_label = claim_size.idxmax()\n",
    "\n",
    "print(\"Kurtosis:\", round(float(kurt_val), 4))\n",
    "print(\"Extreme label:\", extreme_label)\n",
    "\n",
    "assert round(float(kurt_val), 4) == 5.0\n",
    "assert kurt_val > 0\n",
    "assert extreme_label == \"c5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c156a5",
   "metadata": {},
   "source": [
    "##### Series.prod()\n",
    "`prod()` multiplies Series values and returns one product. It is useful for compounded factors such as growth multipliers and probability chains. `min_count` makes it safer when data completeness matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "400385a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "8e616a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6000)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.prod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d51cb",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4866e4",
   "metadata": {},
   "source": [
    "`series.prod()` multiplies all values together. By default, missing values are skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84e295",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b192d",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `None`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values during multiplication.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `min_count` (`int`, default `0`): require at least this many non-missing values, else return missing.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8640e54",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d20325f",
   "metadata": {},
   "source": [
    "Think of chaining multipliers in sequence.\n",
    "\n",
    "- Each factor scales the running result.\n",
    "\n",
    "- One missing factor may be ignored or enforced via rules.\n",
    "\n",
    "Final output is the compounded product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b77176",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d0686",
   "metadata": {},
   "source": [
    "- Pandas iteratively multiplies valid values into an accumulator.\n",
    "\n",
    "- Missing entries are skipped when `skipna=True`.\n",
    "\n",
    "- `min_count` enforces a minimum evidence rule before returning a numeric result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f54565",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e305706",
   "metadata": {},
   "source": [
    "- Products can underflow/overflow for long sequences.\n",
    "\n",
    "- Zero values collapse the entire product to zero.\n",
    "\n",
    "- Skipping missing values can hide incomplete multiplier chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a14c0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad474a3a",
   "metadata": {},
   "source": [
    "- Is multiplication the correct business operation, or should you sum logs?\n",
    "\n",
    "- Do you need a strict completeness threshold (`min_count`)?\n",
    "\n",
    "- Could zeros be data errors rather than real values?\n",
    "\n",
    "- Are values in a stable numeric range to avoid precision issues?\n",
    "\n",
    "- Should missing labels be audited before compounding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686cee92",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02a3cf",
   "metadata": {},
   "source": [
    "Use `prod()` for compounding workflows, and control missing-data behavior with `skipna` and `min_count`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18128fec",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute cumulative conversion factor from stage-wise multipliers with a minimum-data rule.\n",
    "\n",
    "Scenario: return a product only if at least three stage factors are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b8e2877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product (min_count=3): 24.0\n",
      "Product (min_count=4): nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "factor = pd.Series(\n",
    "    [2, 3, None, 4],\n",
    "    index=[\"stage_1\", \"stage_2\", \"stage_3\", \"stage_4\"],\n",
    "    name=\"multiplier\",\n",
    ")\n",
    "\n",
    "prod_ok = factor.prod(skipna=True, min_count=3)\n",
    "prod_strict = factor.prod(skipna=True, min_count=4)\n",
    "\n",
    "print(\"Product (min_count=3):\", prod_ok)\n",
    "print(\"Product (min_count=4):\", prod_strict)\n",
    "\n",
    "assert float(prod_ok) == 24.0\n",
    "assert pd.isna(prod_strict)\n",
    "assert list(factor.dropna().index) == [\"stage_1\", \"stage_2\", \"stage_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88672c",
   "metadata": {},
   "source": [
    "##### Series.sem()\n",
    "`sem()` returns the standard error of the mean for a Series. It quantifies uncertainty of the sample mean estimate. This is useful for confidence-interval thinking and comparing estimate stability across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "47962ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "d6a9d7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.773502691896258)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5fbff",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae9224",
   "metadata": {},
   "source": [
    "`series.sem()` tells you how precise the sample mean is likely to be. Smaller SEM means a more stable mean estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b555f95",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182f57b",
   "metadata": {},
   "source": [
    "- `axis` (`0` or `None`, default `None`): axis to reduce; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values in SEM calculation.\n",
    "\n",
    "- `ddof` (`int`, default `1`): delta degrees of freedom used via underlying sample std.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric data when relevant.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69158db",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb50248",
   "metadata": {},
   "source": [
    "Think of repeatedly sampling and tracking how much sample means bounce around.\n",
    "\n",
    "- Large bounce -> high SEM.\n",
    "\n",
    "- Small bounce -> low SEM.\n",
    "\n",
    "SEM measures that expected bounce size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff436e",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db65778",
   "metadata": {},
   "source": [
    "- Pandas computes standard deviation (with `ddof`) and divides by sqrt(valid_count).\n",
    "\n",
    "- Missing values are excluded when `skipna=True`.\n",
    "\n",
    "- More observations reduce SEM, all else equal, because mean estimates stabilize with sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb9214",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c02dc",
   "metadata": {},
   "source": [
    "- SEM can look small even when data are biased or non-representative.\n",
    "\n",
    "- Small samples and outliers can make SEM unstable.\n",
    "\n",
    "- SEM is often confused with standard deviation; they answer different questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16768da8",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ee333",
   "metadata": {},
   "source": [
    "- Do you need spread of raw data (`std`) or precision of mean estimate (`sem`)?\n",
    "\n",
    "- Is sample size sufficient for reliable SEM interpretation?\n",
    "\n",
    "- Should `ddof` be set explicitly for consistency across analyses?\n",
    "\n",
    "- Are missing values and outliers handled before computing SEM?\n",
    "\n",
    "- Will SEM be converted into confidence intervals downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7263a35",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82996e",
   "metadata": {},
   "source": [
    "Use `sem()` when you care about uncertainty of the mean, not just variability of individual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81b7cb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compare stability of average processing time estimates between two pilot runs.\n",
    "\n",
    "Scenario: team wants to know if observed mean time is precise enough for planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "08c26370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM (ddof=1): 1.291\n",
      "SEM (ddof=0): 1.118\n",
      "Max label: run_4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "processing_time = pd.Series(\n",
    "    [10, 12, 14, 16],\n",
    "    index=[\"run_1\", \"run_2\", \"run_3\", \"run_4\"],\n",
    "    name=\"minutes\",\n",
    ")\n",
    "\n",
    "sem_sample = processing_time.sem(ddof=1)\n",
    "sem_population = processing_time.sem(ddof=0)\n",
    "max_label = processing_time.idxmax()\n",
    "\n",
    "print(\"SEM (ddof=1):\", round(float(sem_sample), 4))\n",
    "print(\"SEM (ddof=0):\", round(float(sem_population), 4))\n",
    "print(\"Max label:\", max_label)\n",
    "\n",
    "assert round(float(sem_sample), 4) == 1.291\n",
    "assert round(float(sem_population), 4) == 1.118\n",
    "assert max_label == \"run_4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161d863",
   "metadata": {},
   "source": [
    "##### Series.idxmax()\n",
    "`idxmax()` returns the index label of the first occurrence of the maximum value. It is useful when you need to identify which entity produced the peak metric. This is a label-first alternative to `max()` when traceability matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "e1c95378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "e480e526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5799c17",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dce77d",
   "metadata": {},
   "source": [
    "`series.idxmax()` gives you the label where the highest value occurs. It returns a label, not the value itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9701925",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1807e",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to operate on; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when searching for the maximum label.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; generally not needed for standard Series usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9ca5d",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e7d15",
   "metadata": {},
   "source": [
    "Think of finding the highest score in a spreadsheet and writing down the row name.\n",
    "\n",
    "- `max()` gives the top score.\n",
    "\n",
    "- `idxmax()` gives who/when produced it.\n",
    "\n",
    "So you get identity, not just magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcc82f",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc2c36",
   "metadata": {},
   "source": [
    "- Pandas scans values to find the maximum under `skipna` rules.\n",
    "\n",
    "- It returns the index label of the first maximum encountered.\n",
    "\n",
    "- This preserves business context (ID/timestamp/category) for follow-up actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf2b24",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8e331",
   "metadata": {},
   "source": [
    "- Ties return the first label only, which may hide equally high alternatives.\n",
    "\n",
    "- All-missing Series raises an error when no valid maximum exists.\n",
    "\n",
    "- If labels are duplicated, traceability can be ambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114df7b",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e69d9",
   "metadata": {},
   "source": [
    "- Do you need all tied maxima or only the first?\n",
    "\n",
    "- Are index labels unique and meaningful for decisions?\n",
    "\n",
    "- Could missing values affect which label is returned?\n",
    "\n",
    "- Should the max value itself also be logged?\n",
    "\n",
    "- Is sorting needed before tie-breaking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79684e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04361d68",
   "metadata": {},
   "source": [
    "Use `idxmax()` when you need the label behind the peak value so you can act on the right record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee59fb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find which campaign produced the highest conversion rate.\n",
    "\n",
    "Scenario: marketing review needs the campaign ID, not only the top rate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "81137f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best label: camp_B\n",
      "Best value: 0.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "conversion = pd.Series(\n",
    "    [0.72, 0.88, None, 0.81],\n",
    "    index=[\"camp_A\", \"camp_B\", \"camp_C\", \"camp_D\"],\n",
    "    name=\"conversion_rate\",\n",
    ")\n",
    "\n",
    "best_label = conversion.idxmax(skipna=True)\n",
    "best_value = conversion.loc[best_label]\n",
    "\n",
    "print(\"Best label:\", best_label)\n",
    "print(\"Best value:\", best_value)\n",
    "\n",
    "assert best_label == \"camp_B\"\n",
    "assert float(best_value) == 0.88\n",
    "assert float(conversion.max(skipna=True)) == float(best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f31c3",
   "metadata": {},
   "source": [
    "##### Series.idxmin()\n",
    "`idxmin()` returns the index label of the first occurrence of the minimum value. It is useful for identifying weakest performance, lowest quality, or minimum-risk cases by label. Use it when you need to know where the low point happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "e245308a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "d163410d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1c41e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3beb19",
   "metadata": {},
   "source": [
    "`series.idxmin()` gives the label where the smallest value is found. Like `idxmax()`, it returns identity, not the value itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ba7b5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f337c",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to operate on; for Series this is the row axis.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when searching for minimum label.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; generally not needed for standard Series usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a57c4b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cd4bb",
   "metadata": {},
   "source": [
    "Think of finding the lowest score in a column and recording the row name.\n",
    "\n",
    "- `min()` gives the lowest score.\n",
    "\n",
    "- `idxmin()` gives who/where it came from.\n",
    "\n",
    "That label is what you investigate next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad8aca",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70f0e7",
   "metadata": {},
   "source": [
    "- Pandas scans for the minimum value under `skipna` behavior.\n",
    "\n",
    "- It returns the index label of the first minimum encountered.\n",
    "\n",
    "- Label output makes downstream alerting and triage workflows straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be855ed",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10848d",
   "metadata": {},
   "source": [
    "- Ties return only the first minimum label.\n",
    "\n",
    "- All-missing input has no valid minimum and raises an error.\n",
    "\n",
    "- Duplicate labels can reduce clarity in incident reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d701c",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb529ed5",
   "metadata": {},
   "source": [
    "- Should tied minima be fully listed instead of first only?\n",
    "\n",
    "- Are labels unique enough for remediation workflows?\n",
    "\n",
    "- Are missing values handled intentionally via `skipna`?\n",
    "\n",
    "- Do you need value + label together in logs?\n",
    "\n",
    "- Is the minimum plausible or likely an outlier/data issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dedb5d",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd07b83",
   "metadata": {},
   "source": [
    "Use `idxmin()` to pinpoint exactly which labeled record produced the lowest value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c5d30",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find the store with the lowest daily NPS for targeted coaching.\n",
    "\n",
    "Scenario: operations needs the store ID behind the minimum score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "01668a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst label: store_B\n",
      "Worst value: 55.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nps = pd.Series(\n",
    "    [62, 55, None, 71],\n",
    "    index=[\"store_A\", \"store_B\", \"store_C\", \"store_D\"],\n",
    "    name=\"daily_nps\",\n",
    ")\n",
    "\n",
    "worst_label = nps.idxmin(skipna=True)\n",
    "worst_value = nps.loc[worst_label]\n",
    "\n",
    "print(\"Worst label:\", worst_label)\n",
    "print(\"Worst value:\", worst_value)\n",
    "\n",
    "assert worst_label == \"store_B\"\n",
    "assert int(worst_value) == 55\n",
    "assert int(nps.min(skipna=True)) == int(worst_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965a1b2",
   "metadata": {},
   "source": [
    "##### Series.corr(other)\n",
    "`corr(other)` computes correlation between two Series after aligning on common index labels. It quantifies linear (or rank-based) association and is widely used for feature screening. Alignment by labels is critical: only overlapping labels contribute to the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "368417d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "c9dacf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.corr(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58de2ef",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153ab9a",
   "metadata": {},
   "source": [
    "`series.corr(other)` tells you how strongly two Series move together, using their shared labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064746d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6faec0",
   "metadata": {},
   "source": [
    "- `other` (`Series`): the second Series to correlate with; labels are aligned before computation.\n",
    "\n",
    "- `method` (`'pearson'`, `'kendall'`, `'spearman'`, default `'pearson'`): correlation type.\n",
    "\n",
    "- `min_periods` (`int` or `None`, default `None`): minimum number of overlapping non-missing pairs required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985ae17",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d122fd",
   "metadata": {},
   "source": [
    "Think of comparing two spreadsheet columns row-by-row by matching row labels first.\n",
    "\n",
    "- Only matched rows count.\n",
    "\n",
    "- Then you measure how similarly values rise/fall.\n",
    "\n",
    "The output is one relationship score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d9af2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec2fdb",
   "metadata": {},
   "source": [
    "- Pandas aligns both Series on the intersection of index labels.\n",
    "\n",
    "- Missing pairs are dropped; remaining paired values feed the selected correlation method.\n",
    "\n",
    "- Result is a scalar correlation coefficient based only on overlapping valid pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21231adb",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e7876",
   "metadata": {},
   "source": [
    "- Misaligned indexes can drastically reduce overlap and change conclusions.\n",
    "\n",
    "- Correlation does not imply causation.\n",
    "\n",
    "- Outliers and nonlinearity can distort Pearson correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50245d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf0457",
   "metadata": {},
   "source": [
    "- How many overlapping labeled pairs are actually used?\n",
    "\n",
    "- Is Pearson appropriate, or should rank-based methods be used?\n",
    "\n",
    "- Could one outlier dominate the coefficient?\n",
    "\n",
    "- Are indexes semantically aligned (same entities/timestamps)?\n",
    "\n",
    "- Do you need significance testing beyond raw correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffd1ba",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437f2e9",
   "metadata": {},
   "source": [
    "Use `corr(other)` to measure association on shared labels, and always inspect overlap size and alignment assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd20950",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Measure relationship between ad spend and conversions for overlapping campaign IDs.\n",
    "\n",
    "Scenario: only campaigns present in both datasets should affect the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "dd9fc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap labels: ['c2', 'c3', 'c4']\n",
      "Correlation: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spend = pd.Series([1, 2, 3, 4], index=[\"c1\", \"c2\", \"c3\", \"c4\"], name=\"spend\")\n",
    "conv = pd.Series([10, 20, 30, 40], index=[\"c2\", \"c3\", \"c4\", \"c5\"], name=\"conv\")\n",
    "\n",
    "aligned_spend, aligned_conv = spend.align(conv, join=\"inner\")\n",
    "corr_val = spend.corr(conv, method=\"pearson\", min_periods=3)\n",
    "\n",
    "print(\"Overlap labels:\", list(aligned_spend.index))\n",
    "print(\"Correlation:\", corr_val)\n",
    "\n",
    "assert list(aligned_spend.index) == [\"c2\", \"c3\", \"c4\"]\n",
    "assert round(float(corr_val), 6) == 1.0\n",
    "assert len(aligned_spend) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61de7fc",
   "metadata": {},
   "source": [
    "##### Series.cov(other)\n",
    "`cov(other)` computes covariance between two Series after label alignment. It captures joint variability in original units and is foundational for risk and regression workflows. Like correlation, only overlapping index labels are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "deeba86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "cac1789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100.0)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cov(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb390b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a36ecc",
   "metadata": {},
   "source": [
    "`series.cov(other)` tells you whether two Series vary together and by how much in raw units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d17e45",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b1eae",
   "metadata": {},
   "source": [
    "- `other` (`Series`): second Series to compare; data are aligned by index labels first.\n",
    "\n",
    "- `min_periods` (`int` or `None`, default `None`): minimum overlapping non-missing pairs required.\n",
    "\n",
    "- `ddof` (`int` or `None`, default `1`): divisor uses `N - ddof`; controls sample vs population-style estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9308125",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc026a",
   "metadata": {},
   "source": [
    "Think of checking whether two labeled columns go up and down together in matched rows.\n",
    "\n",
    "- Same-direction movement yields positive covariance.\n",
    "\n",
    "- Opposite movement yields negative covariance.\n",
    "\n",
    "Magnitude depends on units and scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84871f",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364690b0",
   "metadata": {},
   "source": [
    "- Pandas aligns both Series on shared labels and removes missing pairs.\n",
    "\n",
    "- It computes mean-centered products and averages with divisor `N - ddof`.\n",
    "\n",
    "- Output is one covariance scalar in combined units of both variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09822624",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138edee",
   "metadata": {},
   "source": [
    "- Covariance magnitude depends on units, so cross-metric comparison is hard.\n",
    "\n",
    "- Limited overlap can make estimates unstable.\n",
    "\n",
    "- Misalignment or hidden duplicates can produce misleading values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc190b4",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3875f",
   "metadata": {},
   "source": [
    "- Are series aligned on the same entities/timestamps?\n",
    "\n",
    "- Is overlap count sufficient for reliable covariance?\n",
    "\n",
    "- Should `ddof` be fixed for consistency across analyses?\n",
    "\n",
    "- Would correlation be better for scale-free interpretation?\n",
    "\n",
    "- Are unit choices documented so covariance magnitude is interpretable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042bfa4",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dadfdb4",
   "metadata": {},
   "source": [
    "Use `cov(other)` to quantify co-movement in raw units on overlapping labels, then pair with correlation for normalized interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d65e06",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Estimate covariance between overlapping portfolio factors before risk aggregation.\n",
    "\n",
    "Scenario: risk model uses only shared asset dates from both factor series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2756ce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap labels: ['d2', 'd3', 'd4']\n",
      "Covariance: 10.0\n",
      "Covariance strict: nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "factor_a = pd.Series([1, 2, 3, 4], index=[\"d1\", \"d2\", \"d3\", \"d4\"], name=\"a\")\n",
    "factor_b = pd.Series([10, 20, 30, 40], index=[\"d2\", \"d3\", \"d4\", \"d5\"], name=\"b\")\n",
    "\n",
    "aligned_a, aligned_b = factor_a.align(factor_b, join=\"inner\")\n",
    "cov_val = factor_a.cov(factor_b, min_periods=3, ddof=1)\n",
    "cov_strict = factor_a.cov(factor_b, min_periods=4, ddof=1)\n",
    "\n",
    "print(\"Overlap labels:\", list(aligned_a.index))\n",
    "print(\"Covariance:\", cov_val)\n",
    "print(\"Covariance strict:\", cov_strict)\n",
    "\n",
    "assert list(aligned_a.index) == [\"d2\", \"d3\", \"d4\"]\n",
    "assert round(float(cov_val), 6) == 10.0\n",
    "assert pd.isna(cov_strict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab89b9",
   "metadata": {},
   "source": [
    "#### Logical and Comparion Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f13271",
   "metadata": {},
   "source": [
    "##### Series.gt(value)\n",
    "`gt()` performs element-wise \"greater than\" comparisons and returns a boolean Series. It is useful for threshold-based filtering in analytics and data-quality checks. When comparing to another Series, pandas aligns by index labels before evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "d8e888b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "08da06db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    False\n",
       "b    False\n",
       "c     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.gt(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42399dc",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b16fa",
   "metadata": {},
   "source": [
    "`series.gt(value)` marks each row as `True` if it is strictly greater than the comparison value, else `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048610f",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf602c63",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): comparison target (the `value` in `gt(value)`).\n",
    "\n",
    "- `level` (`int` or label, optional): align on a specific MultiIndex level when relevant.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing values before comparison.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis to compare along; for Series this is the row axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772377fc",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823c04f",
   "metadata": {},
   "source": [
    "Think of adding a rule in a spreadsheet: \"is this cell above the cutoff?\".\n",
    "\n",
    "- If yes, mark `True`.\n",
    "\n",
    "- If no, mark `False`.\n",
    "\n",
    "The result is a yes/no mask you can filter with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd6023",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef549b1",
   "metadata": {},
   "source": [
    "- Pandas compares each value against `other` element-wise.\n",
    "\n",
    "- If `other` is a Series, pandas aligns indexes first, then compares matched labels.\n",
    "\n",
    "- Output keeps the original index with boolean values indicating rule pass/fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a68372",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df595fa2",
   "metadata": {},
   "source": [
    "- Misaligned indexes can introduce missing comparisons when comparing Series-to-Series.\n",
    "\n",
    "- Strict `>` excludes equal values; sometimes `ge()` is the intended rule.\n",
    "\n",
    "- Mixed/object dtypes can cause unexpected comparison behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f950a6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48975d19",
   "metadata": {},
   "source": [
    "- Should equality pass too, or only strictly greater values?\n",
    "\n",
    "- Are indexes aligned before Series-to-Series comparison?\n",
    "\n",
    "- Do missing values need explicit fill behavior?\n",
    "\n",
    "- Is the threshold business-approved and versioned?\n",
    "\n",
    "- Do you need labels of passing rows for audit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94dc25",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17195e",
   "metadata": {},
   "source": [
    "Use `gt()` to build a boolean mask for values above a threshold, then filter while preserving index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e179b1d",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Flag stores with orders above a high-volume cutoff for staffing adjustments.\n",
    "\n",
    "Scenario: operations needs labels of stores where orders are strictly greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7d4f18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask: {'store_A': True, 'store_B': False, 'store_C': True, 'store_D': False}\n",
      "Selected stores: {'store_A': 120, 'store_C': 140}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.Series(\n",
    "    [120, 85, 140, 95],\n",
    "    index=[\"store_A\", \"store_B\", \"store_C\", \"store_D\"],\n",
    "    name=\"orders\",\n",
    ")\n",
    "\n",
    "high_volume = orders.gt(100)\n",
    "selected = orders[high_volume]\n",
    "\n",
    "print(\"Mask:\", high_volume.to_dict())\n",
    "print(\"Selected stores:\", selected.to_dict())\n",
    "\n",
    "assert list(selected.index) == [\"store_A\", \"store_C\"]\n",
    "assert bool(high_volume.loc[\"store_B\"]) is False\n",
    "assert int(high_volume.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57970dcb",
   "metadata": {},
   "source": [
    "##### Series.ge(value)\n",
    "`ge()` performs element-wise \"greater than or equal\" comparisons and returns booleans. It is useful for pass/fail rules where boundary values must be included. Like other comparison ops, index alignment is applied for Series-to-Series comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "82014884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "ff2765f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    False\n",
       "b     True\n",
       "c     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.ge(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d7705",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375baba",
   "metadata": {},
   "source": [
    "`series.ge(value)` marks rows `True` when values are greater than or equal to the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684176a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6591ea4",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): comparison target (the `value` in `ge(value)`).\n",
    "\n",
    "- `level` (`int` or label, optional): align using a MultiIndex level when needed.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing data before comparison.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis parameter; for Series this is the row axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00508b02",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c30a8",
   "metadata": {},
   "source": [
    "Think of a spreadsheet rule: \"pass if score is at least cutoff\".\n",
    "\n",
    "- Equal to cutoff is accepted.\n",
    "\n",
    "- Below cutoff is rejected.\n",
    "\n",
    "This is inclusive threshold logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c4279",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8aec3",
   "metadata": {},
   "source": [
    "- Pandas compares each value to `other` using `>=`.\n",
    "\n",
    "- For Series inputs, labels are aligned before comparison.\n",
    "\n",
    "- Output boolean Series preserves index labels for direct filtering/reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e01cf8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77911ee6",
   "metadata": {},
   "source": [
    "- Inclusive boundary can change business counts versus strict `gt()`.\n",
    "\n",
    "- Misalignment in paired Series can produce unexpected missing comparisons.\n",
    "\n",
    "- Type inconsistencies may coerce or fail comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285eb83",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3775c",
   "metadata": {},
   "source": [
    "- Should boundary-equal rows pass?\n",
    "\n",
    "- Is threshold numeric type consistent with Series dtype?\n",
    "\n",
    "- Are label alignments validated for Series-to-Series checks?\n",
    "\n",
    "- Should missing values be filled before applying the rule?\n",
    "\n",
    "- Are result labels logged for compliance/audit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c990eb",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfc55e",
   "metadata": {},
   "source": [
    "Use `ge()` when your rule is inclusive of the cutoff and you need a filterable boolean mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df63016",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Identify students meeting minimum passing score including exact-cutoff cases.\n",
    "\n",
    "Scenario: pass threshold is 70, and score 70 must count as pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e583de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass mask: {'stu_A': False, 'stu_B': True, 'stu_C': True, 'stu_D': True}\n",
      "Passing students: {'stu_B': 70, 'stu_C': 92, 'stu_D': 70}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = pd.Series(\n",
    "    [68, 70, 92, 70],\n",
    "    index=[\"stu_A\", \"stu_B\", \"stu_C\", \"stu_D\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "passed = scores.ge(70)\n",
    "pass_scores = scores[passed]\n",
    "\n",
    "print(\"Pass mask:\", passed.to_dict())\n",
    "print(\"Passing students:\", pass_scores.to_dict())\n",
    "\n",
    "assert list(pass_scores.index) == [\"stu_B\", \"stu_C\", \"stu_D\"]\n",
    "assert bool(passed.loc[\"stu_A\"]) is False\n",
    "assert int(passed.sum()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe47cd2",
   "metadata": {},
   "source": [
    "##### Series.lt(value)\n",
    "`lt()` performs element-wise \"less than\" comparisons and returns a boolean Series. It is common in low-threshold alerts such as low stock or low performance flags. Label alignment still applies when comparing with another Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "4792a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "0db1d0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b    False\n",
       "c    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.lt(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4e40a",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df76031",
   "metadata": {},
   "source": [
    "`series.lt(value)` marks rows `True` when values are strictly below the comparison value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a339076",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c486511",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): comparison target (the `value` in `lt(value)`).\n",
    "\n",
    "- `level` (`int` or label, optional): compare using a specific MultiIndex level if needed.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing values before applying `<`.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis parameter; for Series this is the row axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169565b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c5a28",
   "metadata": {},
   "source": [
    "Think of a spreadsheet rule: \"is this below the reorder line?\".\n",
    "\n",
    "- Below threshold -> `True` alert.\n",
    "\n",
    "- Otherwise -> `False`.\n",
    "\n",
    "This builds a low-value alert mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8d7ad",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44a14a",
   "metadata": {},
   "source": [
    "- Pandas applies `<` element-wise between Series values and `other`.\n",
    "\n",
    "- If `other` is Series, labels are aligned first to compare matching entities.\n",
    "\n",
    "- Result is an indexed boolean Series used for filtering or alerting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4b8af",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92583cf7",
   "metadata": {},
   "source": [
    "- Strict `<` excludes equal values, which may not match policy.\n",
    "\n",
    "- Missing or misaligned labels can reduce valid comparisons.\n",
    "\n",
    "- Dtype inconsistencies can yield unexpected comparison output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ac68b",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069169e",
   "metadata": {},
   "source": [
    "- Should equality trigger the same rule (`le`) or not?\n",
    "\n",
    "- Are thresholds dynamic by segment and therefore needing aligned Series comparisons?\n",
    "\n",
    "- Are missing rows handled before threshold checks?\n",
    "\n",
    "- Is threshold based on validated business constraints?\n",
    "\n",
    "- Are alert labels retained for escalation workflows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779e636",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03f27f",
   "metadata": {},
   "source": [
    "Use `lt()` for strict lower-bound checks and keep the resulting boolean mask for transparent filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24901503",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Trigger reorder alerts when stock-cover days fall below 10.\n",
    "\n",
    "Scenario: inventory ops only wants SKUs strictly under the safety threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "26152dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reorder mask: {'sku_A': False, 'sku_B': True, 'sku_C': False, 'sku_D': True}\n",
      "Reorder SKUs: {'sku_B': 8, 'sku_D': 6}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stock_days = pd.Series(\n",
    "    [12, 8, 15, 6],\n",
    "    index=[\"sku_A\", \"sku_B\", \"sku_C\", \"sku_D\"],\n",
    "    name=\"stock_cover_days\",\n",
    ")\n",
    "\n",
    "reorder_mask = stock_days.lt(10)\n",
    "reorder = stock_days[reorder_mask]\n",
    "\n",
    "print(\"Reorder mask:\", reorder_mask.to_dict())\n",
    "print(\"Reorder SKUs:\", reorder.to_dict())\n",
    "\n",
    "assert list(reorder.index) == [\"sku_B\", \"sku_D\"]\n",
    "assert int(reorder.loc[\"sku_D\"]) == 6\n",
    "assert int(reorder_mask.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c898bf",
   "metadata": {},
   "source": [
    "##### Series.le(value)\n",
    "`le()` performs element-wise \"less than or equal\" comparisons and returns booleans. It is useful for inclusive upper-limit policies, like defect-rate or SLA boundaries. As with other comparison methods, index alignment drives Series-to-Series behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "fde174e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "2daef15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b     True\n",
       "c    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.le(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283abf25",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac35d7",
   "metadata": {},
   "source": [
    "`series.le(value)` marks rows `True` when values are less than or equal to the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865715e",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99841884",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): comparison target (the `value` in `le(value)`).\n",
    "\n",
    "- `level` (`int` or label, optional): align on a MultiIndex level when needed.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing values before inclusive comparison.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis parameter; for Series this is the row axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde5e09",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c203e",
   "metadata": {},
   "source": [
    "Think of a quality gate: \"pass if metric is at or below the cap\".\n",
    "\n",
    "- Below cap passes.\n",
    "\n",
    "- Exactly at cap also passes.\n",
    "\n",
    "This is inclusive upper-bound logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720641d2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2883ab",
   "metadata": {},
   "source": [
    "- Pandas compares each value to `other` using `<=`.\n",
    "\n",
    "- For Series comparisons, labels are aligned before evaluation.\n",
    "\n",
    "- Output is an indexed boolean mask preserving row identity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de345d9",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0dd72",
   "metadata": {},
   "source": [
    "- Inclusive cutoff can inflate pass counts versus strict `lt()`.\n",
    "\n",
    "- Misalignment may silently reduce comparison pairs.\n",
    "\n",
    "- Object dtype values may compare unexpectedly without normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe95ad",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5bed6",
   "metadata": {},
   "source": [
    "- Is equality supposed to pass under policy rules?\n",
    "\n",
    "- Are all compared values in compatible units and scales?\n",
    "\n",
    "- Is index alignment validated before comparing two Series?\n",
    "\n",
    "- Should missing data be filled explicitly first?\n",
    "\n",
    "- Are passing/failing labels stored for reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8758030",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870394aa",
   "metadata": {},
   "source": [
    "Use `le()` when limits are inclusive and you need a transparent boolean pass/fail mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e713a30",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Check production lines that meet an inclusive defect-rate limit (<= 2.5%).\n",
    "\n",
    "Scenario: quality policy treats exactly 2.5% as acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "05a8b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-target mask: {'line_A': True, 'line_B': False, 'line_C': True, 'line_D': True}\n",
      "Passing lines: {'line_A': 0.02, 'line_C': 0.025, 'line_D': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "defect_rate = pd.Series(\n",
    "    [0.020, 0.030, 0.025, 0.010],\n",
    "    index=[\"line_A\", \"line_B\", \"line_C\", \"line_D\"],\n",
    "    name=\"defect_rate\",\n",
    ")\n",
    "\n",
    "within_target = defect_rate.le(0.025)\n",
    "good_lines = defect_rate[within_target]\n",
    "\n",
    "print(\"Within-target mask:\", within_target.to_dict())\n",
    "print(\"Passing lines:\", good_lines.to_dict())\n",
    "\n",
    "assert list(good_lines.index) == [\"line_A\", \"line_C\", \"line_D\"]\n",
    "assert bool(within_target.loc[\"line_B\"]) is False\n",
    "assert int(within_target.sum()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c3ea0",
   "metadata": {},
   "source": [
    "##### Series.eq(value)\n",
    "`eq()` performs element-wise equality checks and returns a boolean Series. It is useful for exact-match rules such as status flags, category checks, and QA validation. When `other` is another Series, pandas aligns labels before comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "a583f989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "75345b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    False\n",
       "b     True\n",
       "c    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.eq(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0d4f5",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c7784",
   "metadata": {},
   "source": [
    "`series.eq(value)` marks each row `True` when it exactly equals the comparison value, otherwise `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3589f8a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437122fb",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): value(s) to compare against.\n",
    "\n",
    "- `level` (`int` or label, optional): align on a specific MultiIndex level when relevant.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing values before comparison.\n",
    "\n",
    "- `axis` (`0`, default `0`): comparison axis; for Series this is the row axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675acbb5",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b49359",
   "metadata": {},
   "source": [
    "Think of a spreadsheet filter: \"is this exactly equal to target?\".\n",
    "\n",
    "- Exact match -> `True`.\n",
    "\n",
    "- Anything else -> `False`.\n",
    "\n",
    "You get a precise yes/no mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303dca6",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00b7f3",
   "metadata": {},
   "source": [
    "- Pandas compares each Series element with `other` using equality rules.\n",
    "\n",
    "- If `other` is Series-like, index labels are aligned first.\n",
    "\n",
    "- Output is a boolean Series preserving original labels for downstream filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86e985",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b038053a",
   "metadata": {},
   "source": [
    "- Exact equality on floats can fail due to precision; tolerances may be safer.\n",
    "\n",
    "- String/case/whitespace inconsistencies can create false non-matches.\n",
    "\n",
    "- Misaligned indexes in Series-to-Series comparison can introduce missing comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19196df5",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb79991",
   "metadata": {},
   "source": [
    "- Is exact equality the right rule, or do you need tolerance/range logic?\n",
    "\n",
    "- Are labels aligned before comparing two Series?\n",
    "\n",
    "- Should missing values be filled first?\n",
    "\n",
    "- Are text values normalized (case/trim) before equality checks?\n",
    "\n",
    "- Do you need matched labels for audit output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24556e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80526f50",
   "metadata": {},
   "source": [
    "Use `eq()` for exact-match masks, then filter by labels to inspect where matches occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81eb3e2",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Identify orders with status exactly equal to `\"failed\"` for retry workflows.\n",
    "\n",
    "Scenario: ops only retries rows with exact failed status labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "cd076e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed mask: {'ord_1': False, 'ord_2': True, 'ord_3': False, 'ord_4': True}\n",
      "Failed orders: {'ord_2': 'failed', 'ord_4': 'failed'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "status = pd.Series(\n",
    "    [\"ok\", \"failed\", \"ok\", \"failed\"],\n",
    "    index=[\"ord_1\", \"ord_2\", \"ord_3\", \"ord_4\"],\n",
    "    name=\"status\",\n",
    ")\n",
    "\n",
    "failed_mask = status.eq(\"failed\")\n",
    "failed_orders = status[failed_mask]\n",
    "\n",
    "print(\"Failed mask:\", failed_mask.to_dict())\n",
    "print(\"Failed orders:\", failed_orders.to_dict())\n",
    "\n",
    "assert list(failed_orders.index) == [\"ord_2\", \"ord_4\"]\n",
    "assert bool(failed_mask.loc[\"ord_1\"]) is False\n",
    "assert int(failed_mask.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2611ab",
   "metadata": {},
   "source": [
    "##### Series.ne(value)\n",
    "`ne()` performs element-wise \"not equal\" checks and returns booleans. It is useful for excluding a specific class, status, or sentinel value. It also respects label alignment when comparing Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "47fe9096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "ba911317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b    False\n",
       "c     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.ne(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd4b68",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5a7a6",
   "metadata": {},
   "source": [
    "`series.ne(value)` marks rows `True` when they are different from the comparison value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9fea65",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c7e84",
   "metadata": {},
   "source": [
    "- `other` (scalar, Series, or array-like): value(s) used for inequality comparison.\n",
    "\n",
    "- `level` (`int` or label, optional): align on a MultiIndex level when applicable.\n",
    "\n",
    "- `fill_value` (scalar, optional): fill missing data before comparison.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis parameter; for Series this is row-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc823bdb",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d339b6",
   "metadata": {},
   "source": [
    "Think of asking: \"which rows are not this value?\" in a spreadsheet.\n",
    "\n",
    "- Different -> `True`.\n",
    "\n",
    "- Exactly same -> `False`.\n",
    "\n",
    "It creates an exclusion mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c581c47",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4adab",
   "metadata": {},
   "source": [
    "- Pandas compares each element with `other` using `!=`.\n",
    "\n",
    "- For Series-to-Series comparisons, labels are aligned first.\n",
    "\n",
    "- Output is a boolean Series preserving index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c28ce",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03043b4",
   "metadata": {},
   "source": [
    "- Hidden formatting differences can cause unexpected `True` values.\n",
    "\n",
    "- Float precision issues can make near-equal values look unequal.\n",
    "\n",
    "- Alignment mismatches may reduce valid comparison pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54df03d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c2eda",
   "metadata": {},
   "source": [
    "- Are you excluding one exact value or a broader class of values?\n",
    "\n",
    "- Should text normalization happen before inequality checks?\n",
    "\n",
    "- Are missing values treated intentionally?\n",
    "\n",
    "- Are you using the correct alignment when comparing two Series?\n",
    "\n",
    "- Do you need labels of excluded rows for reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953175f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30236540",
   "metadata": {},
   "source": [
    "Use `ne()` to build clean exclusion masks, especially when removing one exact unwanted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55895b0",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Exclude test traffic source rows from production KPI summaries.\n",
    "\n",
    "Scenario: analytics should keep all channels except exact label `\"test\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "db77dc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production mask: {'r1': True, 'r2': False, 'r3': True, 'r4': False, 'r5': True}\n",
      "Production rows: {'r1': 'web', 'r3': 'app', 'r5': 'store'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source = pd.Series(\n",
    "    [\"web\", \"test\", \"app\", \"test\", \"store\"],\n",
    "    index=[\"r1\", \"r2\", \"r3\", \"r4\", \"r5\"],\n",
    "    name=\"source\",\n",
    ")\n",
    "\n",
    "prod_mask = source.ne(\"test\")\n",
    "prod_source = source[prod_mask]\n",
    "\n",
    "print(\"Production mask:\", prod_mask.to_dict())\n",
    "print(\"Production rows:\", prod_source.to_dict())\n",
    "\n",
    "assert list(prod_source.index) == [\"r1\", \"r3\", \"r5\"]\n",
    "assert bool(prod_mask.loc[\"r2\"]) is False\n",
    "assert int(prod_mask.sum()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7c06e",
   "metadata": {},
   "source": [
    "##### Series.all()\n",
    "`all()` reduces a Series to one boolean: `True` only if all elements evaluate to True. It is useful for global pass/fail validation checks. Typical usage is on boolean masks generated by comparison rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "4655fb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "d962be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(series > 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78341b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e53039",
   "metadata": {},
   "source": [
    "`series.all()` asks: \"Do all rows satisfy this condition?\" and returns one True/False answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e64ea",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c481d0c",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): reduction axis; for Series this is the row axis.\n",
    "\n",
    "- `bool_only` (`bool`, default `False`): kept for API consistency; Series typically already behaves as a single dtype vector.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when reducing.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217eeae",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585baa7",
   "metadata": {},
   "source": [
    "Think of a checklist where every box must be checked.\n",
    "\n",
    "- One unchecked item -> overall failure.\n",
    "\n",
    "- All checked -> overall success.\n",
    "\n",
    "`all()` gives that overall decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a62647",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b8c76",
   "metadata": {},
   "source": [
    "- Pandas scans the Series as booleans and looks for any False-like value.\n",
    "\n",
    "- If one False is found, result is False; otherwise True.\n",
    "\n",
    "- With `skipna=True`, missing entries are ignored in the final reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6bbaa",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471fba1",
   "metadata": {},
   "source": [
    "- On non-boolean numeric data, truthiness rules can be surprising (`0` is False, non-zero is True).\n",
    "\n",
    "- `skipna` behavior can hide missing values in strict QA settings.\n",
    "\n",
    "- One bad row flips the global result, so debug labels are still needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde2612",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d84ff1",
   "metadata": {},
   "source": [
    "- Is your input definitely boolean, or should you build a mask first?\n",
    "\n",
    "- Should missing values invalidate the check?\n",
    "\n",
    "- Do you need labels of failing rows in addition to global result?\n",
    "\n",
    "- Is this an all-or-nothing rule or should partial pass be allowed?\n",
    "\n",
    "- Are threshold rules producing the expected boolean mask?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954f0c1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ce7ca",
   "metadata": {},
   "source": [
    "Use `all()` for strict global validation, and pair it with failing-label extraction for actionability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a563ddc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate that every batch in a run meets the minimum quality threshold.\n",
    "\n",
    "Scenario: release proceeds only if all batches pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "89c571c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass mask: {'batch_A': True, 'batch_B': True, 'batch_C': False, 'batch_D': True}\n",
      "All pass?: False\n",
      "Failed labels: ['batch_C']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quality = pd.Series(\n",
    "    [0.91, 0.87, 0.78, 0.88],\n",
    "    index=[\"batch_A\", \"batch_B\", \"batch_C\", \"batch_D\"],\n",
    "    name=\"quality\",\n",
    ")\n",
    "\n",
    "pass_mask = quality.ge(0.80)\n",
    "all_pass = pass_mask.all()\n",
    "failed_labels = pass_mask.index[~pass_mask]\n",
    "\n",
    "print(\"Pass mask:\", pass_mask.to_dict())\n",
    "print(\"All pass?:\", all_pass)\n",
    "print(\"Failed labels:\", list(failed_labels))\n",
    "\n",
    "assert bool(all_pass) is False\n",
    "assert list(failed_labels) == [\"batch_C\"]\n",
    "assert bool(pass_mask.loc[\"batch_A\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8580a",
   "metadata": {},
   "source": [
    "##### Series.any()\n",
    "`any()` reduces a Series to one boolean: `True` if at least one element is True. It is useful for alert triggering when one violation is enough to act. It is commonly applied to boolean masks from comparison methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ff942e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "59a1fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(series > 0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ac687",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd9103",
   "metadata": {},
   "source": [
    "`series.any()` asks: \"Is there at least one row that satisfies this condition?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea7b84",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7f8c3",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): reduction axis; for Series this is the row axis.\n",
    "\n",
    "- `bool_only` (`bool`, default `False`): API-compatibility parameter; Series is typically reduced directly.\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values when reducing.\n",
    "\n",
    "- `**kwargs`: extra options forwarded to reduction internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbc37b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfbbdd4",
   "metadata": {},
   "source": [
    "Think of a safety board where one red light is enough to trigger response.\n",
    "\n",
    "- At least one red -> alert.\n",
    "\n",
    "- No red lights -> no alert.\n",
    "\n",
    "`any()` gives that trigger signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae51df",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a3eb2",
   "metadata": {},
   "source": [
    "- Pandas scans boolean values looking for any True-like element.\n",
    "\n",
    "- If one True is found, result is True; otherwise False.\n",
    "\n",
    "- With `skipna=True`, missing values are ignored in the reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792fc62",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388f4dd",
   "metadata": {},
   "source": [
    "- Non-boolean inputs use truthiness rules that can be unintuitive.\n",
    "\n",
    "- One noisy outlier can trigger True and cause false alarms.\n",
    "\n",
    "- Result is global and does not tell you where the trigger occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bafb0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b6c7f",
   "metadata": {},
   "source": [
    "- Is one violation enough to trigger action, or do you need counts?\n",
    "\n",
    "- Are missing values handled appropriately for safety checks?\n",
    "\n",
    "- Do you also capture labels of triggered rows?\n",
    "\n",
    "- Should thresholds vary by segment/time window?\n",
    "\n",
    "- Is alert logic robust against known noisy outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2261bb7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7dbbb",
   "metadata": {},
   "source": [
    "Use `any()` for one-hit alert logic, then inspect triggered labels to diagnose root causes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61915bbf",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Trigger incident response if any service latency exceeds SLA threshold.\n",
    "\n",
    "Scenario: one SLA breach is enough to open an incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "409db0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breach mask: {'svc_A': False, 'svc_B': False, 'svc_C': False, 'svc_D': True}\n",
      "Has breach?: True\n",
      "Breach labels: ['svc_D']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency_ms = pd.Series(\n",
    "    [180, 220, 190, 260],\n",
    "    index=[\"svc_A\", \"svc_B\", \"svc_C\", \"svc_D\"],\n",
    "    name=\"p95_latency\",\n",
    ")\n",
    "\n",
    "breach_mask = latency_ms.gt(250)\n",
    "has_breach = breach_mask.any()\n",
    "breach_labels = breach_mask.index[breach_mask]\n",
    "\n",
    "print(\"Breach mask:\", breach_mask.to_dict())\n",
    "print(\"Has breach?:\", has_breach)\n",
    "print(\"Breach labels:\", list(breach_labels))\n",
    "\n",
    "assert bool(has_breach) is True\n",
    "assert list(breach_labels) == [\"svc_D\"]\n",
    "assert int(breach_mask.sum()) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e71691",
   "metadata": {},
   "source": [
    "##### Series.isin(values)\n",
    "`isin(values)` checks membership element-wise and returns a boolean Series. It is useful for whitelist/blacklist filtering of categories, IDs, or codes. This is a compact way to express \"value is in this allowed set\" logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "ed940923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "b50b617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b     True\n",
       "c    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.isin([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22a443",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666545a6",
   "metadata": {},
   "source": [
    "`series.isin(values)` marks each row `True` if its value appears in the provided collection, otherwise `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6e8cd",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735890ce",
   "metadata": {},
   "source": [
    "- `values` (set/list-like/Series/Index): collection of candidate values used for membership testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11361a47",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca697b3",
   "metadata": {},
   "source": [
    "Think of checking each spreadsheet row against an approved list.\n",
    "\n",
    "- In approved list -> `True`.\n",
    "\n",
    "- Not in list -> `False`.\n",
    "\n",
    "You get a pass/fail mask by membership."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54928e2c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52bb99",
   "metadata": {},
   "source": [
    "- Pandas builds an efficient membership test from the provided `values`.\n",
    "\n",
    "- Each Series element is checked against that set/list.\n",
    "\n",
    "- Result keeps original index labels with boolean membership outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68eb16d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ed260",
   "metadata": {},
   "source": [
    "- Type mismatches (e.g., string vs numeric IDs) can produce all False unexpectedly.\n",
    "\n",
    "- Very large candidate lists can add memory/time cost.\n",
    "\n",
    "- Missing values need explicit handling if they should be treated as members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c78a8e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5b28f",
   "metadata": {},
   "source": [
    "- Are Series values and candidate values in the same dtype/format?\n",
    "\n",
    "- Should missing values be considered in/out of the set?\n",
    "\n",
    "- Is membership list curated and versioned?\n",
    "\n",
    "- Are you using `isin` for inclusion or exclusion logic?\n",
    "\n",
    "- Do you need labels of matched rows for downstream actions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4a2ce",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f14af",
   "metadata": {},
   "source": [
    "Use `isin(values)` to build readable inclusion masks, then filter rows by label with confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5dd96",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Keep only orders from approved sales channels for official revenue reporting.\n",
    "\n",
    "Scenario: finance accepts only `web` and `store` channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "dbcb1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask: {'o1': True, 'o2': False, 'o3': True, 'o4': False}\n",
      "Kept: {'o1': 'web', 'o3': 'store'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "channel = pd.Series(\n",
    "    [\"web\", \"app\", \"store\", \"partner\"],\n",
    "    index=[\"o1\", \"o2\", \"o3\", \"o4\"],\n",
    "    name=\"channel\",\n",
    ")\n",
    "\n",
    "approved = [\"web\", \"store\"]\n",
    "mask = channel.isin(approved)\n",
    "kept = channel[mask]\n",
    "\n",
    "print(\"Mask:\", mask.to_dict())\n",
    "print(\"Kept:\", kept.to_dict())\n",
    "\n",
    "assert list(kept.index) == [\"o1\", \"o3\"]\n",
    "assert bool(mask.loc[\"o2\"]) is False\n",
    "assert int(mask.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414ba1a",
   "metadata": {},
   "source": [
    "##### Series.between(left, right)\n",
    "`between(left, right)` checks whether each value falls within a numeric/date interval. It returns a boolean Series and is very common for banding and range filters. Boundary inclusion is configurable with `inclusive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "bf0406a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "5665bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    True\n",
       "b    True\n",
       "c    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.between(10, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdc575",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae40e7",
   "metadata": {},
   "source": [
    "`series.between(left, right)` marks rows `True` when values fall inside the specified interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13a524",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae898cf4",
   "metadata": {},
   "source": [
    "- `left` (scalar): lower bound of the interval.\n",
    "\n",
    "- `right` (scalar): upper bound of the interval.\n",
    "\n",
    "- `inclusive` (`'both'`, `'neither'`, `'left'`, `'right'`, default `'both'`): boundary inclusion rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5dcfc",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859f68a",
   "metadata": {},
   "source": [
    "Think of asking whether each row value is inside a target band.\n",
    "\n",
    "- Inside band -> `True`.\n",
    "\n",
    "- Outside band -> `False`.\n",
    "\n",
    "You can choose if edges count as inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ff3a4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db739e7c",
   "metadata": {},
   "source": [
    "- Pandas applies lower and upper comparisons to each value.\n",
    "\n",
    "- It combines those checks according to the `inclusive` setting.\n",
    "\n",
    "- Output is a boolean Series with original labels preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa8499",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a8e6a",
   "metadata": {},
   "source": [
    "- Wrong boundary mode (`inclusive`) can silently change pass counts.\n",
    "\n",
    "- Type mismatch between bounds and Series values causes errors or wrong logic.\n",
    "\n",
    "- Missing values evaluate to False in the resulting mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb982d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bad85",
   "metadata": {},
   "source": [
    "- Should boundaries be inclusive or exclusive?\n",
    "\n",
    "- Are bounds in the same unit/timezone as the Series?\n",
    "\n",
    "- Are missing values intentionally excluded?\n",
    "\n",
    "- Should range checks vary by segment/entity?\n",
    "\n",
    "- Do you need labels of out-of-range rows for remediation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ab381",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade440db",
   "metadata": {},
   "source": [
    "Use `between(left, right)` for clear interval rules, and set `inclusive` explicitly to avoid boundary ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6addb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find sensors operating within acceptable temperature band before compliance export.\n",
    "\n",
    "Scenario: accepted range is 18 to 25 degrees, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "4717330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK mask: {'s1': False, 's2': True, 's3': True, 's4': False}\n",
      "Strict mask: {'s1': False, 's2': True, 's3': False, 's4': False}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp = pd.Series(\n",
    "    [17.5, 19.0, 25.0, 26.2],\n",
    "    index=[\"s1\", \"s2\", \"s3\", \"s4\"],\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "ok_mask = temp.between(18.0, 25.0, inclusive=\"both\")\n",
    "strict_mask = temp.between(18.0, 25.0, inclusive=\"neither\")\n",
    "ok = temp[ok_mask]\n",
    "\n",
    "print(\"OK mask:\", ok_mask.to_dict())\n",
    "print(\"Strict mask:\", strict_mask.to_dict())\n",
    "\n",
    "assert list(ok.index) == [\"s2\", \"s3\"]\n",
    "assert bool(strict_mask.loc[\"s3\"]) is False\n",
    "assert int(ok_mask.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04046c1",
   "metadata": {},
   "source": [
    "##### Series.equals(other)\n",
    "`equals(other)` checks full equality between two Series and returns one boolean. It compares shape, index labels/order, dtype, and values (with matching missing positions). It is useful for regression tests and pipeline consistency checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "bd5d6b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "9405bf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.equals(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f958c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2879da",
   "metadata": {},
   "source": [
    "`series.equals(other)` answers: \"Are these two Series exactly the same in structure and values?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c8da4",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d9c41",
   "metadata": {},
   "source": [
    "- `other` (`object`, typically `Series`): object to compare for exact equality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd67fed",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a7bdd",
   "metadata": {},
   "source": [
    "Think of comparing two spreadsheet columns cell-by-cell with row names.\n",
    "\n",
    "- Same row labels/order and same values -> `True`.\n",
    "\n",
    "- Any mismatch -> `False`.\n",
    "\n",
    "It is an exact-match verdict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0dcfe",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628ddc0",
   "metadata": {},
   "source": [
    "- Pandas verifies both objects are compatible Series-like structures.\n",
    "\n",
    "- It checks index alignment/order, dtype compatibility, and value equality.\n",
    "\n",
    "- Matching missing values at the same positions are treated as equal for this check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881d64b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c878c",
   "metadata": {},
   "source": [
    "- Very strict: same values but different index order returns False.\n",
    "\n",
    "- Dtype differences can fail equality even when printed values look similar.\n",
    "\n",
    "- Returns only one boolean; it does not explain where mismatch happened."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c549d7",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e4f66",
   "metadata": {},
   "source": [
    "- Do you need strict identity or approximate/value-only equality?\n",
    "\n",
    "- Are index order and dtype intentionally controlled before checking?\n",
    "\n",
    "- Should comparison ignore name/index metadata in your use case?\n",
    "\n",
    "- Do you need diagnostics on mismatch locations (`compare`) after False?\n",
    "\n",
    "- Are both Series derived from the same refresh window/version?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d898dee7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f332d",
   "metadata": {},
   "source": [
    "Use `equals(other)` for strict regression checks when full Series identity matters, not just similar values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95106a15",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate that a refactored transformation reproduces exactly the legacy output.\n",
    "\n",
    "Scenario: deployment gate passes only if new and old Series are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "dd3e84d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact same?: True\n",
      "Reordered equal?: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "legacy = pd.Series([1.0, 2.0, None], index=[\"a\", \"b\", \"c\"], name=\"score\")\n",
    "candidate_same = pd.Series([1.0, 2.0, None], index=[\"a\", \"b\", \"c\"], name=\"score\")\n",
    "candidate_reordered = pd.Series([1.0, 2.0, None], index=[\"b\", \"a\", \"c\"], name=\"score\")\n",
    "\n",
    "same_ok = legacy.equals(candidate_same)\n",
    "reordered_ok = legacy.equals(candidate_reordered)\n",
    "\n",
    "print(\"Exact same?:\", same_ok)\n",
    "print(\"Reordered equal?:\", reordered_ok)\n",
    "\n",
    "assert bool(same_ok) is True\n",
    "assert bool(reordered_ok) is False\n",
    "assert legacy.index.equals(candidate_same.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da00ec",
   "metadata": {},
   "source": [
    "#### Missing Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c421b",
   "metadata": {},
   "source": [
    "##### Series.isna()\n",
    "`isna()` returns a boolean mask identifying missing values in a Series. It is a primary diagnostic tool before cleaning or imputing data. The result preserves original index labels, so missing rows are easy to trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "40bd450b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "52f4ed8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    False\n",
       "b    False\n",
       "c    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1dbeba",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabb1a9",
   "metadata": {},
   "source": [
    "`series.isna()` marks each row `True` when the value is missing (`NaN`/`None`/`pd.NA`), otherwise `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d57c79",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f12394",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Use `series.isna()` to build a missing-value mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d240b24",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73f0c2",
   "metadata": {},
   "source": [
    "Think of highlighting blank cells in a spreadsheet column.\n",
    "\n",
    "- Blank -> `True`.\n",
    "\n",
    "- Filled -> `False`.\n",
    "\n",
    "You get a map of where data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec0cb0",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95b80b",
   "metadata": {},
   "source": [
    "- Pandas checks each element against its missing-value rules.\n",
    "\n",
    "- Missing entries are flagged as `True`.\n",
    "\n",
    "- Output is a boolean Series aligned with original index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9e9c2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ca94a",
   "metadata": {},
   "source": [
    "- It identifies missingness but does not fix it.\n",
    "\n",
    "- Different dtypes may represent missing values differently under the hood.\n",
    "\n",
    "- You still need business rules to decide how to handle the flagged rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce2d06",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632826a1",
   "metadata": {},
   "source": [
    "- Are missing values expected for this field?\n",
    "\n",
    "- Which labels are missing and why?\n",
    "\n",
    "- Should missing rows be dropped, filled, or escalated?\n",
    "\n",
    "- Is missingness concentrated in specific segments/time windows?\n",
    "\n",
    "- Do downstream models tolerate missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45177290",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59c1e6",
   "metadata": {},
   "source": [
    "Use `isna()` to locate missing entries first, then apply a deliberate cleanup strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f9183",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Find missing sensor readings and list affected sensor IDs for data collection retries.\n",
    "\n",
    "Scenario: pipeline must flag missing rows before daily KPI computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "1a8b6545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing mask: {'sensor_A': False, 'sensor_B': True, 'sensor_C': False, 'sensor_D': True}\n",
      "Missing labels: ['sensor_B', 'sensor_D']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reading = pd.Series(\n",
    "    [10.5, None, 9.8, pd.NA],\n",
    "    index=[\"sensor_A\", \"sensor_B\", \"sensor_C\", \"sensor_D\"],\n",
    "    dtype=\"Float64\",\n",
    "    name=\"reading\",\n",
    ")\n",
    "\n",
    "missing_mask = reading.isna()\n",
    "missing_labels = reading.index[missing_mask]\n",
    "\n",
    "print(\"Missing mask:\", missing_mask.to_dict())\n",
    "print(\"Missing labels:\", list(missing_labels))\n",
    "\n",
    "assert list(missing_labels) == [\"sensor_B\", \"sensor_D\"]\n",
    "assert int(missing_mask.sum()) == 2\n",
    "assert bool(missing_mask.loc[\"sensor_C\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b292d2f",
   "metadata": {},
   "source": [
    "##### Series.notna()\n",
    "`notna()` returns a boolean mask of non-missing values in a Series. It is often used to keep valid observations before aggregation or modeling. Like `isna()`, index labels are preserved for traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "02d5e1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "10d46b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    True\n",
       "b    True\n",
       "c    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296d041",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb098e",
   "metadata": {},
   "source": [
    "`series.notna()` marks rows `True` when values are present, and `False` when missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d1e7a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3621c4",
   "metadata": {},
   "source": [
    "- No parameters.\n",
    "\n",
    "- Use `series.notna()` to build a valid-data mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298839d",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bf944",
   "metadata": {},
   "source": [
    "Think of marking every filled spreadsheet cell as usable.\n",
    "\n",
    "- Filled -> `True`.\n",
    "\n",
    "- Blank -> `False`.\n",
    "\n",
    "You get a map of usable rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734afe7",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8c3a3",
   "metadata": {},
   "source": [
    "- Pandas applies missing-value detection then negates it.\n",
    "\n",
    "- Present values become `True`; missing become `False`.\n",
    "\n",
    "- Result is a boolean Series aligned to original labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070b84e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec377c",
   "metadata": {},
   "source": [
    "- It only identifies validity, not data correctness.\n",
    "\n",
    "- Non-missing but invalid placeholder values (e.g., -999) are still `True`.\n",
    "\n",
    "- You may need additional semantic validation after `notna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55149b80",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa3f20",
   "metadata": {},
   "source": [
    "- Is non-missing equivalent to valid for this field?\n",
    "\n",
    "- Are sentinel placeholders contaminating quality checks?\n",
    "\n",
    "- Should filtering retain index for downstream alignment?\n",
    "\n",
    "- Do you need counts of valid rows by segment?\n",
    "\n",
    "- Are missing labels being monitored over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575bd73b",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6decc20e",
   "metadata": {},
   "source": [
    "Use `notna()` to isolate usable rows quickly, then apply business validation rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f211113",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Filter out missing refund amounts before computing average refund value.\n",
    "\n",
    "Scenario: finance metric should only use rows with observed refund values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "5cdea5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid mask: {'ord_1': True, 'ord_2': False, 'ord_3': True, 'ord_4': True}\n",
      "Valid refunds: {'ord_1': 5.0, 'ord_3': 7.5, 'ord_4': 6.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "refund = pd.Series(\n",
    "    [5.0, None, 7.5, 6.0],\n",
    "    index=[\"ord_1\", \"ord_2\", \"ord_3\", \"ord_4\"],\n",
    "    name=\"refund\",\n",
    ")\n",
    "\n",
    "valid_mask = refund.notna()\n",
    "valid_refund = refund[valid_mask]\n",
    "\n",
    "print(\"Valid mask:\", valid_mask.to_dict())\n",
    "print(\"Valid refunds:\", valid_refund.to_dict())\n",
    "\n",
    "assert list(valid_refund.index) == [\"ord_1\", \"ord_3\", \"ord_4\"]\n",
    "assert int(valid_mask.sum()) == 3\n",
    "assert bool(valid_mask.loc[\"ord_2\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fecc89",
   "metadata": {},
   "source": [
    "##### Series.dropna()\n",
    "`dropna()` removes missing-value rows from a Series. It is commonly used to create clean subsets for stats and model inputs. By default, labels of remaining rows are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "8216be65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "734197a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e11dc",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691d165",
   "metadata": {},
   "source": [
    "`series.dropna()` returns the same Series without missing rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684a50d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2cadf",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to drop missing values on (Series uses row axis).\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify Series in place if `True`; otherwise return a new Series.\n",
    "\n",
    "- `how` (`None` for Series): kept for API compatibility; not meaningfully used for 1D Series.\n",
    "\n",
    "- `ignore_index` (`bool`, default `False`): reset index to `0..n-1` in result if `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969616cf",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcef821",
   "metadata": {},
   "source": [
    "Think of deleting blank rows from a spreadsheet column.\n",
    "\n",
    "- Blank rows are removed.\n",
    "\n",
    "- Filled rows remain in original order.\n",
    "\n",
    "Optionally, you can renumber rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7161ba",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a384f5",
   "metadata": {},
   "source": [
    "- Pandas builds a non-missing mask and keeps only `True` rows.\n",
    "\n",
    "- Order is preserved; labels are preserved unless `ignore_index=True`.\n",
    "\n",
    "- Result is clean 1D data ready for strict downstream operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cd07e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b366e6",
   "metadata": {},
   "source": [
    "- Dropping rows can bias metrics if missingness is not random.\n",
    "\n",
    "- `inplace=True` can make debugging harder by mutating original data.\n",
    "\n",
    "- Label removal can break alignment with other objects if not expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189dea9",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4426e2",
   "metadata": {},
   "source": [
    "- Is dropping missing rows statistically acceptable here?\n",
    "\n",
    "- Do you need to preserve original labels for alignment?\n",
    "\n",
    "- Should index be reset after dropping?\n",
    "\n",
    "- Are you tracking how many rows were removed?\n",
    "\n",
    "- Would imputation be better than row removal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28593a5",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11527125",
   "metadata": {},
   "source": [
    "Use `dropna()` for clean subsets when missing rows cannot be used, and monitor data loss explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3eae8",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prepare a model input Series by removing rows with missing target values.\n",
    "\n",
    "Scenario: training pipeline requires complete target labels only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "9d6838ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: {'r1': 1.0, 'r3': 0.0, 'r4': 1.0}\n",
      "Clean reset index: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "target = pd.Series(\n",
    "    [1, None, 0, 1],\n",
    "    index=[\"r1\", \"r2\", \"r3\", \"r4\"],\n",
    "    name=\"churn\",\n",
    ")\n",
    "\n",
    "clean = target.dropna()\n",
    "clean_reset = target.dropna(ignore_index=True)\n",
    "\n",
    "print(\"Clean:\", clean.to_dict())\n",
    "print(\"Clean reset index:\", list(clean_reset.index))\n",
    "\n",
    "assert list(clean.index) == [\"r1\", \"r3\", \"r4\"]\n",
    "assert list(clean_reset.index) == [0, 1, 2]\n",
    "assert len(clean) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf2bea",
   "metadata": {},
   "source": [
    "##### Series.fillna(value)\n",
    "`fillna(value)` replaces missing entries using a provided fill value or mapping. It is a common imputation step before aggregation, feature engineering, or exports. Use `limit` when only part of a gap should be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "79567ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "c247b564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64be697",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57943ad3",
   "metadata": {},
   "source": [
    "`series.fillna(value)` fills missing rows with the value you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ff1e7",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27b0c3",
   "metadata": {},
   "source": [
    "- `value` (scalar, dict-like, Series, DataFrame): replacement value(s) for missing entries.\n",
    "\n",
    "- `axis` (`None` or axis, default `None`): axis control; Series uses row axis.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate original Series if `True`.\n",
    "\n",
    "- `limit` (`int` or `None`, default `None`): maximum number of consecutive missing values to fill."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85780712",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8898f",
   "metadata": {},
   "source": [
    "Think of replacing blank spreadsheet cells with a default value.\n",
    "\n",
    "- Blank cells become your fallback.\n",
    "\n",
    "- Non-blank cells stay unchanged.\n",
    "\n",
    "You choose whether to fill all blanks or only some."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8711c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa530677",
   "metadata": {},
   "source": [
    "- Pandas identifies missing positions first.\n",
    "\n",
    "- Missing positions are replaced by `value` based on alignment rules.\n",
    "\n",
    "- `limit` can constrain fill propagation in consecutive gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936bb56",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682acbf0",
   "metadata": {},
   "source": [
    "- Poor fill values can bias downstream metrics/models.\n",
    "\n",
    "- `inplace=True` can hide transformation steps in notebooks.\n",
    "\n",
    "- Filling all missing values may remove useful missingness signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1113190",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6253c",
   "metadata": {},
   "source": [
    "- Is the fill value statistically/business-appropriate?\n",
    "\n",
    "- Should only short gaps be filled (`limit`)?\n",
    "\n",
    "- Do you need segment-specific fills instead of global default?\n",
    "\n",
    "- Should missingness be preserved as separate feature before filling?\n",
    "\n",
    "- Are filled labels tracked for audit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762167f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed9fb4",
   "metadata": {},
   "source": [
    "Use `fillna(value)` to impute missing values deliberately, and document the fill rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1c830",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Impute missing coupon discount values with 0 while limiting overfill in long gaps.\n",
    "\n",
    "Scenario: reporting treats missing discount as no discount for most rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "77ce5e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled all: {'o1': 5.0, 'o2': 0.0, 'o3': 0.0, 'o4': 10.0}\n",
      "Filled limited: {'o1': 5.0, 'o2': 0.0, 'o3': nan, 'o4': 10.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "discount = pd.Series(\n",
    "    [5.0, None, None, 10.0],\n",
    "    index=[\"o1\", \"o2\", \"o3\", \"o4\"],\n",
    "    name=\"discount_pct\",\n",
    ")\n",
    "\n",
    "filled_all = discount.fillna(0)\n",
    "filled_limited = discount.fillna(0, limit=1)\n",
    "\n",
    "print(\"Filled all:\", filled_all.to_dict())\n",
    "print(\"Filled limited:\", filled_limited.to_dict())\n",
    "\n",
    "assert float(filled_all.loc[\"o2\"]) == 0.0\n",
    "assert pd.isna(filled_limited.loc[\"o3\"])\n",
    "assert int(filled_all.isna().sum()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147039a",
   "metadata": {},
   "source": [
    "##### Series.ffill()\n",
    "`ffill()` forward-fills missing values using the last valid observation. It is common in time series where the latest known state carries forward. Use `limit` to restrict how far values propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "dc6926b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "6ab48bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3aa829",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663c6ad",
   "metadata": {},
   "source": [
    "`series.ffill()` fills each missing row with the nearest valid value above it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9b377",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13187aa0",
   "metadata": {},
   "source": [
    "- `axis` (`None` or axis, default `None`): axis control; Series uses row axis.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify original Series if `True`.\n",
    "\n",
    "- `limit` (`int` or `None`, default `None`): max consecutive missing values to forward-fill.\n",
    "\n",
    "- `limit_area` (`'inside'`, `'outside'`, or `None`, default `None`): restrict where fill is applied in gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa514e9",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81d4b7",
   "metadata": {},
   "source": [
    "Think of copying the last known value downward in a spreadsheet.\n",
    "\n",
    "- Missing cell takes the value above.\n",
    "\n",
    "- Keeps going until a new real value appears.\n",
    "\n",
    "This carries state forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293aa37",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98df48",
   "metadata": {},
   "source": [
    "- Pandas scans top-to-bottom tracking the latest valid value.\n",
    "\n",
    "- Missing rows are replaced with that tracked value under `limit` constraints.\n",
    "\n",
    "- Leading missing rows stay missing until a first valid value appears."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a5f18",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1808095",
   "metadata": {},
   "source": [
    "- Can over-propagate stale values if gaps are long.\n",
    "\n",
    "- Leading missing block is not filled without prior value.\n",
    "\n",
    "- Not appropriate when values change rapidly and carry-forward is invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333399d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d10006",
   "metadata": {},
   "source": [
    "- Is carry-forward assumption valid for this metric?\n",
    "\n",
    "- Should long missing stretches remain missing (`limit`)?\n",
    "\n",
    "- Are leading gaps expected and acceptable?\n",
    "\n",
    "- Do you need to flag imputed rows after filling?\n",
    "\n",
    "- Would interpolation or model-based imputation be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40af452",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ba188",
   "metadata": {},
   "source": [
    "Use `ffill()` when last-known values are meaningful and controlled propagation is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60304c",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Carry last known sensor calibration value forward during brief telemetry gaps.\n",
    "\n",
    "Scenario: process logic uses latest valid calibration until an update arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "189a0859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward fill: {'t1': nan, 't2': 1.0, 't3': 1.0, 't4': 1.0, 't5': 2.0}\n",
      "Forward fill limit=1: {'t1': nan, 't2': 1.0, 't3': 1.0, 't4': nan, 't5': 2.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "calibration = pd.Series(\n",
    "    [None, 1.0, None, None, 2.0],\n",
    "    index=[\"t1\", \"t2\", \"t3\", \"t4\", \"t5\"],\n",
    "    name=\"calibration\",\n",
    ")\n",
    "\n",
    "ff = calibration.ffill()\n",
    "ff_limit = calibration.ffill(limit=1)\n",
    "\n",
    "print(\"Forward fill:\", ff.to_dict())\n",
    "print(\"Forward fill limit=1:\", ff_limit.to_dict())\n",
    "\n",
    "assert pd.isna(ff.loc[\"t1\"])\n",
    "assert float(ff.loc[\"t4\"]) == 1.0\n",
    "assert pd.isna(ff_limit.loc[\"t4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbf490",
   "metadata": {},
   "source": [
    "##### Series.bfill()\n",
    "`bfill()` backward-fills missing values using the next valid observation below. It is useful when future known values can validly backfill short gaps. As with `ffill`, `limit` prevents excessive propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "a47f6402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "3be3d6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c63b3",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351a960",
   "metadata": {},
   "source": [
    "`series.bfill()` fills a missing row with the next available value below it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392222c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9c3b4",
   "metadata": {},
   "source": [
    "- `axis` (`None` or axis, default `None`): axis control; Series uses row axis.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate original Series if `True`.\n",
    "\n",
    "- `limit` (`int` or `None`, default `None`): max consecutive missing values to backward-fill.\n",
    "\n",
    "- `limit_area` (`'inside'`, `'outside'`, or `None`, default `None`): restrict where backfill is allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab028ebf",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3198d41",
   "metadata": {},
   "source": [
    "Think of copying the next known value upward into blanks.\n",
    "\n",
    "- Missing cell takes the value below.\n",
    "\n",
    "- Useful when future value can stand in for short gaps.\n",
    "\n",
    "This pulls information backward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5e36c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81262a",
   "metadata": {},
   "source": [
    "- Pandas scans bottom-to-top tracking the next valid value.\n",
    "\n",
    "- Missing rows are replaced with that next value under `limit` rules.\n",
    "\n",
    "- Trailing missing rows remain missing if no later value exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0effdef",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596c6e7",
   "metadata": {},
   "source": [
    "- Can introduce look-ahead bias in time-series modeling.\n",
    "\n",
    "- Trailing missing block may stay unresolved.\n",
    "\n",
    "- Business meaning may be invalid if future value should not influence past row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70294ef7",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6dc832",
   "metadata": {},
   "source": [
    "- Is backfilling acceptable or does it leak future information?\n",
    "\n",
    "- Should long gaps remain missing via `limit`?\n",
    "\n",
    "- Are trailing gaps expected and handled downstream?\n",
    "\n",
    "- Do you need to tag rows filled by bfill for audit?\n",
    "\n",
    "- Would forward fill or interpolation be more defensible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cf0ae",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe7b00",
   "metadata": {},
   "source": [
    "Use `bfill()` carefully when next-known values are valid substitutes and look-ahead bias is not a concern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c0f78",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Backfill short sensor gaps from the next confirmed reading in offline cleanup.\n",
    "\n",
    "Scenario: historical correction step is allowed to use nearby future readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "1feaf7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward fill: {'t1': 5.0, 't2': 5.0, 't3': 5.0, 't4': 7.0, 't5': 7.0}\n",
      "Backward fill limit=1: {'t1': nan, 't2': 5.0, 't3': 5.0, 't4': 7.0, 't5': 7.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signal = pd.Series(\n",
    "    [None, None, 5.0, None, 7.0],\n",
    "    index=[\"t1\", \"t2\", \"t3\", \"t4\", \"t5\"],\n",
    "    name=\"signal\",\n",
    ")\n",
    "\n",
    "bf = signal.bfill()\n",
    "bf_limit = signal.bfill(limit=1)\n",
    "\n",
    "print(\"Backward fill:\", bf.to_dict())\n",
    "print(\"Backward fill limit=1:\", bf_limit.to_dict())\n",
    "\n",
    "assert float(bf.loc[\"t1\"]) == 5.0\n",
    "assert pd.isna(bf_limit.loc[\"t1\"])\n",
    "assert float(bf.loc[\"t4\"]) == 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4686e2b",
   "metadata": {},
   "source": [
    "##### Series.interpolate()\n",
    "`interpolate()` estimates missing values from neighboring observations. It is useful for numeric/time-series data when smooth continuity assumptions are reasonable. Method and direction parameters control how estimates are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "32a23ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "34fa6fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0f6c2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e08e97",
   "metadata": {},
   "source": [
    "`series.interpolate()` fills missing values by estimating them from nearby known values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af82f9a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4655bd",
   "metadata": {},
   "source": [
    "- `method` (str, default `'linear'`): interpolation strategy (e.g., `'linear'`, `'time'`, `'nearest'`, etc., depending on index/data).\n",
    "\n",
    "- `axis` (`0`, default `0`): interpolation axis; for Series this is row-wise.\n",
    "\n",
    "- `limit` (`int` or `None`, default `None`): max consecutive missing values to fill.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate original Series if `True`.\n",
    "\n",
    "- `limit_direction` (`'forward'`, `'backward'`, `'both'`, or `None`): allowed fill direction.\n",
    "\n",
    "- `limit_area` (`'inside'`, `'outside'`, or `None`): restrict interpolation region.\n",
    "\n",
    "- `**kwargs`: method-specific options passed to interpolation backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f1403",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1cef1",
   "metadata": {},
   "source": [
    "Think of drawing a line through known points and estimating values in the gaps.\n",
    "\n",
    "- Missing points are inferred from neighbors.\n",
    "\n",
    "- Smoothness assumptions drive estimates.\n",
    "\n",
    "This fills gaps without using a constant fallback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7c799",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc4d0a",
   "metadata": {},
   "source": [
    "- Pandas identifies missing runs and applies the chosen interpolation method.\n",
    "\n",
    "- For linear interpolation, estimates are proportional between surrounding known points.\n",
    "\n",
    "- Constraints (`limit`, direction, area) bound where filling occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a6a06",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2d571",
   "metadata": {},
   "source": [
    "- Interpolated values are estimates, not observed data.\n",
    "\n",
    "- Wrong method assumptions can introduce bias.\n",
    "\n",
    "- Extrapolation at boundaries may remain missing depending on settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79616db",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5c72b",
   "metadata": {},
   "source": [
    "- Is interpolation scientifically/business-wise justified for this metric?\n",
    "\n",
    "- Which method best matches data dynamics (linear/time/nearest)?\n",
    "\n",
    "- Should edge gaps be filled or preserved?\n",
    "\n",
    "- Are interpolated rows tagged for downstream transparency?\n",
    "\n",
    "- How sensitive are results to interpolation settings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02978344",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf716e0",
   "metadata": {},
   "source": [
    "Use `interpolate()` for numeric gap-filling when continuity assumptions are valid and documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05aecac",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Estimate missing minute-level energy readings between two observed points.\n",
    "\n",
    "Scenario: linear interpolation is accepted for short telemetry dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "109350fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated: {'m1': 10.0, 'm2': 20.0, 'm3': 30.0, 'm4': 40.0, 'm5': 50.0}\n",
      "Interpolated limit=1: {'m1': 10.0, 'm2': 20.0, 'm3': 30.0, 'm4': 40.0, 'm5': 50.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "energy = pd.Series(\n",
    "    [10.0, None, 30.0, None, 50.0],\n",
    "    index=[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\"],\n",
    "    name=\"kwh\",\n",
    ")\n",
    "\n",
    "interp = energy.interpolate(method=\"linear\")\n",
    "interp_limited = energy.interpolate(method=\"linear\", limit=1)\n",
    "\n",
    "print(\"Interpolated:\", interp.to_dict())\n",
    "print(\"Interpolated limit=1:\", interp_limited.to_dict())\n",
    "\n",
    "assert float(interp.loc[\"m2\"]) == 20.0\n",
    "assert float(interp.loc[\"m4\"]) == 40.0\n",
    "assert int(interp.isna().sum()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e205ea1",
   "metadata": {},
   "source": [
    "#### Sorting and handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cef06f",
   "metadata": {},
   "source": [
    "##### Series.sort_values()\n",
    "`sort_values()` orders a Series by its values and returns a sorted Series. It is useful for ranking, top/bottom analysis, and ordered reporting outputs. You can control direction, missing-value position, and stability details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "cffd2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "d676649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c8976",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe6208",
   "metadata": {},
   "source": [
    "`series.sort_values()` rearranges rows from smallest to largest value by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e4a24",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc33d1",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to sort; for Series this is the row axis.\n",
    "\n",
    "- `ascending` (`bool` or sequence, default `True`): sort order direction.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify original Series if `True`.\n",
    "\n",
    "- `kind` (`str`, default `'quicksort'`): sorting algorithm (`'quicksort'`, `'mergesort'`, etc.).\n",
    "\n",
    "- `na_position` (`'first'`/`'last'`, default `'last'`): position of missing values in result.\n",
    "\n",
    "- `ignore_index` (`bool`, default `False`): reset index to `0..n-1` in output.\n",
    "\n",
    "- `key` (callable or `None`): transformation function applied before sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8eb7b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c155a",
   "metadata": {},
   "source": [
    "Think of sorting a spreadsheet column by cell values.\n",
    "\n",
    "- Small-to-large or large-to-small.\n",
    "\n",
    "- Decide where blanks go.\n",
    "\n",
    "Row labels travel with their values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236e41c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa53e0",
   "metadata": {},
   "source": [
    "- Pandas computes a value-based ordering index.\n",
    "\n",
    "- It reorders the Series using that order while preserving label-value pairing.\n",
    "\n",
    "- Missing values are placed per `na_position` policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326d75e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321637e",
   "metadata": {},
   "source": [
    "- Sorting changes row order and can break assumptions of positional code.\n",
    "\n",
    "- Missing-value placement affects top/bottom interpretations.\n",
    "\n",
    "- In-place sort can hide transformations in notebooks/pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403d4a6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96995f6e",
   "metadata": {},
   "source": [
    "- Do you need ascending or descending order?\n",
    "\n",
    "- Where should missing values appear?\n",
    "\n",
    "- Should index be reset after sorting?\n",
    "\n",
    "- Is stable sorting needed for ties?\n",
    "\n",
    "- Do labels need to remain mapped for downstream joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326e70c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ef40d",
   "metadata": {},
   "source": [
    "Use `sort_values()` to reorder by magnitude while keeping labels attached to each value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2be5a0",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Order products by margin and review highest-margin SKUs first.\n",
    "\n",
    "Scenario: analysts want descending order with missing margins shown first for QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e3d9bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descending: {'sku_C': nan, 'sku_B': 0.32, 'sku_D': 0.21, 'sku_A': 0.15}\n",
      "Ascending labels: ['sku_A', 'sku_D', 'sku_B', 'sku_C']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "margin = pd.Series(\n",
    "    [0.15, 0.32, None, 0.21],\n",
    "    index=[\"sku_A\", \"sku_B\", \"sku_C\", \"sku_D\"],\n",
    "    name=\"margin\",\n",
    ")\n",
    "\n",
    "desc = margin.sort_values(ascending=False, na_position=\"first\")\n",
    "asc = margin.sort_values(ascending=True, na_position=\"last\")\n",
    "\n",
    "print(\"Descending:\", desc.to_dict())\n",
    "print(\"Ascending labels:\", list(asc.index))\n",
    "\n",
    "assert pd.isna(desc.iloc[0])\n",
    "assert list(asc.index) == [\"sku_A\", \"sku_D\", \"sku_B\", \"sku_C\"]\n",
    "assert float(asc.iloc[0]) == 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a7b9d",
   "metadata": {},
   "source": [
    "##### Series.sort_index()\n",
    "`sort_index()` orders a Series by index labels instead of values. It is useful when index order encodes business meaning (IDs, dates, hierarchy). This is often used before alignment, joins, or presentation formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "7eddd059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "2251d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2028c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75451d8",
   "metadata": {},
   "source": [
    "`series.sort_index()` rearranges rows by label order, not by value size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557655a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a07a0",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to sort; for Series this is row labels.\n",
    "\n",
    "- `level` (label/int or `None`): MultiIndex level to sort by when relevant.\n",
    "\n",
    "- `ascending` (`bool` or sequence, default `True`): sort direction for index labels.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate original Series if `True`.\n",
    "\n",
    "- `kind` (`str`, default `'quicksort'`): sorting algorithm.\n",
    "\n",
    "- `na_position` (`'first'`/`'last'`, default `'last'`): where missing index labels go.\n",
    "\n",
    "- `sort_remaining` (`bool`, default `True`): MultiIndex behavior for remaining levels.\n",
    "\n",
    "- `ignore_index` (`bool`, default `False`): reset result index.\n",
    "\n",
    "- `key` (callable or `None`): transformation function applied to index before sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b40b73",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee166b",
   "metadata": {},
   "source": [
    "Think of sorting rows by row names in a spreadsheet.\n",
    "\n",
    "- Values stay attached to their row names.\n",
    "\n",
    "- Only label order changes.\n",
    "\n",
    "Great for making index order predictable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4b67a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0eb44",
   "metadata": {},
   "source": [
    "- Pandas derives an ordering from index labels (or levels).\n",
    "\n",
    "- It reorders the Series by that label order.\n",
    "\n",
    "- Value-index mapping remains unchanged for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c1940",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8dbf9",
   "metadata": {},
   "source": [
    "- Sorting labels can hide original arrival/order semantics.\n",
    "\n",
    "- Index dtype/casing can produce unexpected lexical order.\n",
    "\n",
    "- Resetting index may lose meaningful labels if done unintentionally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df67ac6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441beacd",
   "metadata": {},
   "source": [
    "- Is label ordering required for downstream operations?\n",
    "\n",
    "- Should sorting be case-insensitive (`key`)?\n",
    "\n",
    "- Do you need to preserve original index labels?\n",
    "\n",
    "- Are MultiIndex level priorities configured correctly?\n",
    "\n",
    "- Is this sort for logic correctness or just presentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e3773",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde1556",
   "metadata": {},
   "source": [
    "Use `sort_index()` when label order matters more than value order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e9de4",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Normalize mixed-case customer IDs into predictable order before report export.\n",
    "\n",
    "Scenario: exports should sort IDs alphabetically ignoring case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "803c8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default order: ['A_01', 'b_02', 'c_03']\n",
      "Case-insensitive order: ['A_01', 'b_02', 'c_03']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [90, 85, 88],\n",
    "    index=[\"b_02\", \"A_01\", \"c_03\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "sorted_default = kpi.sort_index()\n",
    "sorted_casefold = kpi.sort_index(key=lambda idx: idx.str.lower())\n",
    "\n",
    "print(\"Default order:\", list(sorted_default.index))\n",
    "print(\"Case-insensitive order:\", list(sorted_casefold.index))\n",
    "\n",
    "assert list(sorted_default.index) == [\"A_01\", \"b_02\", \"c_03\"]\n",
    "assert list(sorted_casefold.index) == [\"A_01\", \"b_02\", \"c_03\"]\n",
    "assert int(sorted_casefold.loc[\"b_02\"]) == 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480763e",
   "metadata": {},
   "source": [
    "##### Series.rank()\n",
    "`rank()` assigns order ranks to Series values. It is useful for scoring, leaderboards, percentile features, and tie-aware ordering. You can control tie strategy, direction, and percentile output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "83855a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "8e6be6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f9871",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dfdaab",
   "metadata": {},
   "source": [
    "`series.rank()` replaces values with their rank positions based on ordering rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5c3a5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e6475",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis to rank; Series uses row axis.\n",
    "\n",
    "- `method` (`'average'`, `'min'`, `'max'`, `'first'`, `'dense'`, default `'average'`): tie-handling strategy.\n",
    "\n",
    "- `numeric_only` (`bool`, default `False`): include only numeric values when relevant.\n",
    "\n",
    "- `na_option` (`'keep'`, `'top'`, `'bottom'`, default `'keep'`): handling of missing values in ranking.\n",
    "\n",
    "- `ascending` (`bool`, default `True`): rank low-to-high when `True`, reverse when `False`.\n",
    "\n",
    "- `pct` (`bool`, default `False`): return percentile ranks instead of absolute ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf46d7c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96dd97",
   "metadata": {},
   "source": [
    "Think of assigning positions in a race.\n",
    "\n",
    "- Faster times get better ranks (depending on direction).\n",
    "\n",
    "- Ties follow a chosen rule.\n",
    "\n",
    "You turn raw values into order positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf8198",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7e100",
   "metadata": {},
   "source": [
    "- Pandas sorts values conceptually and assigns positions.\n",
    "\n",
    "- Tie policy determines how equal values share or split ranks.\n",
    "\n",
    "- `pct=True` scales ranks into 0-1 style percent positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad5f53",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6d748",
   "metadata": {},
   "source": [
    "- Different tie methods produce different business outcomes.\n",
    "\n",
    "- Missing-value rank policy can subtly shift distributions.\n",
    "\n",
    "- Ranking ignores absolute distance between values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9086995",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be3b7b",
   "metadata": {},
   "source": [
    "- Which tie policy matches business rules?\n",
    "\n",
    "- Should highest value get rank 1 (`ascending=False`)?\n",
    "\n",
    "- Do you need percentile rank or absolute rank numbers?\n",
    "\n",
    "- How should missing values be treated in rank outputs?\n",
    "\n",
    "- Are rank labels needed for audit traceability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26e336",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ff33e",
   "metadata": {},
   "source": [
    "Use `rank()` to convert raw values into ordered positions with explicit tie handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd18aaf",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create a dense descending leaderboard for seller performance with tied scores.\n",
    "\n",
    "Scenario: tied sellers share same rank without gaps in rank numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "be52d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense rank: {'seller_A': 1.0, 'seller_B': 2.0, 'seller_C': 2.0, 'seller_D': 3.0}\n",
      "Pct rank: {'seller_A': 0.25, 'seller_B': 0.625, 'seller_C': 0.625, 'seller_D': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.Series(\n",
    "    [100, 80, 80, 60],\n",
    "    index=[\"seller_A\", \"seller_B\", \"seller_C\", \"seller_D\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "dense_rank = score.rank(ascending=False, method=\"dense\")\n",
    "pct_rank = score.rank(ascending=False, pct=True)\n",
    "\n",
    "print(\"Dense rank:\", dense_rank.to_dict())\n",
    "print(\"Pct rank:\", pct_rank.round(3).to_dict())\n",
    "\n",
    "assert dense_rank.loc[\"seller_A\"] == 1.0\n",
    "assert dense_rank.loc[\"seller_B\"] == dense_rank.loc[\"seller_C\"] == 2.0\n",
    "assert round(float(pct_rank.loc[\"seller_D\"]), 2) == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16ecb",
   "metadata": {},
   "source": [
    "##### Series.nlargest(n)\n",
    "`nlargest(n)` returns the top `n` largest values with their labels. It is efficient for top-k reporting and alerting use cases. Tie handling is configurable via the `keep` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "4502625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "5fc6ce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    30\n",
       "b    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.nlargest(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc05577",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93d00e",
   "metadata": {},
   "source": [
    "`series.nlargest(n)` gives the highest `n` rows without sorting the full Series manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807d37a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250788b",
   "metadata": {},
   "source": [
    "- `n` (`int`, default `5`): number of largest rows to return.\n",
    "\n",
    "- `keep` (`'first'`, `'last'`, `'all'`, default `'first'`): tie-handling policy at the cutoff boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44240cec",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40110cf1",
   "metadata": {},
   "source": [
    "Think of pulling the top performers from a leaderboard.\n",
    "\n",
    "- Keep first tie instances, last tie instances, or all ties.\n",
    "\n",
    "- Return only top rows needed.\n",
    "\n",
    "Fast for top-k views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3437b0b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ce444",
   "metadata": {},
   "source": [
    "- Pandas selects the largest values directly instead of full sorting every row.\n",
    "\n",
    "- It preserves label-value mapping for selected rows.\n",
    "\n",
    "- `keep` controls how equal cutoff values are treated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001fd15",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707085f",
   "metadata": {},
   "source": [
    "- Tie behavior can change row count (especially `keep='all'`).\n",
    "\n",
    "- Missing values are excluded from the largest set.\n",
    "\n",
    "- For tiny Series, full sort may be equally readable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a70094",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6272cf",
   "metadata": {},
   "source": [
    "- Do you need exactly `n` rows or all ties at boundary?\n",
    "\n",
    "- Is descending order enough, or do you need additional tie-breakers?\n",
    "\n",
    "- Should missing values be handled before top-k extraction?\n",
    "\n",
    "- Are selected labels used for action workflows?\n",
    "\n",
    "- Is top-k recomputed per segment/time window?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f131c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f45123",
   "metadata": {},
   "source": [
    "Use `nlargest(n)` for efficient top-k extraction with explicit tie policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb8f5c",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Pull top revenue products for weekly merchandising decisions.\n",
    "\n",
    "Scenario: include all tied products at the cutoff to avoid arbitrary exclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "95fa6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top2 first: {'prod_B': 72, 'prod_D': 72}\n",
      "Top2 all ties: {'prod_B': 72, 'prod_D': 72}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.Series(\n",
    "    [45, 72, 61, 72],\n",
    "    index=[\"prod_A\", \"prod_B\", \"prod_C\", \"prod_D\"],\n",
    "    name=\"revenue\",\n",
    ")\n",
    "\n",
    "top2_first = revenue.nlargest(2, keep=\"first\")\n",
    "top2_all = revenue.nlargest(2, keep=\"all\")\n",
    "\n",
    "print(\"Top2 first:\", top2_first.to_dict())\n",
    "print(\"Top2 all ties:\", top2_all.to_dict())\n",
    "\n",
    "assert list(top2_first.index) == [\"prod_B\", \"prod_D\"]\n",
    "assert int(top2_all.size) == 2\n",
    "assert int(top2_first.iloc[0]) == 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37162a",
   "metadata": {},
   "source": [
    "##### Series.nsmallest(n)\n",
    "`nsmallest(n)` returns the bottom `n` smallest values with labels. It is useful for low-outlier review, weak-performer triage, and floor analysis. Like `nlargest`, tie policy is controlled by `keep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "4caf5abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "ed4654af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.nsmallest(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce9c53",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b630d",
   "metadata": {},
   "source": [
    "`series.nsmallest(n)` gives the lowest `n` rows quickly, preserving labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720d6a1",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceeadf",
   "metadata": {},
   "source": [
    "- `n` (`int`, default `5`): number of smallest rows to return.\n",
    "\n",
    "- `keep` (`'first'`, `'last'`, `'all'`, default `'first'`): tie-handling policy at the cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2398a61",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060b9bb",
   "metadata": {},
   "source": [
    "Think of listing weakest performers first.\n",
    "\n",
    "- Return the bottom `n`.\n",
    "\n",
    "- Decide tie handling with `keep`.\n",
    "\n",
    "Useful for troubleshooting low-end cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553699f0",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a93c8",
   "metadata": {},
   "source": [
    "- Pandas selects smallest values directly via an efficient top-k style routine.\n",
    "\n",
    "- Selected rows keep their original labels.\n",
    "\n",
    "- `keep` determines inclusion behavior for equal boundary values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842dcbf",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf91f1",
   "metadata": {},
   "source": [
    "- Boundary ties can alter expected output size.\n",
    "\n",
    "- Missing values are not treated as smallest candidates here.\n",
    "\n",
    "- Very small samples may make bottom-k noisy and unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db808265",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830809c",
   "metadata": {},
   "source": [
    "- Is bottom-k enough, or do you need all low outliers by threshold?\n",
    "\n",
    "- Should ties be fully included?\n",
    "\n",
    "- Are low values genuine events or data errors?\n",
    "\n",
    "- Do you need labels for remediation workflows?\n",
    "\n",
    "- Should analysis be segmented before selecting n-smallest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09f912",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c13c2",
   "metadata": {},
   "source": [
    "Use `nsmallest(n)` for fast low-end extraction and pair it with label-based investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403aee6",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Identify lowest customer satisfaction stores for targeted coaching.\n",
    "\n",
    "Scenario: operations wants bottom two stores each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "cf422fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom2: {'store_D': 3.5, 'store_B': 3.8}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "satisfaction = pd.Series(\n",
    "    [4.3, 3.8, 4.7, 3.5],\n",
    "    index=[\"store_A\", \"store_B\", \"store_C\", \"store_D\"],\n",
    "    name=\"csat\",\n",
    ")\n",
    "\n",
    "bottom2 = satisfaction.nsmallest(2)\n",
    "print(\"Bottom2:\", bottom2.to_dict())\n",
    "\n",
    "assert list(bottom2.index) == [\"store_D\", \"store_B\"]\n",
    "assert float(bottom2.iloc[0]) == 3.5\n",
    "assert int(bottom2.size) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3063a",
   "metadata": {},
   "source": [
    "#### Transformation and element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1d0ce",
   "metadata": {},
   "source": [
    "##### Series.apply(func)\n",
    "`apply(func)` runs a custom function over Series data and returns transformed output. It is useful when built-in vectorized methods are not enough for your business rule. Use it carefully for readability and correctness, especially on larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "00a7c1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "7aaef5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20\n",
       "b    40\n",
       "c    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.apply(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d676b2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ca6fa",
   "metadata": {},
   "source": [
    "`series.apply(func)` applies your function and returns a new result based on that logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c620a88",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72916f29",
   "metadata": {},
   "source": [
    "- `func` (callable or compatible function spec): transformation function to apply.\n",
    "\n",
    "- `args` (`tuple`, default `()`): extra positional arguments passed to `func`.\n",
    "\n",
    "- `by_row` (`'compat'` or `False`, default `'compat'`): controls how function application is interpreted in pandas internals.\n",
    "\n",
    "- `**kwargs`: additional keyword arguments forwarded to `func`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926d8ea",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a3f6d",
   "metadata": {},
   "source": [
    "Think of running the same formula over every row in a spreadsheet column.\n",
    "\n",
    "- Each value goes through your rule.\n",
    "\n",
    "- Output keeps row labels aligned.\n",
    "\n",
    "You get a custom transformed column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956990d7",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18993d0",
   "metadata": {},
   "source": [
    "- Pandas iterates through Series values according to apply semantics.\n",
    "\n",
    "- Each value (or the Series context, depending on function usage) is passed to `func`.\n",
    "\n",
    "- Returned results are assembled into a labeled output object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c247b4",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2970cab",
   "metadata": {},
   "source": [
    "- Python-level custom functions can be slower than vectorized pandas operations.\n",
    "\n",
    "- Complex lambdas may reduce readability and testability.\n",
    "\n",
    "- Type changes can occur unexpectedly if function outputs mixed types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192be95a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc1c0b",
   "metadata": {},
   "source": [
    "- Can this be done with a faster built-in vectorized method instead?\n",
    "\n",
    "- Is the custom function deterministic and side-effect free?\n",
    "\n",
    "- Are dtype/output expectations explicitly validated?\n",
    "\n",
    "- Do you need extra args/kwargs rather than closing over hidden state?\n",
    "\n",
    "- Are transformed labels preserved for downstream joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c611af",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5690c7c",
   "metadata": {},
   "source": [
    "Use `apply(func)` when you need custom per-value logic, and validate output type and behavior with asserts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d2747",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Apply a custom tax uplift rule to transaction amounts before reporting net/gross views.\n",
    "\n",
    "Scenario: each amount is adjusted with one reusable business function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "bffb0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross amounts: {'txn_1': 110.0, 'txn_2': 275.0, 'txn_3': 88.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount = pd.Series(\n",
    "    [100.0, 250.0, 80.0],\n",
    "    index=[\"txn_1\", \"txn_2\", \"txn_3\"],\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "def add_tax(x, rate):\n",
    "    return round(x * (1 + rate), 2)\n",
    "\n",
    "gross = amount.apply(add_tax, args=(0.1,))\n",
    "print(\"Gross amounts:\", gross.to_dict())\n",
    "\n",
    "assert float(gross.loc[\"txn_1\"]) == 110.0\n",
    "assert float(gross.loc[\"txn_2\"]) == 275.0\n",
    "assert list(gross.index) == [\"txn_1\", \"txn_2\", \"txn_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1249e5",
   "metadata": {},
   "source": [
    "##### Series.map(func)\n",
    "`map(func)` maps each Series value through a function, mapping, or another Series. It is ideal for label encoding, category standardization, and code-to-name translation. Compared with `apply`, it is specialized for element-wise mapping workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "a4e45517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "666ebdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    low\n",
       "b    mid\n",
       "c    NaN\n",
       "dtype: str"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.map({10: 'low', 20: 'mid'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7057695",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef59bd",
   "metadata": {},
   "source": [
    "`series.map(func)` replaces each value using a mapping rule (dictionary/function/Series lookup)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c7c90",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a4d99",
   "metadata": {},
   "source": [
    "- `func` (callable, mapping, Series, or `None`): mapping logic/source.\n",
    "\n",
    "- `na_action` (`'ignore'` or `None`, default `None`): if `'ignore'`, missing values are skipped during mapping.\n",
    "\n",
    "- `engine` (callable or `None`, default `None`): execution engine option when supported.\n",
    "\n",
    "- `**kwargs`: additional keyword arguments passed to callable mappers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f94f6",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebb457",
   "metadata": {},
   "source": [
    "Think of a lookup table in a spreadsheet.\n",
    "\n",
    "- Each code gets replaced by its descriptive label.\n",
    "\n",
    "- Unknown codes can become missing unless handled.\n",
    "\n",
    "Great for translating categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3672f8",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946c553",
   "metadata": {},
   "source": [
    "- Pandas reads each value and applies the chosen mapping source/rule.\n",
    "\n",
    "- For dict/Series mappings, exact key matches are replaced.\n",
    "\n",
    "- Output keeps original index labels with mapped values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff365f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b504af",
   "metadata": {},
   "source": [
    "- Unmapped keys become missing (`NaN`) with dict-like mappings.\n",
    "\n",
    "- Type mismatch between source values and mapping keys causes missed matches.\n",
    "\n",
    "- Overusing function mappers can be slower than vectorized alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f4524",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754df17",
   "metadata": {},
   "source": [
    "- Is your mapping table complete for all expected values?\n",
    "\n",
    "- Do you need fallback labels for unknown keys?\n",
    "\n",
    "- Are key dtypes normalized before mapping?\n",
    "\n",
    "- Should missing values be preserved via `na_action='ignore'`?\n",
    "\n",
    "- Are mapped labels validated against allowed vocabulary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40295a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553049b",
   "metadata": {},
   "source": [
    "Use `map(func)` for clean value translation workflows, especially code-to-label conversion with index preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b111f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert payment channel codes into readable channel names for dashboards.\n",
    "\n",
    "Scenario: numeric channel codes must be mapped to business labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "698b5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped channels: {'o1': 'web', 'o2': 'store', 'o3': 'app', 'o4': 'store'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "channel_code = pd.Series(\n",
    "    [1, 2, 3, 2],\n",
    "    index=[\"o1\", \"o2\", \"o3\", \"o4\"],\n",
    "    name=\"channel_code\",\n",
    ")\n",
    "\n",
    "mapping = {1: \"web\", 2: \"store\", 3: \"app\"}\n",
    "channel_name = channel_code.map(mapping)\n",
    "print(\"Mapped channels:\", channel_name.to_dict())\n",
    "\n",
    "assert channel_name.loc[\"o1\"] == \"web\"\n",
    "assert channel_name.loc[\"o3\"] == \"app\"\n",
    "assert int(channel_name.isna().sum()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e68196",
   "metadata": {},
   "source": [
    "##### Series.astype(dtype)\n",
    "`astype(dtype)` casts a Series to a target data type. It is essential for schema control, memory tuning, and model-ready feature preparation. Use `errors` behavior intentionally to avoid silent type issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "61695713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "b0e38b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10.0\n",
       "b    20.0\n",
       "c    30.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ba084",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672d1d0",
   "metadata": {},
   "source": [
    "`series.astype(dtype)` changes how values are stored/interpreted by converting to the requested dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbd8bb",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34fd49",
   "metadata": {},
   "source": [
    "- `dtype` (dtype spec): target dtype (e.g., `\"float64\"`, `\"Int64\"`, `\"category\"`).\n",
    "\n",
    "- `copy` (`bool` or no_default): whether to ensure a copied object instead of reusing data when possible.\n",
    "\n",
    "- `errors` (`'raise'` or `'ignore'`, default `'raise'`): error behavior when conversion fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6182ac",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6611296",
   "metadata": {},
   "source": [
    "Think of changing a spreadsheet column format (text -> number).\n",
    "\n",
    "- Format controls valid operations and memory use.\n",
    "\n",
    "- Wrong format causes wrong behavior or failures.\n",
    "\n",
    "Casting enforces expected data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3277fc",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab05996",
   "metadata": {},
   "source": [
    "- Pandas attempts to convert each value to the target dtype.\n",
    "\n",
    "- If conversion succeeds, output Series has new dtype metadata and values.\n",
    "\n",
    "- On failure, behavior depends on `errors` policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9555c0",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6929d6",
   "metadata": {},
   "source": [
    "- Invalid strings or mixed formats can break conversion (`errors='raise'`).\n",
    "\n",
    "- Downcasting/upcasting can affect precision or missing-value behavior.\n",
    "\n",
    "- `errors='ignore'` may mask conversion failures if not checked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd23f2d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea04b6",
   "metadata": {},
   "source": [
    "- Is target dtype explicitly defined by schema?\n",
    "\n",
    "- How should invalid values be handled before cast?\n",
    "\n",
    "- Do you need nullable dtypes (e.g., `Int64`) for missing support?\n",
    "\n",
    "- Is precision loss acceptable for this field?\n",
    "\n",
    "- Are post-cast dtype assertions in place?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83b9d1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134904c",
   "metadata": {},
   "source": [
    "Use `astype(dtype)` to enforce the exact type you need, then assert dtype to protect downstream steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ac648",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Cast order quantity from string input to nullable integer for feature engineering.\n",
    "\n",
    "Scenario: ingestion provides quantities as text but model pipeline expects integer semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "82418392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dtype: Int64\n",
      "Converted values: {'o1': 10, 'o2': 0, 'o3': 25}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qty_text = pd.Series(\n",
    "    [\"10\", \"0\", \"25\"],\n",
    "    index=[\"o1\", \"o2\", \"o3\"],\n",
    "    name=\"qty\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "\n",
    "qty_int = qty_text.astype(\"Int64\")\n",
    "print(\"Converted dtype:\", qty_int.dtype)\n",
    "print(\"Converted values:\", qty_int.to_dict())\n",
    "\n",
    "assert str(qty_int.dtype) == \"Int64\"\n",
    "assert int(qty_int.loc[\"o3\"]) == 25\n",
    "assert int(qty_int.sum()) == 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166836bc",
   "metadata": {},
   "source": [
    "##### Series.transform(func)\n",
    "`transform(func)` applies a function and returns a Series aligned to the original index. It is useful for feature engineering where output length must match input length. This differs from aggregation methods that reduce to a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "7d8e5cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "ace6e682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -10.0\n",
       "b     0.0\n",
       "c    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79489680",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbdb04",
   "metadata": {},
   "source": [
    "`series.transform(func)` creates transformed values while keeping one output row for each original row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669de12d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c5baa",
   "metadata": {},
   "source": [
    "- `func` (callable, function name, or list-like): transformation logic applied while preserving shape/alignment.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis to transform; for Series this is row-wise.\n",
    "\n",
    "- `*args`: extra positional arguments passed to `func`.\n",
    "\n",
    "- `**kwargs`: extra keyword arguments passed to `func`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b046bd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f52ee",
   "metadata": {},
   "source": [
    "Think of rewriting each spreadsheet row using a formula but keeping the same row grid.\n",
    "\n",
    "- Number of rows stays unchanged.\n",
    "\n",
    "- Each row gets transformed output.\n",
    "\n",
    "Great for aligned feature creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1ffc8",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60143faf",
   "metadata": {},
   "source": [
    "- Pandas runs the transform function and expects broadcastable/aligned output.\n",
    "\n",
    "- Output is returned with the original index structure preserved.\n",
    "\n",
    "- This enables direct assignment as new feature columns without reindexing friction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c07e38",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02f755",
   "metadata": {},
   "source": [
    "- Functions that reduce to incompatible shapes can fail or behave unexpectedly.\n",
    "\n",
    "- Complex transforms may be slower than vectorized built-ins.\n",
    "\n",
    "- Ambiguous functions can blur distinction between transform and aggregate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d9715",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2da3b",
   "metadata": {},
   "source": [
    "- Does your function return output aligned to original index length?\n",
    "\n",
    "- Would a vectorized built-in be clearer/faster?\n",
    "\n",
    "- Are transformed values validated against expected ranges?\n",
    "\n",
    "- Do you need group-aware transform instead (via groupby)?\n",
    "\n",
    "- Is feature reproducibility ensured with deterministic logic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf1ed5",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4ea96",
   "metadata": {},
   "source": [
    "Use `transform(func)` when you need per-row transformed output that stays aligned to the same index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f0fe7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build z-score feature from transaction amount while preserving order IDs.\n",
    "\n",
    "Scenario: feature pipeline requires normalized values with exact original label alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "b08636c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: {'txn_A': 0.0, 'txn_B': 1.225, 'txn_C': -1.225}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount = pd.Series(\n",
    "    [100.0, 120.0, 80.0],\n",
    "    index=[\"txn_A\", \"txn_B\", \"txn_C\"],\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "z = amount.transform(lambda x: (x - x.mean()) / x.std(ddof=0))\n",
    "print(\"Z-score:\", z.round(3).to_dict())\n",
    "\n",
    "assert list(z.index) == list(amount.index)\n",
    "assert round(float(z.loc[\"txn_B\"]), 3) == 1.225\n",
    "assert round(float(z.mean()), 10) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd597f",
   "metadata": {},
   "source": [
    "##### Series.aggregate(func)\n",
    "`aggregate(func)` applies one or more aggregation functions to a Series. It is useful when you need compact summary metrics in one call. Output shape depends on whether you pass one function or many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "ce4a954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "b60defb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum     60.0\n",
       "mean    20.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.aggregate(['sum', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e1cad",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b99661",
   "metadata": {},
   "source": [
    "`series.aggregate(func)` computes summary statistics like sum/mean/min/max using the function(s) you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf1e5a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8f330",
   "metadata": {},
   "source": [
    "- `func` (callable, str, list-like, dict-like, or `None`): aggregation definition(s).\n",
    "\n",
    "- `axis` (`0`, default `0`): aggregation axis; for Series this is row-wise.\n",
    "\n",
    "- `*args`: positional arguments passed to aggregation function(s).\n",
    "\n",
    "- `**kwargs`: keyword arguments passed to aggregation function(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609084e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c674a1",
   "metadata": {},
   "source": [
    "Think of requesting a quick summary table for one spreadsheet column.\n",
    "\n",
    "- Ask for one metric: get one result.\n",
    "\n",
    "- Ask for many metrics: get many results.\n",
    "\n",
    "All in one command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085d5ad",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5360a",
   "metadata": {},
   "source": [
    "- Pandas dispatches each requested aggregation to the Series values.\n",
    "\n",
    "- Single aggregation returns a scalar; multiple aggregations return a labeled Series.\n",
    "\n",
    "- Functions run over non-missing values according to each function?s semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333fe5e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0ba24",
   "metadata": {},
   "source": [
    "- Mixed output types from custom functions can be confusing.\n",
    "\n",
    "- Large lists of functions can reduce readability.\n",
    "\n",
    "- Different functions handle missing values differently; assumptions must be explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b678dd9",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8db24",
   "metadata": {},
   "source": [
    "- Do you need one summary metric or a set of metrics?\n",
    "\n",
    "- Are missing-value rules consistent across chosen functions?\n",
    "\n",
    "- Are custom aggregation functions deterministic and tested?\n",
    "\n",
    "- Is output shape (scalar vs Series) handled correctly downstream?\n",
    "\n",
    "- Are metric names clear for reporting/audit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a17ab3",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c6407",
   "metadata": {},
   "source": [
    "Use `aggregate(func)` to compute one or multiple summary stats in a single, explicit step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4801d",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Produce compact weekly KPI summary from one metric Series.\n",
    "\n",
    "Scenario: dashboard card needs sum, mean, and max in one output object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "7f36f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: {'sum': 50.0, 'mean': 12.5, 'max': 15.0}\n",
      "Single mean: 12.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [12, 15, 10, 13],\n",
    "    index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\"],\n",
    "    name=\"orders\",\n",
    ")\n",
    "\n",
    "summary = kpi.aggregate([\"sum\", \"mean\", \"max\"])\n",
    "single = kpi.aggregate(\"mean\")\n",
    "\n",
    "print(\"Summary:\", summary.to_dict())\n",
    "print(\"Single mean:\", single)\n",
    "\n",
    "assert int(summary.loc[\"sum\"]) == 50\n",
    "assert float(summary.loc[\"mean\"]) == 12.5\n",
    "assert float(single) == 12.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a2624",
   "metadata": {},
   "source": [
    "##### Series.pipe(func)\n",
    "`pipe(func)` passes the Series into a function and returns that function?s output. It is useful for readable transformation chains and reusable function-based pipelines. This keeps notebook logic modular without breaking method-chaining style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "5a5204ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "e6a6a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20\n",
       "b    40\n",
       "c    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.pipe(lambda s: s * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fe504",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753ee53",
   "metadata": {},
   "source": [
    "`series.pipe(func)` means: \"take this Series and feed it to my function\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5bc9c5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7dd3f6",
   "metadata": {},
   "source": [
    "- `func` (callable or tuple): function to call, or `(func, data_keyword)` tuple for keyword-style piping.\n",
    "\n",
    "- `*args`: positional arguments forwarded to `func`.\n",
    "\n",
    "- `**kwargs`: keyword arguments forwarded to `func`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53428178",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d8627",
   "metadata": {},
   "source": [
    "Think of passing a spreadsheet column to a reusable macro.\n",
    "\n",
    "- Column goes in.\n",
    "\n",
    "- Macro applies logic.\n",
    "\n",
    "- Result comes back to the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbbbd0",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf9a45",
   "metadata": {},
   "source": [
    "- Pandas calls your function with the Series as first argument (or named keyword via tuple form).\n",
    "\n",
    "- Returned object from the function becomes the pipeline output at that step.\n",
    "\n",
    "- This enables composable, testable transformation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ae633",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f8e23",
   "metadata": {},
   "source": [
    "- Indirect function chains can be hard to debug without clear naming.\n",
    "\n",
    "- Functions that mutate input unexpectedly can create hidden side effects.\n",
    "\n",
    "- Poorly typed function returns can break later chain steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8087d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf257e3",
   "metadata": {},
   "source": [
    "- Is the piped function pure and deterministic?\n",
    "\n",
    "- Are function inputs/outputs documented and tested?\n",
    "\n",
    "- Do you need tuple form for keyword injection?\n",
    "\n",
    "- Is chain readability improved or reduced by this abstraction?\n",
    "\n",
    "- Are index labels preserved through the function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a62907",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1f6bb",
   "metadata": {},
   "source": [
    "Use `pipe(func)` to keep transformation code modular while preserving chain readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e7fe1",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Normalize transaction amounts relative to a chosen baseline row in a clean chain.\n",
    "\n",
    "Scenario: analysts want a reusable normalization function in multiple notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "4af9b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative: {'txn_A': 1.0, 'txn_B': 1.2, 'txn_C': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount = pd.Series(\n",
    "    [100.0, 120.0, 80.0],\n",
    "    index=[\"txn_A\", \"txn_B\", \"txn_C\"],\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "def normalize_to_label(s, base_label):\n",
    "    return s / s.loc[base_label]\n",
    "\n",
    "relative = amount.pipe(normalize_to_label, base_label=\"txn_A\")\n",
    "print(\"Relative:\", relative.round(3).to_dict())\n",
    "\n",
    "assert round(float(relative.loc[\"txn_A\"]), 3) == 1.0\n",
    "assert round(float(relative.loc[\"txn_B\"]), 3) == 1.2\n",
    "assert list(relative.index) == [\"txn_A\", \"txn_B\", \"txn_C\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945c7d8",
   "metadata": {},
   "source": [
    "##### Series.replace(to_replace, value)\n",
    "`replace(to_replace, value)` substitutes selected values with new ones. It is useful for cleaning sentinel values, standardizing labels, and fixing known data issues. Replacement rules can be scalar, list-like, dict-based, or regex-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "1c47f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "8322c0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "b     20\n",
       "c     30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.replace(10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279da07",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b90410",
   "metadata": {},
   "source": [
    "`series.replace(to_replace, value)` finds matches and swaps them with replacement values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f2453",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad28196",
   "metadata": {},
   "source": [
    "- `to_replace` (scalar, list, dict, regex-like, or `None`): target values/patterns to replace.\n",
    "\n",
    "- `value` (scalar, list, dict, or no_default): replacement value(s), depending on replacement mode.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate original Series if `True`.\n",
    "\n",
    "- `regex` (`bool`, default `False`): interpret `to_replace` as regex patterns when applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b05277",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c821f",
   "metadata": {},
   "source": [
    "Think of find-and-replace in a spreadsheet column.\n",
    "\n",
    "- Find unwanted or outdated values.\n",
    "\n",
    "- Replace with clean standardized values.\n",
    "\n",
    "Useful for data normalization before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb74645",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d3a7d",
   "metadata": {},
   "source": [
    "- Pandas scans Series values for matches to replacement rules.\n",
    "\n",
    "- Matching entries are swapped with replacement outputs.\n",
    "\n",
    "- Result preserves index labels and row order unless mutated in place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0508029",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea5932",
   "metadata": {},
   "source": [
    "- Over-broad regex patterns can replace unintended values.\n",
    "\n",
    "- Type mismatches between target and actual values can miss replacements.\n",
    "\n",
    "- In-place replacement can hide original raw data needed for audits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b489a08",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b53565",
   "metadata": {},
   "source": [
    "- Are replacement rules specific enough to avoid accidental edits?\n",
    "\n",
    "- Should sentinel values become missing or concrete defaults?\n",
    "\n",
    "- Are replacements reversible/auditable if needed?\n",
    "\n",
    "- Do regex rules need unit tests before production use?\n",
    "\n",
    "- Are dtype changes after replacement expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a06c56",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6feac62",
   "metadata": {},
   "source": [
    "Use `replace()` to standardize known bad or legacy values before downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da03a3",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert legacy status codes and sentinel placeholders into cleaned reporting values.\n",
    "\n",
    "Scenario: `ERR` should become `error`, and `-999` should become missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "e01f74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: {'r1': 'OK', 'r2': 'error', 'r3': None, 'r4': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "status = pd.Series(\n",
    "    [\"OK\", \"ERR\", -999, \"OK\"],\n",
    "    index=[\"r1\", \"r2\", \"r3\", \"r4\"],\n",
    "    name=\"status\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "\n",
    "clean = status.replace({\"ERR\": \"error\", -999: pd.NA})\n",
    "print(\"Cleaned:\", clean.to_dict())\n",
    "\n",
    "assert clean.loc[\"r2\"] == \"error\"\n",
    "assert pd.isna(clean.loc[\"r3\"])\n",
    "assert clean.loc[\"r1\"] == \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366eb83",
   "metadata": {},
   "source": [
    "##### Series.round(decimals)\n",
    "`round(decimals)` rounds numeric values to a specified number of decimal places. It is useful for reporting display, currency formatting, and stable comparison outputs. Rounding changes value representation, so precision decisions should be intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "cc9a4c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "4a8ead32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546884c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d41bc9",
   "metadata": {},
   "source": [
    "`series.round(decimals)` trims numeric values to the requested decimal precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fed2c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62820a2d",
   "metadata": {},
   "source": [
    "- `decimals` (`int`, default `0`): number of decimal places to keep.\n",
    "\n",
    "- `*args`, `**kwargs`: additional arguments for compatibility with NumPy-style signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e90ce",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3d60e",
   "metadata": {},
   "source": [
    "Think of formatting spreadsheet numbers to fewer decimal places.\n",
    "\n",
    "- Keeps values readable.\n",
    "\n",
    "- Reduces noisy precision in reports.\n",
    "\n",
    "But underlying interpretation may change slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f9a9",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35fc5c",
   "metadata": {},
   "source": [
    "- Pandas applies numerical rounding to each value at specified precision.\n",
    "\n",
    "- Output is a Series with same labels and rounded numeric values.\n",
    "\n",
    "- Rounding rule follows underlying numeric behavior for the dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84509aa2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ecd6b",
   "metadata": {},
   "source": [
    "- Rounding can hide small but meaningful differences.\n",
    "\n",
    "- Binary floating-point representation may surprise at edge cases.\n",
    "\n",
    "- Early rounding in pipelines can accumulate downstream error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc656c92",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548643e",
   "metadata": {},
   "source": [
    "- Is this rounding for display only or for calculation inputs?\n",
    "\n",
    "- What precision is required by business/legal rules?\n",
    "\n",
    "- Could rounding alter ranking/order decisions?\n",
    "\n",
    "- Should raw high-precision values be retained separately?\n",
    "\n",
    "- Are comparisons done before or after rounding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e401c18",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bbd38",
   "metadata": {},
   "source": [
    "Use `round(decimals)` for controlled precision, and delay rounding until the right pipeline stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83806a85",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prepare financial KPI output rounded to 2 decimals for stakeholder reporting.\n",
    "\n",
    "Scenario: dashboard should display stable 2-decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "8f81fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded: {'m1': 1.23, 'm2': 2.35, 'm3': -0.56}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series(\n",
    "    [1.2349, 2.3451, -0.5555],\n",
    "    index=[\"m1\", \"m2\", \"m3\"],\n",
    "    name=\"metric\",\n",
    ")\n",
    "\n",
    "rounded = kpi.round(2)\n",
    "print(\"Rounded:\", rounded.to_dict())\n",
    "\n",
    "assert float(rounded.loc[\"m1\"]) == 1.23\n",
    "assert float(rounded.loc[\"m2\"]) == 2.35\n",
    "assert float(rounded.loc[\"m3\"]) == -0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf3f43",
   "metadata": {},
   "source": [
    "##### Series.clip(lower, upper)\n",
    "`clip(lower, upper)` caps values outside a specified range. It is useful for outlier control, business-rule bounds, and robust feature preprocessing. Values below `lower` are raised; values above `upper` are reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "b16f1654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "40c52719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.clip(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168014f",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e0991",
   "metadata": {},
   "source": [
    "`series.clip(lower, upper)` forces every value to stay within lower/upper limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9775c9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6b591",
   "metadata": {},
   "source": [
    "- `lower` (scalar, array-like, or `None`): lower bound; values below it are set to this bound.\n",
    "\n",
    "- `upper` (scalar, array-like, or `None`): upper bound; values above it are set to this bound.\n",
    "\n",
    "- `axis` (`Axis`/`None`, default `None`): alignment axis for array-like bounds.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify original Series if `True`.\n",
    "\n",
    "- `**kwargs`: additional options for compatibility/dispatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812172d",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd24d6",
   "metadata": {},
   "source": [
    "Think of putting guardrails on a spreadsheet column.\n",
    "\n",
    "- Too low -> raised to minimum allowed.\n",
    "\n",
    "- Too high -> lowered to maximum allowed.\n",
    "\n",
    "Values inside range stay unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53b1e4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74729314",
   "metadata": {},
   "source": [
    "- Pandas compares each value to bounds.\n",
    "\n",
    "- Out-of-range values are replaced by boundary values.\n",
    "\n",
    "- In-range values pass through untouched, preserving index alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952402ac",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb565c0",
   "metadata": {},
   "source": [
    "- Clipping can mask true extremes if used without documentation.\n",
    "\n",
    "- Overly tight bounds may distort genuine signal.\n",
    "\n",
    "- In-place clipping can make it hard to recover original raw values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a91f8a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103859d5",
   "metadata": {},
   "source": [
    "- Are lower/upper bounds domain-validated?\n",
    "\n",
    "- Should clipped rows be flagged for audit?\n",
    "\n",
    "- Are bounds global or segment-specific?\n",
    "\n",
    "- Is clipping applied before or after key aggregations?\n",
    "\n",
    "- Do you retain raw values for traceability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59bfff",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb6804",
   "metadata": {},
   "source": [
    "Use `clip(lower, upper)` to enforce safe value bounds while keeping row labels and shape intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813712e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Cap extreme sensor outliers before building a stable monitoring feature.\n",
    "\n",
    "Scenario: sensor readings should stay within physical range 0 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "e89aba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capped: {'s1': 0.0, 's2': 10.0, 's3': 50.0, 's4': 30.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sensor = pd.Series(\n",
    "    [-5.0, 10.0, 55.0, 30.0],\n",
    "    index=[\"s1\", \"s2\", \"s3\", \"s4\"],\n",
    "    name=\"reading\",\n",
    ")\n",
    "\n",
    "capped = sensor.clip(lower=0.0, upper=50.0)\n",
    "print(\"Capped:\", capped.to_dict())\n",
    "\n",
    "assert float(capped.loc[\"s1\"]) == 0.0\n",
    "assert float(capped.loc[\"s3\"]) == 50.0\n",
    "assert float(capped.loc[\"s2\"]) == 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a396cb3",
   "metadata": {},
   "source": [
    "##### Series.abs()\n",
    "`abs()` returns absolute values element-wise, turning negative numbers into magnitudes. It is commonly used in error analysis where direction is less important than size. The index and labels are preserved, so downstream joins remain stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "fee699aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "b10ddf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe4687",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376fd16",
   "metadata": {},
   "source": [
    "`series.abs()` keeps values positive by measuring distance from zero for each element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1e736",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68baed26",
   "metadata": {},
   "source": [
    "- `(none)`: `abs()` takes no explicit arguments and applies absolute value element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6d264",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba0be7",
   "metadata": {},
   "source": [
    "Think of checking how far each spreadsheet cell is from zero, ignoring whether it is above or below.\n",
    "\n",
    "- `-4` and `4` both become `4`.\n",
    "\n",
    "- Row labels stay exactly where they are.\n",
    "\n",
    "You focus on magnitude only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f14494",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124d41b",
   "metadata": {},
   "source": [
    "- Pandas applies absolute-value logic to each element.\n",
    "\n",
    "- Negative numbers flip sign; positive numbers and zeros remain unchanged.\n",
    "\n",
    "- The output keeps the same index alignment as the input Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c93e5b0",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf7a18",
   "metadata": {},
   "source": [
    "- Non-numeric/object-heavy Series may error or behave unexpectedly.\n",
    "\n",
    "- Converting to absolute values removes direction information.\n",
    "\n",
    "- Missing values remain missing and still need separate handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2a9f7",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa13542",
   "metadata": {},
   "source": [
    "- Do you still need the sign (direction) later in the analysis?\n",
    "\n",
    "- Is the Series guaranteed to be numeric before calling `abs()`?\n",
    "\n",
    "- Should missing values be handled before or after magnitude conversion?\n",
    "\n",
    "- Are thresholds defined on signed values or absolute values?\n",
    "\n",
    "- Will this transformation affect alert logic downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b92bde",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e8e26",
   "metadata": {},
   "source": [
    "Use `abs()` when you care about size of change/error, not direction, and keep index labels intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829662e3",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert signed forecast errors into absolute errors before computing MAE-style metrics.\n",
    "\n",
    "Scenario: each store keeps its label so you can aggregate by region later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "b60c9e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute errors: {'store_a': 3.0, 'store_b': 1.5, 'store_c': 2.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "forecast_error = pd.Series(\n",
    "    [-3.0, 1.5, -2.0],\n",
    "    index=[\"store_a\", \"store_b\", \"store_c\"],\n",
    "    name=\"error\",\n",
    ")\n",
    "\n",
    "abs_error = forecast_error.abs()\n",
    "print(\"Absolute errors:\", abs_error.to_dict())\n",
    "\n",
    "assert float(abs_error.loc[\"store_a\"]) == 3.0\n",
    "assert float(abs_error.loc[\"store_b\"]) == 1.5\n",
    "assert list(abs_error.index) == [\"store_a\", \"store_b\", \"store_c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09433633",
   "metadata": {},
   "source": [
    "##### Series.where(condition)\n",
    "`where(condition)` keeps values where the condition is `True` and replaces the rest. By default, replaced values become `NaN`, but you can provide `other`. It is widely used in data cleaning pipelines to keep valid measurements and flag invalid ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "a400289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "6f4c3788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.where(series > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527a764",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47939e43",
   "metadata": {},
   "source": [
    "`series.where(cond)` says: keep good rows, replace failing rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66f2eb",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fbacf",
   "metadata": {},
   "source": [
    "- `cond` (bool Series/array-like/callable): condition evaluated element-wise; `True` keeps original value.\n",
    "\n",
    "- `other` (scalar, Series, callable, default `NaN`): replacement for `False` positions.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify current Series instead of returning a new one.\n",
    "\n",
    "- `axis` (`None`/axis label, default `None`): alignment axis (rarely relevant for plain Series).\n",
    "\n",
    "- `level` (int/label, optional): broadcast across a MultiIndex level when relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3201a9",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a775c3b",
   "metadata": {},
   "source": [
    "Think of a spreadsheet quality rule: pass rows stay, fail rows are blanked or filled with a marker.\n",
    "\n",
    "- Passing cells keep original values.\n",
    "\n",
    "- Failing cells are replaced.\n",
    "\n",
    "The row labels do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17727738",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82745573",
   "metadata": {},
   "source": [
    "- Pandas evaluates `cond` for each indexed position.\n",
    "\n",
    "- Where `cond` is `True`, original values are retained.\n",
    "\n",
    "- Where `cond` is `False`, values are replaced by `other` (or `NaN` by default).\n",
    "\n",
    "- Index alignment determines which condition applies to which label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950ed29",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa36f9",
   "metadata": {},
   "source": [
    "- Misaligned condition indexes can produce unexpected replacements.\n",
    "\n",
    "- Default `NaN` replacement can upcast integer dtype to float.\n",
    "\n",
    "- `inplace=True` can make lineage/debugging harder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb3e8e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813aa74",
   "metadata": {},
   "source": [
    "- Does `cond` align exactly with the Series index labels?\n",
    "\n",
    "- Should failures become `NaN` or a domain-specific fallback value?\n",
    "\n",
    "- Do you need to preserve integer dtype after replacement?\n",
    "\n",
    "- Is `where` clearer than writing equivalent boolean assignment?\n",
    "\n",
    "- Should invalid rows be logged before replacement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff86a1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea43b7",
   "metadata": {},
   "source": [
    "Use `where` to keep valid rows and replace invalid ones, while preserving index structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0fc1a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Keep only plausible temperature readings before daily average calculations.\n",
    "\n",
    "Scenario: values outside 10 to 35 Celsius are considered sensor anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "4db700d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean temperatures: {'m1': 18.0, 'm2': nan, 'm3': 22.5, 'm4': nan}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp_c = pd.Series(\n",
    "    [18.0, 42.0, 22.5, 5.0],\n",
    "    index=[\"m1\", \"m2\", \"m3\", \"m4\"],\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "clean = temp_c.where((temp_c >= 10) & (temp_c <= 35))\n",
    "print(\"Clean temperatures:\", clean.to_dict())\n",
    "\n",
    "assert pd.isna(clean.loc[\"m2\"])\n",
    "assert float(clean.loc[\"m3\"]) == 22.5\n",
    "assert clean.index.equals(temp_c.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790bbc3",
   "metadata": {},
   "source": [
    "##### Series.mask(condition)\n",
    "`mask(condition)` is the inverse pattern of `where`: it replaces values where the condition is `True`. This is useful when you want to hide or null-out flagged records directly. Like other Series operations, index labels are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "7c763ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "ba262e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.mask(series < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a14d73",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1645f",
   "metadata": {},
   "source": [
    "`series.mask(cond)` says: if the rule matches, replace that value; otherwise keep it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e71c2",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3354270",
   "metadata": {},
   "source": [
    "- `cond` (bool Series/array-like/callable): condition evaluated element-wise; `True` positions are replaced.\n",
    "\n",
    "- `other` (scalar, Series, callable, default `NaN`): replacement value(s) for `True` positions.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify current Series directly when `True`.\n",
    "\n",
    "- `axis` (`None`/axis label, default `None`): alignment axis (rarely relevant for Series).\n",
    "\n",
    "- `level` (int/label, optional): MultiIndex broadcasting level when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486629c0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc7781",
   "metadata": {},
   "source": [
    "Think of using a marker to black out spreadsheet cells that match a risk rule.\n",
    "\n",
    "- Matched cells are replaced.\n",
    "\n",
    "- Unmatched cells stay untouched.\n",
    "\n",
    "You deliberately hide flagged data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87773b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b422cc",
   "metadata": {},
   "source": [
    "- Pandas computes `cond` for each label.\n",
    "\n",
    "- `True` entries are replaced by `other` (or `NaN`).\n",
    "\n",
    "- `False` entries keep original values.\n",
    "\n",
    "- Index alignment governs label-to-condition mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ee940",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cba5e",
   "metadata": {},
   "source": [
    "- Easy to invert logic accidentally versus `where`.\n",
    "\n",
    "- Introducing `NaN` can change dtype (for example, int to float).\n",
    "\n",
    "- Misaligned boolean masks can produce incorrect replacements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318bbd4",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073841ae",
   "metadata": {},
   "source": [
    "- Are you intentionally replacing `True` matches (mask) rather than keeping them (where)?\n",
    "\n",
    "- Does `other` preserve expected dtype constraints?\n",
    "\n",
    "- Is the condition index perfectly aligned to data labels?\n",
    "\n",
    "- Should masked rows be audited before nulling?\n",
    "\n",
    "- Do downstream steps expect missing values after masking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612abf4",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89f421",
   "metadata": {},
   "source": [
    "Use `mask` to replace rows that match a rule, while keeping non-matching rows and labels intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497d4e3",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Null-out suspiciously high transaction amounts before computing routine KPIs.\n",
    "\n",
    "Scenario: transactions above 1000 are sent to manual review, so they are masked from automatic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "01c6f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked amounts: {'txn_1': 120.0, 'txn_2': 950.0, 'txn_3': 300.0, 'txn_4': nan}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amount = pd.Series(\n",
    "    [120, 950, 300, 1400],\n",
    "    index=[\"txn_1\", \"txn_2\", \"txn_3\", \"txn_4\"],\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "masked = amount.mask(amount > 1000)\n",
    "print(\"Masked amounts:\", masked.to_dict())\n",
    "\n",
    "assert pd.isna(masked.loc[\"txn_4\"])\n",
    "assert float(masked.loc[\"txn_2\"]) == 950.0\n",
    "assert masked.index.equals(amount.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156043a3",
   "metadata": {},
   "source": [
    "##### Series.copy(deep=True)\n",
    "`copy(deep=True)` creates a new Series object so later edits do not mutate the original data accidentally. It is a core defensive step in feature engineering and QA pipelines. Use deep copy when you need an isolated working version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "5dc81831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "403ea133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c9953",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea50f57",
   "metadata": {},
   "source": [
    "`series.copy()` makes a separate Series you can change safely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39143a2c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c31335",
   "metadata": {},
   "source": [
    "- `deep` (`bool`, default `True`): when `True`, copy data/index so value edits in one Series do not affect the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c898c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa51980",
   "metadata": {},
   "source": [
    "Think of photocopying a spreadsheet column before experimenting.\n",
    "\n",
    "- You keep one untouched original.\n",
    "\n",
    "- You test changes on the copy.\n",
    "\n",
    "If results are wrong, the source remains safe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db527a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0c8fa",
   "metadata": {},
   "source": [
    "- Pandas creates a new Series object.\n",
    "\n",
    "- With `deep=True`, data buffers are copied for independent value mutation.\n",
    "\n",
    "- Subsequent value updates on one Series do not propagate to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008298c",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff03864",
   "metadata": {},
   "source": [
    "- Deep copies consume extra memory.\n",
    "\n",
    "- For object elements (for example, nested Python lists), deep copy is not recursive over every inner object.\n",
    "\n",
    "- Skipping copy can lead to subtle accidental mutation bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7b1ce",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b428067",
   "metadata": {},
   "source": [
    "- Do you need full isolation (`deep=True`) or just a lightweight view-like copy?\n",
    "\n",
    "- Is memory overhead acceptable for your Series size?\n",
    "\n",
    "- Are there nested mutable Python objects in the Series?\n",
    "\n",
    "- Which step owns the source of truth after copying?\n",
    "\n",
    "- Have you asserted that original data remains unchanged?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e82f1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c1c57",
   "metadata": {},
   "source": [
    "Use `copy(deep=True)` to protect source data while you transform a working Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7928b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create a baseline snapshot before applying cleaning rules, so QA can compare before/after values.\n",
    "\n",
    "Scenario: keep raw daily units untouched while testing correction logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "ab6c569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current units: {'d1': 10, 'd2': 99, 'd3': 8}\n",
      "Baseline units: {'d1': 10, 'd2': 12, 'd3': 8}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "units = pd.Series([10, 12, 8], index=[\"d1\", \"d2\", \"d3\"], name=\"units\")\n",
    "baseline = units.copy(deep=True)\n",
    "\n",
    "units.loc[\"d2\"] = 99\n",
    "print(\"Current units:\", units.to_dict())\n",
    "print(\"Baseline units:\", baseline.to_dict())\n",
    "\n",
    "assert int(baseline.loc[\"d2\"]) == 12\n",
    "assert int(units.loc[\"d2\"]) == 99\n",
    "assert baseline is not units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf45eed",
   "metadata": {},
   "source": [
    "##### Series.drop(labels)\n",
    "`drop(labels)` removes entries by index label from a Series. It is commonly used to exclude known bad IDs, holdout points, or administrative rows. By default it returns a new Series and leaves the original unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "58bb366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "e5d50dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.drop(labels=series.index[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152fad3",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da790637",
   "metadata": {},
   "source": [
    "`series.drop(...)` deletes selected label rows from the Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21f67b",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d9477",
   "metadata": {},
   "source": [
    "- `labels` (single label or list-like): index labels to remove.\n",
    "\n",
    "- `axis` (default `0`): API-compatible axis selector; Series operations are along index axis.\n",
    "\n",
    "- `index` (label or list-like, optional): explicit alternative to `labels` for index removal.\n",
    "\n",
    "- `level` (int/label, optional): remove labels on a specific MultiIndex level.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify the Series directly instead of returning a new one.\n",
    "\n",
    "- `errors` (`'raise'` or `'ignore'`, default `'raise'`): behavior when a label is missing.\n",
    "\n",
    "- `columns` (accepted for API consistency): not used for Series data removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3178e29",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba5d51",
   "metadata": {},
   "source": [
    "Think of deleting named rows from a spreadsheet column.\n",
    "\n",
    "- You specify row labels, not numeric positions.\n",
    "\n",
    "- Remaining rows keep their original labels.\n",
    "\n",
    "Only selected labels are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e90a60",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec2eb0",
   "metadata": {},
   "source": [
    "- Pandas matches requested labels against the Series index.\n",
    "\n",
    "- Matched entries are removed from the result.\n",
    "\n",
    "- Missing labels raise an error unless `errors='ignore'`.\n",
    "\n",
    "- `inplace=True` updates the existing Series object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ee294",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748c166",
   "metadata": {},
   "source": [
    "- Typos in labels can raise `KeyError` with default settings.\n",
    "\n",
    "- Dropping labels changes shape and can break downstream alignment assumptions.\n",
    "\n",
    "- Heavy use of `inplace=True` can make pipelines harder to reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f88c6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83304c42",
   "metadata": {},
   "source": [
    "- Are you dropping by label (`drop`) or by integer position (`iloc`)?\n",
    "\n",
    "- Should missing labels fail fast or be ignored?\n",
    "\n",
    "- Do downstream joins expect the removed labels to exist?\n",
    "\n",
    "- Is index uniqueness guaranteed before dropping?\n",
    "\n",
    "- Do you need to document why each label was removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804e1a1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fb06f",
   "metadata": {},
   "source": [
    "Use `drop(labels)` to remove known index labels safely, with explicit error behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaac9d9",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Exclude failed sensors from a quality score Series before reporting dashboard KPIs.\n",
    "\n",
    "Scenario: sensors `s2` and `s4` are under maintenance and should not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "0ad3577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active sensors: {'s1': 0.98, 's3': 0.91}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quality = pd.Series(\n",
    "    [0.98, 0.76, 0.91, 0.88],\n",
    "    index=[\"s1\", \"s2\", \"s3\", \"s4\"],\n",
    "    name=\"score\",\n",
    ")\n",
    "\n",
    "active = quality.drop(labels=[\"s2\", \"s4\"])\n",
    "print(\"Active sensors:\", active.to_dict())\n",
    "\n",
    "assert list(active.index) == [\"s1\", \"s3\"]\n",
    "assert \"s2\" not in active.index\n",
    "assert float(active.loc[\"s1\"]) == 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4912d5",
   "metadata": {},
   "source": [
    "##### Series.explode()\n",
    "`explode()` expands each list-like element into multiple rows, duplicating the original index label as needed. It is essential when normalizing nested data before counting, grouping, or joining. Non-list scalars pass through unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "1b6e4f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "9450b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9fd06",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478446b8",
   "metadata": {},
   "source": [
    "`series.explode()` turns one row containing many values into many rows containing one value each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d25e8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a19f79",
   "metadata": {},
   "source": [
    "- `ignore_index` (`bool`, default `False`): when `True`, reset output index to `0..n-1`; otherwise keep/duplicate original labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a39f7b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362b781",
   "metadata": {},
   "source": [
    "Think of a spreadsheet cell with multiple tags being split into separate rows, one tag per row.\n",
    "\n",
    "- A row with 3 tags becomes 3 rows.\n",
    "\n",
    "- The original row label is duplicated unless you reset index.\n",
    "\n",
    "This prepares data for clean counting and grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a920e",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc329a2",
   "metadata": {},
   "source": [
    "- Pandas inspects each element for list-like structure.\n",
    "\n",
    "- List-like elements are expanded so each member becomes its own row.\n",
    "\n",
    "- Index labels are repeated to preserve lineage unless `ignore_index=True`.\n",
    "\n",
    "- Empty list-likes become missing (`NaN`) entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb621a4",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b40b6a",
   "metadata": {},
   "source": [
    "- Exploding can significantly increase row count.\n",
    "\n",
    "- Repeated indexes after explode may require `reset_index()` for downstream tools.\n",
    "\n",
    "- Result dtype is often `object`, which may need explicit recasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8217ce9",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abd977",
   "metadata": {},
   "source": [
    "- Do you need to preserve original labels or use `ignore_index=True`?\n",
    "\n",
    "- How should empty lists be interpreted in downstream metrics?\n",
    "\n",
    "- Is row expansion size acceptable for memory/performance?\n",
    "\n",
    "- Will you aggregate immediately after exploding?\n",
    "\n",
    "- Do you need to cast exploded values to a stricter dtype?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1748be",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2343bc",
   "metadata": {},
   "source": [
    "Use `explode()` to normalize list-like cells into one-value-per-row format while keeping traceability to source labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ba7b5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Normalize per-post tag lists so you can compute tag frequencies accurately.\n",
    "\n",
    "Scenario: each blog post has zero or more tags stored as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "37267e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_1    pandas\n",
      "post_1    python\n",
      "post_2    python\n",
      "post_3       NaN\n",
      "post_4       sql\n",
      "post_4       etl\n",
      "Name: tags, dtype: str\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tags = pd.Series(\n",
    "    [[\"pandas\", \"python\"], [\"python\"], [], [\"sql\", \"etl\"]],\n",
    "    index=[\"post_1\", \"post_2\", \"post_3\", \"post_4\"],\n",
    "    name=\"tags\",\n",
    ")\n",
    "\n",
    "exploded = tags.explode()\n",
    "print(exploded)\n",
    "\n",
    "assert list(exploded.loc[\"post_1\"]) == [\"pandas\", \"python\"]\n",
    "assert pd.isna(exploded.loc[\"post_3\"])\n",
    "assert exploded.index.tolist().count(\"post_4\") == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903f981",
   "metadata": {},
   "source": [
    "##### Series.compare(other)\n",
    "`compare(other)` shows differences between two aligned Series values. It is useful for QA checks between baseline and recomputed metrics. The output highlights only changed labels by default, which makes audits faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "6441bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "ecd2ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other]\n",
       "Index: []"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.compare(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81bc24",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467b7ab",
   "metadata": {},
   "source": [
    "`series.compare(other)` tells you where two Series differ and what each side contains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96720648",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c69fc",
   "metadata": {},
   "source": [
    "- `other` (`Series`): Series to compare against; labels should align meaningfully.\n",
    "\n",
    "- `align_axis` (`0`/`1`, default `1`): choose whether comparison pairs are aligned by columns or rows in the result.\n",
    "\n",
    "- `keep_shape` (`bool`, default `False`): keep all original labels, even if equal.\n",
    "\n",
    "- `keep_equal` (`bool`, default `False`): include equal values in output instead of showing only differences.\n",
    "\n",
    "- `result_names` (`tuple`, default `(\"self\", \"other\")`): column labels for compared values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b389a60",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a6db5",
   "metadata": {},
   "source": [
    "Think of comparing two spreadsheet versions side by side.\n",
    "\n",
    "- Unchanged rows can be hidden.\n",
    "\n",
    "- Changed rows show old vs new values.\n",
    "\n",
    "You quickly see exactly what moved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446728fe",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960a909",
   "metadata": {},
   "source": [
    "- Pandas aligns both Series on index labels.\n",
    "\n",
    "- It checks each aligned position for equality.\n",
    "\n",
    "- Differing positions are emitted with paired values (`self` vs `other`).\n",
    "\n",
    "- Optional flags control whether equal rows/shape are retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7af6bc",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa98269",
   "metadata": {},
   "source": [
    "- Mismatched indexes can hide intended row-to-row comparisons.\n",
    "\n",
    "- Output type is tabular (DataFrame-like), not a plain Series.\n",
    "\n",
    "- NaN comparison behavior can be surprising if missingness differs across sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a0b64",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2f261",
   "metadata": {},
   "source": [
    "- Are both Series aligned on the same business key labels?\n",
    "\n",
    "- Do you want only differences or full shape (`keep_shape=True`)?\n",
    "\n",
    "- Should equal values be retained for full audit context?\n",
    "\n",
    "- Are result column names clear for reviewers?\n",
    "\n",
    "- Have missing values been standardized before comparison?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2a2e9",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41ac28",
   "metadata": {},
   "source": [
    "Use `compare` to audit exactly where two labeled Series disagree and by how much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76826938",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate a new KPI pipeline by comparing recomputed values against last month baseline outputs.\n",
    "\n",
    "Scenario: flag only accounts where KPI changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "fb46dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        recalc  baseline\n",
      "acct_b   125.0     120.0\n",
      "acct_c    80.0      90.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline = pd.Series([100, 120, 90], index=[\"acct_a\", \"acct_b\", \"acct_c\"], name=\"kpi\")\n",
    "recalc = pd.Series([100, 125, 80], index=[\"acct_a\", \"acct_b\", \"acct_c\"], name=\"kpi\")\n",
    "\n",
    "delta = recalc.compare(baseline, result_names=(\"recalc\", \"baseline\"))\n",
    "print(delta)\n",
    "\n",
    "assert list(delta.index) == [\"acct_b\", \"acct_c\"]\n",
    "assert float(delta.loc[\"acct_b\", \"recalc\"]) == 125.0\n",
    "assert float(delta.loc[\"acct_c\", \"baseline\"]) == 90.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed352978",
   "metadata": {},
   "source": [
    "##### Series.cumsum()\n",
    "`cumsum()` computes a running total from top to bottom of the Series. It is a standard operation for cumulative KPIs like units sold or tickets processed. Each output value includes all prior values up to that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "106a6e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "187a4789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    30\n",
       "c    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b94c3e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a56e5f",
   "metadata": {},
   "source": [
    "`series.cumsum()` adds values progressively and returns the running sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20e14c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263e8c8",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis of operation (for Series this is the index axis).\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values while accumulating.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; usually not needed for standard Series use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f214c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d931d2",
   "metadata": {},
   "source": [
    "Think of a spreadsheet running-total column.\n",
    "\n",
    "- Row 1 is the first amount.\n",
    "\n",
    "- Row 2 is row1 + row2.\n",
    "\n",
    "Each row carries forward accumulated history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae708cf",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dab82",
   "metadata": {},
   "source": [
    "- Pandas scans values in index order.\n",
    "\n",
    "- Each step adds current value to previous cumulative state.\n",
    "\n",
    "- With `skipna=True`, missing values do not permanently break accumulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9916f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813270f4",
   "metadata": {},
   "source": [
    "- Wrong index order yields wrong running interpretation.\n",
    "\n",
    "- Large totals can overflow for narrow integer dtypes.\n",
    "\n",
    "- Missing values handling differs depending on `skipna` setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839b6f2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966249c",
   "metadata": {},
   "source": [
    "- Is the Series sorted in the intended chronological/business order?\n",
    "\n",
    "- Should missing values pause accumulation or be skipped?\n",
    "\n",
    "- Do you need grouped cumulative sums instead of global?\n",
    "\n",
    "- Are dtype limits safe for peak cumulative totals?\n",
    "\n",
    "- Do downstream charts expect cumulative, not period values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91fb4d",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03b752",
   "metadata": {},
   "source": [
    "Use `cumsum()` to build running totals while preserving original labels for traceability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89c810",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Track cumulative daily orders in a week to monitor progress against target.\n",
    "\n",
    "Scenario: each day label maps to one daily order count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "5894d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running orders: {'Mon': 5, 'Tue': 12, 'Wed': 15, 'Thu': 19}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "daily_orders = pd.Series([5, 7, 3, 4], index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\"], name=\"orders\")\n",
    "running_orders = daily_orders.cumsum()\n",
    "print(\"Running orders:\", running_orders.to_dict())\n",
    "\n",
    "assert int(running_orders.loc[\"Tue\"]) == 12\n",
    "assert int(running_orders.loc[\"Thu\"]) == 19\n",
    "assert running_orders.index.equals(daily_orders.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b49705",
   "metadata": {},
   "source": [
    "##### Series.cumprod()\n",
    "`cumprod()` computes cumulative multiplication across the Series. It is useful for compounding workflows, such as chained growth factors. Each label stores product of all previous factors up to that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "18fcd765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "68bc55da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      10\n",
       "b     200\n",
       "c    6000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15629a4b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375bb81",
   "metadata": {},
   "source": [
    "`series.cumprod()` multiplies values progressively to produce a running product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2d166",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e5da5",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis of operation (Series uses index axis).\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values during cumulative product.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; typically unused in standard Series code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e573a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599be483",
   "metadata": {},
   "source": [
    "Think of compounding returns in a spreadsheet.\n",
    "\n",
    "- First row is first factor.\n",
    "\n",
    "- Next row multiplies previous product by new factor.\n",
    "\n",
    "It builds compounded effect over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70d3ea",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba8706",
   "metadata": {},
   "source": [
    "- Pandas iterates in index order and maintains cumulative product state.\n",
    "\n",
    "- Each new value multiplies that state.\n",
    "\n",
    "- Missing values are either skipped or propagated depending on `skipna`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c194f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b559e5",
   "metadata": {},
   "source": [
    "- Zero values collapse later products to zero until reset context changes.\n",
    "\n",
    "- Repeated multiplication can accumulate floating-point rounding error.\n",
    "\n",
    "- Unsuitable dtype/order choices can produce misleading compounded metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410217c",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ddb4f",
   "metadata": {},
   "source": [
    "- Are inputs true multiplicative factors (for example, `1 + rate`)?\n",
    "\n",
    "- Is index order correct for compounding logic?\n",
    "\n",
    "- How should zeros or missing values affect subsequent results?\n",
    "\n",
    "- Do you need rounding policy for reporting?\n",
    "\n",
    "- Are you validating compounded totals against known checkpoints?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28240f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3217a5d",
   "metadata": {},
   "source": [
    "Use `cumprod()` for chained multiplication, such as cumulative growth factors over ordered labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5551f8",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute compounded retention from daily retention factors in a funnel.\n",
    "\n",
    "Scenario: each day contributes one multiplicative retention factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "f3e648f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compounded factors: {'d1': 0.98, 'd2': 0.9702, 'd3': 0.9799019999999999}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "retention_factor = pd.Series([0.98, 0.99, 1.01], index=[\"d1\", \"d2\", \"d3\"], name=\"factor\")\n",
    "compounded = retention_factor.cumprod()\n",
    "print(\"Compounded factors:\", compounded.to_dict())\n",
    "\n",
    "assert round(float(compounded.loc[\"d1\"]), 6) == 0.98\n",
    "assert round(float(compounded.loc[\"d2\"]), 6) == 0.9702\n",
    "assert round(float(compounded.loc[\"d3\"]), 6) == round(0.98 * 0.99 * 1.01, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94727f",
   "metadata": {},
   "source": [
    "##### Series.cummax()\n",
    "`cummax()` returns the running maximum observed so far at each label. It is useful for peak tracking and drawdown-type analysis. Once a new high appears, it becomes the new running reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "8fcbf337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "f9149bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cummax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d951fbc",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3609dd",
   "metadata": {},
   "source": [
    "`series.cummax()` keeps the highest value seen up to each position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736cee3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ae379",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis of operation (Series index axis).\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values while computing running max.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; usually not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb38da2",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c55c62",
   "metadata": {},
   "source": [
    "Think of a scoreboard showing \"best score so far\" after each round.\n",
    "\n",
    "- If current score is lower, best score stays.\n",
    "\n",
    "- If current score is higher, best score updates.\n",
    "\n",
    "You track the peak over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9728f9a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98a021",
   "metadata": {},
   "source": [
    "- Pandas processes values in order and stores current running maximum.\n",
    "\n",
    "- Each new value is compared to the stored max.\n",
    "\n",
    "- The larger of the two is emitted for that index label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12f9cf",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f178c57",
   "metadata": {},
   "source": [
    "- If order is wrong, the \"running peak\" has no business meaning.\n",
    "\n",
    "- Missing values can influence continuity depending on `skipna`.\n",
    "\n",
    "- Running maxima can hide short-term volatility if used alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487cf0ee",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79be712",
   "metadata": {},
   "source": [
    "- Is index order the intended sequence for peak tracking?\n",
    "\n",
    "- Do you also need current-minus-peak (drawdown) for context?\n",
    "\n",
    "- How should missing observations be handled?\n",
    "\n",
    "- Is the metric expected to be non-decreasing after `cummax`?\n",
    "\n",
    "- Will stakeholders misread running peak as current value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b98c4",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444ded0",
   "metadata": {},
   "source": [
    "Use `cummax()` to track best-so-far values across an ordered Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7988a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Track running highest account balance to support drawdown monitoring.\n",
    "\n",
    "Scenario: each day has one observed balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "b1d23306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running peak: {'d1': 1000, 'd2': 1200, 'd3': 1200, 'd4': 1300}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "balance = pd.Series([1000, 1200, 1150, 1300], index=[\"d1\", \"d2\", \"d3\", \"d4\"], name=\"balance\")\n",
    "peak = balance.cummax()\n",
    "print(\"Running peak:\", peak.to_dict())\n",
    "\n",
    "assert int(peak.loc[\"d1\"]) == 1000\n",
    "assert int(peak.loc[\"d3\"]) == 1200\n",
    "assert int(peak.loc[\"d4\"]) == 1300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62d233",
   "metadata": {},
   "source": [
    "##### Series.cummin()\n",
    "`cummin()` returns the running minimum observed so far at each label. It is useful for floor tracking, like worst-case metrics over time. Once a new low appears, it becomes the new running floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "2f6618cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "9db8e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    10\n",
       "c    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cummin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075f280",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f55c5f",
   "metadata": {},
   "source": [
    "`series.cummin()` keeps the lowest value seen up to each position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064a6f8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c51cb4",
   "metadata": {},
   "source": [
    "- `axis` (`0`, default `0`): axis of operation (Series index axis).\n",
    "\n",
    "- `skipna` (`bool`, default `True`): ignore missing values while computing running min.\n",
    "\n",
    "- `*args`, `**kwargs`: compatibility placeholders; usually unused."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db263e9",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6069d7",
   "metadata": {},
   "source": [
    "Think of recording the coldest temperature reached so far each day.\n",
    "\n",
    "- If today is warmer, floor stays the same.\n",
    "\n",
    "- If today is colder, floor updates.\n",
    "\n",
    "You keep a running low watermark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681fe90",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11ffba",
   "metadata": {},
   "source": [
    "- Pandas walks values in order and stores running minimum state.\n",
    "\n",
    "- Each new value is compared to current floor.\n",
    "\n",
    "- The smaller value is emitted at that label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b08274",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd33d5",
   "metadata": {},
   "source": [
    "- Misordered indexes produce misleading running floors.\n",
    "\n",
    "- Missing data handling can affect continuity if `skipna` changes.\n",
    "\n",
    "- Running minima can overemphasize old extremes in recent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbc0ed",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7ce31",
   "metadata": {},
   "source": [
    "- Is the Series ordered correctly for floor interpretation?\n",
    "\n",
    "- Do you need rolling minima instead of cumulative minima?\n",
    "\n",
    "- Should missing observations be imputed before floor tracking?\n",
    "\n",
    "- Is downstream logic expecting a non-increasing floor?\n",
    "\n",
    "- Do you need both running min and current value for reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e294953",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43375298",
   "metadata": {},
   "source": [
    "Use `cummin()` to track lowest-so-far values across an ordered labeled Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297bb14",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Monitor running lowest inventory level to detect persistent stock-risk periods.\n",
    "\n",
    "Scenario: each day label maps to one closing inventory value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "80d91631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running floor: {'d1': 50, 'd2': 42, 'd3': 42, 'd4': 38}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inventory = pd.Series([50, 42, 45, 38], index=[\"d1\", \"d2\", \"d3\", \"d4\"], name=\"inventory\")\n",
    "floor = inventory.cummin()\n",
    "print(\"Running floor:\", floor.to_dict())\n",
    "\n",
    "assert int(floor.loc[\"d1\"]) == 50\n",
    "assert int(floor.loc[\"d3\"]) == 42\n",
    "assert int(floor.loc[\"d4\"]) == 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6018d",
   "metadata": {},
   "source": [
    "##### Series.diff(periods=1)\n",
    "`diff(periods=1)` computes the difference between each value and a prior value. It is useful for change detection, like day-over-day movement in KPIs. The first entries where no prior value exists become missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "b4f8cee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "c299d12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     NaN\n",
       "b    10.0\n",
       "c    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321fc0b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0a966",
   "metadata": {},
   "source": [
    "`series.diff()` shows how much each row changed versus an earlier row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4b4e2",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ca737",
   "metadata": {},
   "source": [
    "- `periods` (`int`, default `1`): how many rows back to subtract from the current value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e878e5b",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db879a7",
   "metadata": {},
   "source": [
    "Think of a spreadsheet column that compares each cell with the one above it.\n",
    "\n",
    "- If today is higher, the difference is positive.\n",
    "\n",
    "- If today is lower, the difference is negative.\n",
    "\n",
    "You get row-by-row movement, not totals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5199c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d734325",
   "metadata": {},
   "source": [
    "- Pandas shifts values by `periods`.\n",
    "\n",
    "- It subtracts shifted values from current values at aligned labels.\n",
    "\n",
    "- Rows without enough history produce missing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afec3a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4af85",
   "metadata": {},
   "source": [
    "- First `periods` rows are `NaN` by design.\n",
    "\n",
    "- Differences depend on row order; unsorted data gives misleading changes.\n",
    "\n",
    "- Non-numeric data may error or coerce unexpectedly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1cf128",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93752aa9",
   "metadata": {},
   "source": [
    "- Is the Series sorted in the correct chronological/business order?\n",
    "\n",
    "- Should change be versus previous row or a longer lag?\n",
    "\n",
    "- Are initial `NaN` rows acceptable downstream?\n",
    "\n",
    "- Do you need absolute change (`diff`) or relative change (`pct_change`)?\n",
    "\n",
    "- Are index labels preserved for audit traceability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f96a5",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329333e5",
   "metadata": {},
   "source": [
    "Use `diff(periods)` to compute row-to-row (or lagged) absolute change while keeping labels aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5759029",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Calculate day-over-day unit change to detect sudden demand jumps.\n",
    "\n",
    "Scenario: each label is one day in reporting order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "f25f40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-over-day change: {'d1': nan, 'd2': 20.0, 'd3': -30.0, 'd4': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales = pd.Series([100, 120, 90, 95], index=[\"d1\", \"d2\", \"d3\", \"d4\"], name=\"sales\")\n",
    "delta = sales.diff(periods=1)\n",
    "print(\"Day-over-day change:\", delta.to_dict())\n",
    "\n",
    "assert pd.isna(delta.loc[\"d1\"])\n",
    "assert float(delta.loc[\"d2\"]) == 20.0\n",
    "assert float(delta.loc[\"d4\"]) == 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf3d4f",
   "metadata": {},
   "source": [
    "##### Series.pct_change(periods=1)\n",
    "`pct_change(periods=1)` computes relative change from a prior value as a fraction. It is widely used for growth rates in finance and product analytics. Remember: output is ratio change (for example, `0.10` means 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "b5af6d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "4db0372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    NaN\n",
       "b    1.0\n",
       "c    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7a994",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9d912",
   "metadata": {},
   "source": [
    "`series.pct_change()` tells you percent-style growth/decline between rows as decimal rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc00e3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a42e1",
   "metadata": {},
   "source": [
    "- `periods` (`int`, default `1`): lag to compare against.\n",
    "\n",
    "- `fill_method` (`None`, default `None`): optional fill behavior before computing change.\n",
    "\n",
    "- `freq` (date offset or `None`): time-based shift when using datetime-like indexes.\n",
    "\n",
    "- `**kwargs`: additional options passed through to internal shift operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f077f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4430c67",
   "metadata": {},
   "source": [
    "Think of a spreadsheet growth column: `(current - previous) / previous`.\n",
    "\n",
    "- Positive means growth.\n",
    "\n",
    "- Negative means decline.\n",
    "\n",
    "You measure rate, not raw difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10decb",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48730b",
   "metadata": {},
   "source": [
    "- Pandas aligns current values with lagged values from `periods` steps back.\n",
    "\n",
    "- It computes `(current / prior) - 1` element-wise.\n",
    "\n",
    "- Positions without a prior value return missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9136b4d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd637505",
   "metadata": {},
   "source": [
    "- First `periods` rows are `NaN`.\n",
    "\n",
    "- Division by zero can produce `inf` or missing values.\n",
    "\n",
    "- Unsorted indexes can produce incorrect growth interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80e92a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f5cb8",
   "metadata": {},
   "source": [
    "- Do stakeholders expect decimal rates (`0.05`) or percentages (`5%`)?\n",
    "\n",
    "- Is the row order correct for growth interpretation?\n",
    "\n",
    "- Can prior values be zero in your data?\n",
    "\n",
    "- Should missing values be filled before computing change?\n",
    "\n",
    "- Is lag `1` correct, or do you need week-over-week/month-over-month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbc658",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e6a67",
   "metadata": {},
   "source": [
    "Use `pct_change(periods)` for relative growth/decline rates on an ordered Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a50c6",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute week-over-week revenue growth rate for dashboard trend indicators.\n",
    "\n",
    "Scenario: each label is a weekly snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "6b043b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth rate: {'w1': nan, 'w2': 0.10000000000000009, 'w3': -0.09999999999999998, 'w4': 0.050000000000000044}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.Series([200.0, 220.0, 198.0, 207.9], index=[\"w1\", \"w2\", \"w3\", \"w4\"], name=\"revenue\")\n",
    "growth = revenue.pct_change(periods=1)\n",
    "print(\"Growth rate:\", growth.to_dict())\n",
    "\n",
    "assert pd.isna(growth.loc[\"w1\"])\n",
    "assert round(float(growth.loc[\"w2\"]), 4) == 0.1\n",
    "assert round(float(growth.loc[\"w4\"]), 4) == 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bb54d",
   "metadata": {},
   "source": [
    "##### Series.add(other)\n",
    "`add(other)` performs element-wise addition with index alignment. It is safer than using raw `+` when labels may differ. With `fill_value`, you can control how missing labels are treated during addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "bff2e31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "4e17fb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20\n",
       "b    30\n",
       "c    40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.add(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d74b879",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b0421",
   "metadata": {},
   "source": [
    "`series.add(other)` adds values by label, not just by position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad31b5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10697b8",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): value(s) to add.\n",
    "\n",
    "- `level` (int/label or `None`): align on a MultiIndex level when relevant.\n",
    "\n",
    "- `fill_value` (scalar or `None`): value used when one side has a missing label.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector kept for API consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa1fc3",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe073b8",
   "metadata": {},
   "source": [
    "Think of summing two spreadsheet columns by row labels.\n",
    "\n",
    "- Matching labels are added together.\n",
    "\n",
    "- Missing labels can be filled before adding.\n",
    "\n",
    "This prevents accidental position-based mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6aec03",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066facb",
   "metadata": {},
   "source": [
    "- Pandas aligns both operands by index labels.\n",
    "\n",
    "- It applies addition element-wise on aligned pairs.\n",
    "\n",
    "- `fill_value` substitutes missing side values before arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e2f51",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead052db",
   "metadata": {},
   "source": [
    "- Misaligned labels can create unexpected extra rows.\n",
    "\n",
    "- Without `fill_value`, unmatched labels may become missing.\n",
    "\n",
    "- Mixing dtypes can coerce output to a broader dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c575da2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18c24d",
   "metadata": {},
   "source": [
    "- Do both Series share the same business keys?\n",
    "\n",
    "- Should unmatched labels be treated as zero with `fill_value`?\n",
    "\n",
    "- Are you okay with union of indexes in the result?\n",
    "\n",
    "- Is label alignment preferred over raw positional arithmetic?\n",
    "\n",
    "- Are output dtypes acceptable for downstream steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fe8b3",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac200d03",
   "metadata": {},
   "source": [
    "Use `add` for explicit, label-aware addition and control missing-key behavior with `fill_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d016e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Combine baseline demand and manual adjustment signals by SKU.\n",
    "\n",
    "Scenario: some adjustments exist for SKUs missing from baseline and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "4180f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final quantity: {'sku1': 105.0, 'sku2': 80.0, 'sku3': 57.0, 'sku4': 4.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.Series([100, 80, 60], index=[\"sku1\", \"sku2\", \"sku3\"], name=\"base_qty\")\n",
    "adjustment = pd.Series([5, -3, 4], index=[\"sku1\", \"sku3\", \"sku4\"], name=\"adjustment\")\n",
    "\n",
    "final_qty = base.add(adjustment, fill_value=0)\n",
    "print(\"Final quantity:\", final_qty.to_dict())\n",
    "\n",
    "assert float(final_qty.loc[\"sku1\"]) == 105.0\n",
    "assert float(final_qty.loc[\"sku2\"]) == 80.0\n",
    "assert float(final_qty.loc[\"sku4\"]) == 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cebedd",
   "metadata": {},
   "source": [
    "##### Series.sub(other)\n",
    "`sub(other)` performs element-wise subtraction with index alignment. It is commonly used for residuals such as actual minus forecast. Like other arithmetic methods, labels drive pairing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "aa972eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "73345bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     5\n",
       "b    15\n",
       "c    25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.sub(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b32236",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ff256",
   "metadata": {},
   "source": [
    "`series.sub(other)` subtracts values by matching index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ae11d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a74ad4",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): value(s) to subtract.\n",
    "\n",
    "- `level` (int/label or `None`): align on a MultiIndex level when needed.\n",
    "\n",
    "- `fill_value` (scalar or `None`): replacement used for missing labels before subtraction.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector retained for API compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52305baf",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0092c",
   "metadata": {},
   "source": [
    "Think of comparing two spreadsheet columns: one baseline, one observed.\n",
    "\n",
    "- Subtract row by row using labels.\n",
    "\n",
    "- Positive means above baseline.\n",
    "\n",
    "You get signed deviation per label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75edbf8",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714efe6",
   "metadata": {},
   "source": [
    "- Pandas aligns indexes of both operands first.\n",
    "\n",
    "- It subtracts `other` from `self` at each aligned label.\n",
    "\n",
    "- Unmatched labels can be handled with `fill_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008cbfa",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a2f26",
   "metadata": {},
   "source": [
    "- Operand order matters (`a.sub(b)` differs from `b.sub(a)`).\n",
    "\n",
    "- Unmatched labels can introduce missing results if not filled.\n",
    "\n",
    "- Result dtype may upcast depending on missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ba653",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e6d54",
   "metadata": {},
   "source": [
    "- Is the subtraction direction correct for your business meaning?\n",
    "\n",
    "- Are both Series aligned on the same key labels?\n",
    "\n",
    "- Should unmatched labels be zero-filled?\n",
    "\n",
    "- Are negative outputs expected and handled?\n",
    "\n",
    "- Do you need absolute residuals after subtraction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826330ee",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84f90d",
   "metadata": {},
   "source": [
    "Use `sub` for explicit, label-aware subtraction and clear residual calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a672aa",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute forecast error per product (`actual - forecast`) for model monitoring.\n",
    "\n",
    "Scenario: each product keeps the same label for later grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "7dc41083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast error: {'p1': 10, 'p2': -5, 'p3': 0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "actual = pd.Series([120, 90, 100], index=[\"p1\", \"p2\", \"p3\"], name=\"actual\")\n",
    "forecast = pd.Series([110, 95, 100], index=[\"p1\", \"p2\", \"p3\"], name=\"forecast\")\n",
    "\n",
    "error = actual.sub(forecast)\n",
    "print(\"Forecast error:\", error.to_dict())\n",
    "\n",
    "assert int(error.loc[\"p1\"]) == 10\n",
    "assert int(error.loc[\"p2\"]) == -5\n",
    "assert int(error.loc[\"p3\"]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4247182",
   "metadata": {},
   "source": [
    "##### Series.mul(other)\n",
    "`mul(other)` performs element-wise multiplication with index alignment. It is useful for weighted metrics, scaling factors, and revenue-like calculations. `fill_value` helps define behavior for unmatched labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "9529c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "ceca7bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20\n",
       "b    40\n",
       "c    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.mul(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bae3a",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34e20b",
   "metadata": {},
   "source": [
    "`series.mul(other)` multiplies values by label-aligned counterpart values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82d8f9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8bea4",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): multiplier(s).\n",
    "\n",
    "- `level` (int/label or `None`): align across a specific MultiIndex level when needed.\n",
    "\n",
    "- `fill_value` (float/scalar or `None`): substitute for missing labels before multiplying.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector for API consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8a0e8",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474d802",
   "metadata": {},
   "source": [
    "Think of multiplying quantity by factor per labeled row in a spreadsheet.\n",
    "\n",
    "- Matching labels multiply directly.\n",
    "\n",
    "- Missing labels can use a default factor.\n",
    "\n",
    "You get controlled, aligned scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de91578",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a838b",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by index labels.\n",
    "\n",
    "- It multiplies aligned pairs element-wise.\n",
    "\n",
    "- Missing side values can be filled before multiplication using `fill_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd5c32",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724ea3f",
   "metadata": {},
   "source": [
    "- Unmatched labels may create unexpected extra index entries.\n",
    "\n",
    "- Zero/near-zero multipliers can flatten signal.\n",
    "\n",
    "- Dtype coercion can happen with mixed numeric types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c48b00",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726d681",
   "metadata": {},
   "source": [
    "- Are both operands indexed by the same business key?\n",
    "\n",
    "- Should missing multipliers default to 1.0 via `fill_value`?\n",
    "\n",
    "- Do you expect union index behavior in output?\n",
    "\n",
    "- Are negative multipliers valid in your domain?\n",
    "\n",
    "- Is numeric precision sufficient for reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ca891",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d627f3f",
   "metadata": {},
   "source": [
    "Use `mul` for label-aware multiplication and explicit missing-label handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c407f9a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Apply per-product weighting factors to units while preserving SKU labels.\n",
    "\n",
    "Scenario: some weights arrive for products not present in the units slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "2792fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted units: {'p1': 20.0, 'p2': 5.0, 'p3': 12.0, 'p4': 2.5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "units = pd.Series([10, 5, 8], index=[\"p1\", \"p2\", \"p3\"], name=\"units\")\n",
    "weight = pd.Series([2.0, 1.5, 2.5], index=[\"p1\", \"p3\", \"p4\"], name=\"weight\")\n",
    "\n",
    "weighted_units = units.mul(weight, fill_value=1.0)\n",
    "print(\"Weighted units:\", weighted_units.to_dict())\n",
    "\n",
    "assert float(weighted_units.loc[\"p1\"]) == 20.0\n",
    "assert float(weighted_units.loc[\"p2\"]) == 5.0\n",
    "assert float(weighted_units.loc[\"p4\"]) == 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c08321",
   "metadata": {},
   "source": [
    "##### Series.div(other)\n",
    "`div(other)` performs element-wise division with index alignment. It is useful for rate metrics such as cost per unit or conversion efficiency. Keep an eye on zero denominators and missing labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "99a6e553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "be6e1449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     5.0\n",
       "b    10.0\n",
       "c    15.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.div(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f9a9e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7c951",
   "metadata": {},
   "source": [
    "`series.div(other)` divides values by aligned counterpart values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42a363",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55676037",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): denominator value(s).\n",
    "\n",
    "- `level` (int/label or `None`): align on a MultiIndex level if applicable.\n",
    "\n",
    "- `fill_value` (scalar or `None`): replacement for missing labels before division.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector kept for API compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894fbf46",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbc15b",
   "metadata": {},
   "source": [
    "Think of dividing two labeled spreadsheet columns to get per-row rates.\n",
    "\n",
    "- Numerator and denominator pair by label.\n",
    "\n",
    "- Wrong/missing labels break rate meaning.\n",
    "\n",
    "You get interpretable per-label ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da036f",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b541d23",
   "metadata": {},
   "source": [
    "- Pandas aligns both operands by index.\n",
    "\n",
    "- It computes element-wise division (`self / other`) at matched labels.\n",
    "\n",
    "- Missing labels can be filled before computation using `fill_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa3761",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8cb186",
   "metadata": {},
   "source": [
    "- Division by zero yields `inf` or missing values.\n",
    "\n",
    "- Label mismatches can produce unexpected missing outputs.\n",
    "\n",
    "- Floating-point results may need rounding for presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69eaa75",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675407b",
   "metadata": {},
   "source": [
    "- Are denominators guaranteed non-zero?\n",
    "\n",
    "- Is `self / other` the intended direction?\n",
    "\n",
    "- Should missing labels be filled before division?\n",
    "\n",
    "- Do you need rounding policy for rates?\n",
    "\n",
    "- Are resulting rates validated against known benchmarks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3495be6",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ab253",
   "metadata": {},
   "source": [
    "Use `div` for explicit label-aware rate computation and monitor denominator quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5e234",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute cost-per-order per campaign from spend and order counts.\n",
    "\n",
    "Scenario: campaign labels must stay aligned for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "5705a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost per order: {'camp_a': 20.0, 'camp_b': 30.0, 'camp_c': 30.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spend = pd.Series([200.0, 150.0, 90.0], index=[\"camp_a\", \"camp_b\", \"camp_c\"], name=\"spend\")\n",
    "orders = pd.Series([10, 5, 3], index=[\"camp_a\", \"camp_b\", \"camp_c\"], name=\"orders\")\n",
    "\n",
    "cpo = spend.div(orders)\n",
    "print(\"Cost per order:\", cpo.to_dict())\n",
    "\n",
    "assert float(cpo.loc[\"camp_a\"]) == 20.0\n",
    "assert float(cpo.loc[\"camp_b\"]) == 30.0\n",
    "assert round(float(cpo.loc[\"camp_c\"]), 2) == 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9e7dc",
   "metadata": {},
   "source": [
    "##### Series.pow(other)\n",
    "`pow(other)` raises each value to a power using scalar or label-aligned exponents. It is useful in feature engineering for polynomial transformations. Alignment rules are the same as other arithmetic methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "ee7ba752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "c6300f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "b    400\n",
       "c    900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.pow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795332d",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e03712",
   "metadata": {},
   "source": [
    "`series.pow(other)` applies exponentiation element-wise with label alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe175ca",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef10ceb",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): exponent value(s).\n",
    "\n",
    "- `level` (int/label or `None`): align on a specific MultiIndex level when needed.\n",
    "\n",
    "- `fill_value` (scalar or `None`): replacement for missing labels before exponentiation.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector for API consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bc7ff",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15395b64",
   "metadata": {},
   "source": [
    "Think of a spreadsheet where each row can have its own exponent.\n",
    "\n",
    "- One row may be squared, another cubed.\n",
    "\n",
    "- Labels ensure the right exponent is matched to the right row.\n",
    "\n",
    "This enables controlled nonlinear scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d8c95",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1400f2",
   "metadata": {},
   "source": [
    "- Pandas aligns base and exponent operands by index labels.\n",
    "\n",
    "- It computes exponentiation per aligned pair.\n",
    "\n",
    "- Missing labels can be substituted via `fill_value` before calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e4718",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11655697",
   "metadata": {},
   "source": [
    "- Fractional exponents on negative bases may produce invalid/complex results.\n",
    "\n",
    "- Large exponents can overflow quickly.\n",
    "\n",
    "- Misaligned labels can distort intended transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16e254",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3e183",
   "metadata": {},
   "source": [
    "- Are exponents scalar or label-specific by design?\n",
    "\n",
    "- Can base values be negative with fractional exponents?\n",
    "\n",
    "- Is numeric range safe from overflow?\n",
    "\n",
    "- Do you need post-transform scaling/normalization?\n",
    "\n",
    "- Are label alignments validated before exponentiation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67882855",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae1042",
   "metadata": {},
   "source": [
    "Use `pow` for label-aware exponent transforms when nonlinear feature scaling is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22943a58",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create nonlinear score features by applying per-segment exponents to base scores.\n",
    "\n",
    "Scenario: each segment uses a known exponent profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "52265b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponent-scaled score: {'seg_a': 2, 'seg_b': 9, 'seg_c': 64}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_score = pd.Series([2, 3, 4], index=[\"seg_a\", \"seg_b\", \"seg_c\"], name=\"score\")\n",
    "exponent = pd.Series([1, 2, 3], index=[\"seg_a\", \"seg_b\", \"seg_c\"], name=\"exp\")\n",
    "\n",
    "scaled = base_score.pow(exponent)\n",
    "print(\"Exponent-scaled score:\", scaled.to_dict())\n",
    "\n",
    "assert int(scaled.loc[\"seg_a\"]) == 2\n",
    "assert int(scaled.loc[\"seg_b\"]) == 9\n",
    "assert int(scaled.loc[\"seg_c\"]) == 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26265c63",
   "metadata": {},
   "source": [
    "##### Series.mod(other)\n",
    "`mod(other)` computes the remainder after division, element-wise with alignment. It is useful for cyclic features, bucketing, and parity checks. The result keeps Series labels for downstream joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "ab6cc0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "184b2126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    0\n",
       "c    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.mod(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d039cf8",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d29ccb",
   "metadata": {},
   "source": [
    "`series.mod(other)` returns what is left after dividing each value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052b345",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89f50f",
   "metadata": {},
   "source": [
    "- `other` (scalar or Series): divisor value(s).\n",
    "\n",
    "- `level` (int/label or `None`): align on a MultiIndex level when relevant.\n",
    "\n",
    "- `fill_value` (scalar or `None`): substitute for missing labels before remainder calculation.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector retained for API consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4447220",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0590d",
   "metadata": {},
   "source": [
    "Think of splitting counts into fixed-size boxes and checking leftovers.\n",
    "\n",
    "- Remainder tells you leftover units.\n",
    "\n",
    "- With divisor 2, you get even/odd style outputs.\n",
    "\n",
    "Useful for cyclic grouping rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff96072",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffc431",
   "metadata": {},
   "source": [
    "- Pandas aligns operands by index labels.\n",
    "\n",
    "- It performs element-wise modulo arithmetic (`self % other`).\n",
    "\n",
    "- Missing label values can be filled before computing remainders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09806e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c05dc",
   "metadata": {},
   "source": [
    "- Modulo by zero is invalid and can produce errors/infinite results.\n",
    "\n",
    "- Sign behavior with negative values may surprise if not expected.\n",
    "\n",
    "- Misaligned indexes can create unintended missing rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7806856",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa7c30",
   "metadata": {},
   "source": [
    "- Is the divisor guaranteed non-zero?\n",
    "\n",
    "- Are negative inputs possible, and is remainder sign behavior acceptable?\n",
    "\n",
    "- Should missing labels be filled before modulo?\n",
    "\n",
    "- Are cyclic buckets clearly documented?\n",
    "\n",
    "- Do downstream steps expect integer remainder dtype?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f419697",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffe54e",
   "metadata": {},
   "source": [
    "Use `mod` for remainder-based grouping or cyclic features while preserving labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca03201",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Derive minute-within-hour from processing durations to detect scheduling patterns.\n",
    "\n",
    "Scenario: each job keeps its ID label for later diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "7837c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minute within hour: {'job_1': 1, 'job_2': 5, 'job_3': 59}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "minutes = pd.Series([61, 125, 59], index=[\"job_1\", \"job_2\", \"job_3\"], name=\"minutes\")\n",
    "minute_in_hour = minutes.mod(60)\n",
    "print(\"Minute within hour:\", minute_in_hour.to_dict())\n",
    "\n",
    "assert int(minute_in_hour.loc[\"job_1\"]) == 1\n",
    "assert int(minute_in_hour.loc[\"job_2\"]) == 5\n",
    "assert int(minute_in_hour.loc[\"job_3\"]) == 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35523e4",
   "metadata": {},
   "source": [
    "#### Window Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa310f82",
   "metadata": {},
   "source": [
    "##### Series.rolling(window)\n",
    "`rolling(window)` creates moving windows over ordered Series values. It is commonly used to smooth noise and compute local trend metrics. The output keeps the same index labels, so you can align results with original timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "8d515584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1    10\n",
       "d2    12\n",
       "d3    11\n",
       "d4    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([10, 12, 11, 15], index=[\"d1\", \"d2\", \"d3\", \"d4\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "bc40201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1     NaN\n",
       "d2    11.0\n",
       "d3    11.5\n",
       "d4    13.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.rolling(window=2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af028525",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f142d8d",
   "metadata": {},
   "source": [
    "`series.rolling(window)` builds a sliding chunk of rows, then you apply an aggregation like `mean()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842c221",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7390c",
   "metadata": {},
   "source": [
    "- `window` (int, offset, or indexer): window size definition.\n",
    "\n",
    "- `min_periods` (`int` or `None`): minimum valid points required to return a value.\n",
    "\n",
    "- `center` (`bool`, default `False`): place result labels at the center of the window.\n",
    "\n",
    "- `win_type` (`str` or `None`): optional weighted window type.\n",
    "\n",
    "- `on` (`str` or `None`): column label for DataFrame time windows; usually not used for Series.\n",
    "\n",
    "- `closed` (`\"left\"`, `\"right\"`, `\"both\"`, `\"neither\"`, or `None`): interval closure for time windows.\n",
    "\n",
    "- `step` (`int` or `None`): evaluate every n-th window.\n",
    "\n",
    "- `method` (`\"single\"` or `\"table\"`): execution method for some engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bce3a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3dbdef",
   "metadata": {},
   "source": [
    "Think of looking at a spreadsheet through a small moving frame.\n",
    "\n",
    "- The frame slides row by row.\n",
    "\n",
    "- You compute one summary per frame.\n",
    "\n",
    "This gives local trend signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdca26",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5844e0a",
   "metadata": {},
   "source": [
    "- Pandas defines a window around each label using your `window` rule.\n",
    "\n",
    "- It applies the chosen aggregation on values inside each window.\n",
    "\n",
    "- If valid points are below `min_periods`, result is missing for that label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7bdb1",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a4767",
   "metadata": {},
   "source": [
    "- Early rows can be `NaN` when full windows are not available.\n",
    "\n",
    "- Wrong sort order gives misleading rolling statistics.\n",
    "\n",
    "- Large windows can hide fast local changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a941a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4ebe",
   "metadata": {},
   "source": [
    "- Is the Series sorted in the intended temporal/business order?\n",
    "\n",
    "- What window size best matches the process cycle?\n",
    "\n",
    "- Should partial windows be allowed with `min_periods`?\n",
    "\n",
    "- Do you need simple or weighted windows?\n",
    "\n",
    "- Are edge `NaN` values handled downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d77275",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2126504",
   "metadata": {},
   "source": [
    "Use `rolling` to compute moving metrics over nearby rows while preserving index alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6370cf",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Smooth daily order counts with a 2-day moving average for a stable dashboard signal.\n",
    "\n",
    "Scenario: keep date labels unchanged so the metric can be merged with original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "f93268c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-day moving average: {Timestamp('2025-01-01 00:00:00'): nan, Timestamp('2025-01-02 00:00:00'): 110.0, Timestamp('2025-01-03 00:00:00'): 105.0, Timestamp('2025-01-04 00:00:00'): 100.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.Series(\n",
    "    [100, 120, 90, 110],\n",
    "    index=pd.to_datetime([\"2025-01-01\", \"2025-01-02\", \"2025-01-03\", \"2025-01-04\"]),\n",
    "    name=\"orders\",\n",
    ")\n",
    "\n",
    "ma2 = orders.rolling(window=2, min_periods=2).mean()\n",
    "print(\"2-day moving average:\", ma2.to_dict())\n",
    "\n",
    "assert pd.isna(ma2.loc[pd.Timestamp(\"2025-01-01\")])\n",
    "assert float(ma2.loc[pd.Timestamp(\"2025-01-02\")]) == 110.0\n",
    "assert float(ma2.loc[pd.Timestamp(\"2025-01-04\")]) == 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987b63c",
   "metadata": {},
   "source": [
    "##### Series.expanding()\n",
    "`expanding()` creates a growing window from the first row to the current row. It is useful for running metrics where history should never be dropped. The output stays aligned to the original index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c346efc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch1    2\n",
       "batch2    1\n",
       "batch3    3\n",
       "batch4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([2, 1, 3, 0], index=[\"batch1\", \"batch2\", \"batch3\", \"batch4\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "87e7d401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch1    2.0\n",
       "batch2    1.5\n",
       "batch3    2.0\n",
       "batch4    1.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.expanding(min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2f7d4",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7cdda",
   "metadata": {},
   "source": [
    "`series.expanding()` uses all rows seen so far and updates the summary each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79078ac3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff812f46",
   "metadata": {},
   "source": [
    "- `min_periods` (`int`, default `1`): minimum observations before producing a value.\n",
    "\n",
    "- `method` (`\"single\"` or `\"table\"`, default `\"single\"`): execution method for supported engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e7d5",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee38402",
   "metadata": {},
   "source": [
    "Think of a spreadsheet summary that keeps adding new rows to the calculation.\n",
    "\n",
    "- Row 1 uses only row 1.\n",
    "\n",
    "- Row 4 uses rows 1 to 4.\n",
    "\n",
    "You get cumulative context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94db4d1",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70a1a7",
   "metadata": {},
   "source": [
    "- Pandas grows the active window from start to current label.\n",
    "\n",
    "- The chosen aggregation is recomputed on that expanding range.\n",
    "\n",
    "- `min_periods` controls when outputs start being non-missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e9ab6",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51035cd4",
   "metadata": {},
   "source": [
    "- Old history keeps affecting values, so recent shifts may appear slowly.\n",
    "\n",
    "- Wrong row order breaks cumulative interpretation.\n",
    "\n",
    "- Expanding metrics are less reactive than rolling metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ff55a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629002a6",
   "metadata": {},
   "source": [
    "- Do you need full-history context (`expanding`) or local context (`rolling`)?\n",
    "\n",
    "- Is row ordering guaranteed correct?\n",
    "\n",
    "- Should early rows be missing until a threshold count is reached?\n",
    "\n",
    "- Is slow responsiveness acceptable for your decision use case?\n",
    "\n",
    "- Are cumulative metrics clearly labeled in reports?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1436d5b",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649ee2c",
   "metadata": {},
   "source": [
    "Use `expanding` when each new value should summarize everything observed up to that point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f4fdd",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Track cumulative average defect count by production batch to monitor long-run quality trend.\n",
    "\n",
    "Scenario: each batch label remains traceable in QA logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "c15bacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative average defects: {'batch1': 2.0, 'batch2': 1.5, 'batch3': 2.0, 'batch4': 1.5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "defects = pd.Series([2, 1, 3, 0], index=[\"batch1\", \"batch2\", \"batch3\", \"batch4\"], name=\"defects\")\n",
    "cum_avg = defects.expanding(min_periods=1).mean()\n",
    "print(\"Cumulative average defects:\", cum_avg.to_dict())\n",
    "\n",
    "assert float(cum_avg.loc[\"batch1\"]) == 2.0\n",
    "assert float(cum_avg.loc[\"batch3\"]) == 2.0\n",
    "assert cum_avg.index.equals(defects.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f65d41",
   "metadata": {},
   "source": [
    "##### Series.ewm(span)\n",
    "`ewm(...)` computes exponentially weighted statistics, giving more weight to recent observations. It is useful for responsive smoothing where old points should decay in influence. You choose decay through one of `span`, `com`, `halflife`, or `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "8b023929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t1    100\n",
       "t2    120\n",
       "t3     80\n",
       "t4     90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([100, 120, 80, 90], index=[\"t1\", \"t2\", \"t3\", \"t4\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "4d476b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t1    100.000000\n",
       "t2    113.333333\n",
       "t3     91.111111\n",
       "t4     90.370370\n",
       "dtype: float64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.ewm(span=2, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138cc64",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59badaa1",
   "metadata": {},
   "source": [
    "`series.ewm(...)` makes a smoothed series where recent rows count more than older rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69e502",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90228f",
   "metadata": {},
   "source": [
    "- `com` (`float` or `None`): center-of-mass decay parameter.\n",
    "\n",
    "- `span` (`float` or `None`): span-based decay parameter.\n",
    "\n",
    "- `halflife` (`float`, timedelta-like, or `None`): decay speed as half-life.\n",
    "\n",
    "- `alpha` (`float` or `None`): direct smoothing factor.\n",
    "\n",
    "- `min_periods` (`int` or `None`, default `0`): minimum observations before output.\n",
    "\n",
    "- `adjust` (`bool`, default `True`): choose weighted formula style.\n",
    "\n",
    "- `ignore_na` (`bool`, default `False`): control missing-value treatment in weighting.\n",
    "\n",
    "- `times` (array-like or `None`): optional time stamps for irregularly spaced data.\n",
    "\n",
    "- `method` (`\"single\"` or `\"table\"`, default `\"single\"`): execution method for supported engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1a4d6",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ca8cf",
   "metadata": {},
   "source": [
    "Think of a score where yesterday matters more than last month.\n",
    "\n",
    "- New rows quickly influence the line.\n",
    "\n",
    "- Old rows fade but are not fully ignored.\n",
    "\n",
    "You get smoother but still responsive trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e4358",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ef421",
   "metadata": {},
   "source": [
    "- Pandas assigns exponentially decaying weights to past observations.\n",
    "\n",
    "- Recent values receive larger weights than older ones.\n",
    "\n",
    "- The weighted aggregation is computed at each label, preserving index alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603da66",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f998507",
   "metadata": {},
   "source": [
    "- Different decay settings can change interpretation a lot.\n",
    "\n",
    "- `adjust=True` vs `adjust=False` produces different numeric paths.\n",
    "\n",
    "- Poorly chosen decay can oversmooth or overreact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81d1ad",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248410d",
   "metadata": {},
   "source": [
    "- Which decay parameter (`span/com/halflife/alpha`) is easiest to explain to stakeholders?\n",
    "\n",
    "- Should smoothing prioritize responsiveness or stability?\n",
    "\n",
    "- Is `adjust=False` preferred for recursive real-time behavior?\n",
    "\n",
    "- How should missing values affect smoothing?\n",
    "\n",
    "- Are smoothed values validated against known events?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac30c96",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f1f60",
   "metadata": {},
   "source": [
    "Use `ewm` for weighted smoothing where recent observations should matter more than old ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d9cff",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Smooth minute-level traffic counts to reduce noise while preserving recent changes for alerting.\n",
    "\n",
    "Scenario: recent traffic spikes should influence the signal quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "f70b2cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWM mean: {'m1': 100.0, 'm2': 113.33333333333334, 'm3': 91.11111111111111, 'm4': 90.37037037037038}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "traffic = pd.Series([100, 120, 80, 90], index=[\"m1\", \"m2\", \"m3\", \"m4\"], name=\"traffic\")\n",
    "ewm_mean = traffic.ewm(span=2, adjust=False).mean()\n",
    "print(\"EWM mean:\", ewm_mean.to_dict())\n",
    "\n",
    "assert round(float(ewm_mean.loc[\"m1\"]), 2) == 100.00\n",
    "assert round(float(ewm_mean.loc[\"m2\"]), 2) == 113.33\n",
    "assert round(float(ewm_mean.loc[\"m4\"]), 2) == 90.37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d585bd7",
   "metadata": {},
   "source": [
    "#### Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac66d6d",
   "metadata": {},
   "source": [
    "##### Series.resample(rule)\n",
    "`resample(rule)` groups time-indexed Series data into new calendar/frequency bins. It is used to upsample or downsample before aggregation and reporting. A datetime-like index (or an explicit datetime level) is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "1754d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-01 00:00:00    1\n",
       "2025-01-01 12:00:00    2\n",
       "2025-01-02 00:00:00    3\n",
       "2025-01-02 12:00:00    4\n",
       "Freq: 12h, Name: value, dtype: int64"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [1, 2, 3, 4],\n",
    "    index=pd.date_range(\"2025-01-01\", periods=4, freq=\"12h\"),\n",
    "    name=\"value\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "4e18359f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-01    3\n",
       "2025-01-02    7\n",
       "Freq: D, Name: value, dtype: int64"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample(\"D\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54101ce2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30d733",
   "metadata": {},
   "source": [
    "`series.resample(rule)` regroups time rows into new time buckets, then you apply an aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b655d73",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa88cc6",
   "metadata": {},
   "source": [
    "- `rule` (offset alias like `\"D\"`, `\"W\"`, `\"M\"`): target frequency buckets.\n",
    "\n",
    "- `closed` (`\"left\"`/`\"right\"` or `None`): which bin side is inclusive.\n",
    "\n",
    "- `label` (`\"left\"`/`\"right\"` or `None`): which bin edge labels the output index.\n",
    "\n",
    "- `convention` (`\"start\"`/`\"end\"`, etc.): period conversion convention.\n",
    "\n",
    "- `on` (label or `None`): datetime column to use when operating on DataFrames.\n",
    "\n",
    "- `level` (index level or `None`): datetime level in MultiIndex data.\n",
    "\n",
    "- `origin` (timestamp/keyword): anchor point for bin alignment.\n",
    "\n",
    "- `offset` (timedelta-like or `None`): shift bin edges.\n",
    "\n",
    "- `group_keys` (`bool`, default `False`): include group keys in apply output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e5d9a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd6e1a",
   "metadata": {},
   "source": [
    "Think of folding detailed timestamps into calendar bins in a spreadsheet pivot.\n",
    "\n",
    "- Many rows collapse into one bucket.\n",
    "\n",
    "- You choose how each bucket is summarized.\n",
    "\n",
    "This standardizes reporting frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e63261",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd80cb",
   "metadata": {},
   "source": [
    "- Pandas maps each timestamp to a bin defined by `rule`.\n",
    "\n",
    "- Values in the same bin are grouped together.\n",
    "\n",
    "- You run an aggregation (`sum`, `mean`, etc.) on each bin to produce output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec2fb5",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19809",
   "metadata": {},
   "source": [
    "- Requires datetime-like index/level; plain index will fail.\n",
    "\n",
    "- Bin boundary settings (`closed`, `label`) can change results noticeably.\n",
    "\n",
    "- Time zone and daylight-saving changes can complicate interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03a41b",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3f3e0",
   "metadata": {},
   "source": [
    "- Is your index truly datetime-like and timezone-consistent?\n",
    "\n",
    "- Which aggregation matches business meaning for each bin?\n",
    "\n",
    "- Are bin labels/closures documented for consumers?\n",
    "\n",
    "- Do you need anchored bins via `origin`/`offset`?\n",
    "\n",
    "- Have you validated totals before and after resampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a5bef",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5b714",
   "metadata": {},
   "source": [
    "Use `resample` to regroup time-indexed data into new frequencies, then aggregate per bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aec616",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Aggregate 12-hour energy readings into daily totals for reporting.\n",
    "\n",
    "Scenario: each daily label represents total energy for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "55fc83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily energy: {Timestamp('2025-01-01 00:00:00'): 3.0, Timestamp('2025-01-02 00:00:00'): 7.0, Timestamp('2025-01-03 00:00:00'): 11.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "energy = pd.Series(\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    index=pd.date_range(\"2025-01-01\", periods=6, freq=\"12h\"),\n",
    "    name=\"kwh\",\n",
    ")\n",
    "\n",
    "daily = energy.resample(\"D\").sum()\n",
    "print(\"Daily energy:\", daily.to_dict())\n",
    "\n",
    "assert float(daily.loc[pd.Timestamp(\"2025-01-01\")]) == 3.0\n",
    "assert float(daily.loc[pd.Timestamp(\"2025-01-02\")]) == 7.0\n",
    "assert float(daily.loc[pd.Timestamp(\"2025-01-03\")]) == 11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14872423",
   "metadata": {},
   "source": [
    "##### Series.asfreq(freq)\n",
    "`asfreq(freq)` converts a time-indexed Series to a new fixed frequency without aggregation. Missing timestamps introduced by the new frequency become `NaN` unless filled. Use it when you need a regular time grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "61724026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-01    10\n",
       "2025-01-03    12\n",
       "2025-01-04    11\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [10, 12, 11],\n",
    "    index=pd.to_datetime([\"2025-01-01\", \"2025-01-03\", \"2025-01-04\"]),\n",
    "    name=\"value\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "055ac3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-01    10.0\n",
       "2025-01-02     NaN\n",
       "2025-01-03    12.0\n",
       "2025-01-04    11.0\n",
       "Freq: D, Name: value, dtype: float64"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq(\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7143f66",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6abae",
   "metadata": {},
   "source": [
    "`series.asfreq(freq)` puts your series on a fixed time grid and leaves gaps where data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46abf9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7fde5",
   "metadata": {},
   "source": [
    "- `freq` (offset alias): target frequency (for example, `\"D\"`, `\"H\"`).\n",
    "\n",
    "- `method` (`\"ffill\"`, `\"bfill\"`, or `None`): optional fill strategy for introduced gaps.\n",
    "\n",
    "- `how` (`\"start\"`, `\"end\"`, or `None`): convention for PeriodIndex conversions.\n",
    "\n",
    "- `normalize` (`bool`, default `False`): normalize timestamps to midnight before conversion.\n",
    "\n",
    "- `fill_value` (scalar or `None`): value used to fill new missing timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a652e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fa3e4",
   "metadata": {},
   "source": [
    "Think of forcing a spreadsheet time column to include every calendar day.\n",
    "\n",
    "- Existing days keep original values.\n",
    "\n",
    "- Missing days appear as blank (or filled) rows.\n",
    "\n",
    "You get a regular timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b6c98",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a2c54",
   "metadata": {},
   "source": [
    "- Pandas builds a new index at the requested frequency.\n",
    "\n",
    "- Existing timestamps are aligned to this new grid.\n",
    "\n",
    "- New timestamps receive missing values or configured fills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b1f05",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913bdb0",
   "metadata": {},
   "source": [
    "- `asfreq` does not aggregate; it only reindexes frequency.\n",
    "\n",
    "- Large upsampling can create many missing rows.\n",
    "\n",
    "- Wrong fill strategy can introduce artificial patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f34141",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9513ce",
   "metadata": {},
   "source": [
    "- Do you need frequency conversion only (`asfreq`) or binning+aggregation (`resample`)?\n",
    "\n",
    "- Should introduced gaps stay missing or be filled?\n",
    "\n",
    "- Is target frequency aligned with business reporting cadence?\n",
    "\n",
    "- Could upsampling explode row count unnecessarily?\n",
    "\n",
    "- Are timezone and calendar assumptions explicit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1a4fc",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5025d",
   "metadata": {},
   "source": [
    "Use `asfreq` to place a time Series on a regular frequency grid without combining rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6f55e",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Normalize irregular telemetry to daily checkpoints before feature engineering.\n",
    "\n",
    "Scenario: missing days should remain visible as `NaN` for data quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "b1e92bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily grid: {Timestamp('2025-01-01 00:00:00'): 10.0, Timestamp('2025-01-02 00:00:00'): nan, Timestamp('2025-01-03 00:00:00'): 12.0, Timestamp('2025-01-04 00:00:00'): 11.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "telemetry = pd.Series(\n",
    "    [10.0, 12.0, 11.0],\n",
    "    index=pd.to_datetime([\"2025-01-01\", \"2025-01-03\", \"2025-01-04\"]),\n",
    "    name=\"metric\",\n",
    ")\n",
    "\n",
    "daily = telemetry.asfreq(\"D\")\n",
    "print(\"Daily grid:\", daily.to_dict())\n",
    "\n",
    "assert float(daily.loc[pd.Timestamp(\"2025-01-01\")]) == 10.0\n",
    "assert pd.isna(daily.loc[pd.Timestamp(\"2025-01-02\")])\n",
    "assert float(daily.loc[pd.Timestamp(\"2025-01-04\")]) == 11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd2b6d",
   "metadata": {},
   "source": [
    "##### Series.shift(periods=1)\n",
    "`shift(periods=1)` moves values up or down relative to the index. It is commonly used to create lag or lead features for time-series modeling. By default, the index stays the same and only values are shifted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "7c65a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-02-01    50\n",
       "2025-02-02    55\n",
       "2025-02-03    53\n",
       "Name: demand, dtype: int64"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [50, 55, 53],\n",
    "    index=pd.to_datetime([\"2025-02-01\", \"2025-02-02\", \"2025-02-03\"]),\n",
    "    name=\"demand\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "edbc1b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-02-01     NaN\n",
       "2025-02-02    50.0\n",
       "2025-02-03    55.0\n",
       "Name: demand, dtype: float64"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35025ddc",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e898a4",
   "metadata": {},
   "source": [
    "`series.shift(periods)` repositions values by a lag/lead amount, creating empty spots at the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319f3a5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927045a",
   "metadata": {},
   "source": [
    "- `periods` (`int` or sequence of `int`, default `1`): number of steps to shift values.\n",
    "\n",
    "- `freq` (offset or `None`): shift index by frequency instead of shifting raw values.\n",
    "\n",
    "- `axis` (`0`, default `0`): axis selector (Series uses index axis).\n",
    "\n",
    "- `fill_value` (scalar, optional): value inserted into newly created missing positions.\n",
    "\n",
    "- `suffix` (`str` or `None`): suffix for column naming when multiple periods return a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18b97f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f914c",
   "metadata": {},
   "source": [
    "Think of copying a spreadsheet column and moving it down by one row.\n",
    "\n",
    "- Each row now sees the previous row value.\n",
    "\n",
    "- Top row becomes empty (or filled).\n",
    "\n",
    "This creates lag features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce98483",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828540e",
   "metadata": {},
   "source": [
    "- Pandas offsets values by the requested number of periods.\n",
    "\n",
    "- Edge positions created by the shift are filled with missing or `fill_value`.\n",
    "\n",
    "- With `freq`, timestamps are shifted in calendar terms instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbecfce",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f321de",
   "metadata": {},
   "source": [
    "- Edge `NaN` rows are expected and must be handled before modeling.\n",
    "\n",
    "- Positive vs negative periods invert lag/lead direction.\n",
    "\n",
    "- Confusing value shift with index-frequency shift can cause logic bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1f160",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5d018",
   "metadata": {},
   "source": [
    "- Do you need a lag (`periods>0`) or lead (`periods<0`)?\n",
    "\n",
    "- Should edge missing values be dropped or filled?\n",
    "\n",
    "- Are you shifting values or shifting timestamps via `freq`?\n",
    "\n",
    "- Is index ordering validated before creating lags?\n",
    "\n",
    "- Are lag features aligned with target horizon?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184d68a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149924b",
   "metadata": {},
   "source": [
    "Use `shift` to create lag/lead features while preserving original index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20d5b1",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build a one-day lag demand feature for a forecasting model.\n",
    "\n",
    "Scenario: each date keeps its own row, and lagged value comes from the previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "4d07958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag-1 demand: {Timestamp('2025-02-01 00:00:00'): nan, Timestamp('2025-02-02 00:00:00'): 50.0, Timestamp('2025-02-03 00:00:00'): 55.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "demand = pd.Series(\n",
    "    [50, 55, 53],\n",
    "    index=pd.to_datetime([\"2025-02-01\", \"2025-02-02\", \"2025-02-03\"]),\n",
    "    name=\"demand\",\n",
    ")\n",
    "\n",
    "lag1 = demand.shift(periods=1)\n",
    "print(\"Lag-1 demand:\", lag1.to_dict())\n",
    "\n",
    "assert pd.isna(lag1.loc[pd.Timestamp(\"2025-02-01\")])\n",
    "assert float(lag1.loc[pd.Timestamp(\"2025-02-02\")]) == 50.0\n",
    "assert float(lag1.loc[pd.Timestamp(\"2025-02-03\")]) == 55.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbecb8b4",
   "metadata": {},
   "source": [
    "##### Series.diff(periods=1)\n",
    "`diff(periods=1)` computes absolute change between each timestamp and its lagged value. In time series, it is useful for first-difference analysis and change-point checks. The index stays the same, so each difference remains tied to its date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "37802f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-03-01    20.0\n",
       "2025-03-02    22.5\n",
       "2025-03-03    21.0\n",
       "Name: temp_c, dtype: float64"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [20.0, 22.5, 21.0],\n",
    "    index=pd.to_datetime([\"2025-03-01\", \"2025-03-02\", \"2025-03-03\"]),\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "0590a9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-03-01    NaN\n",
       "2025-03-02    2.5\n",
       "2025-03-03   -1.5\n",
       "Name: temp_c, dtype: float64"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.diff(periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dfe685",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455a545",
   "metadata": {},
   "source": [
    "`series.diff()` shows how much the value moved since the previous timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6686a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863afe6d",
   "metadata": {},
   "source": [
    "- `periods` (`int`, default `1`): lag distance used for subtraction in time order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ff9aa",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3055e",
   "metadata": {},
   "source": [
    "Think of a daily spreadsheet where each row compares today to yesterday.\n",
    "\n",
    "- Positive means increase.\n",
    "\n",
    "- Negative means decrease.\n",
    "\n",
    "You read step-by-step movement over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5497a58",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4160a",
   "metadata": {},
   "source": [
    "- Pandas shifts the series by `periods` timestamps.\n",
    "\n",
    "- It subtracts lagged values from current values label-by-label.\n",
    "\n",
    "- Initial rows without enough history return missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244c7c3",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a8bfd",
   "metadata": {},
   "source": [
    "- First `periods` rows become `NaN` by design.\n",
    "\n",
    "- Wrong chronological order gives wrong differences.\n",
    "\n",
    "- Gaps in timestamps are not automatically normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db369cba",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdec11e",
   "metadata": {},
   "source": [
    "- Is the index sorted in chronological order?\n",
    "\n",
    "- Should lag be 1 period or a longer interval?\n",
    "\n",
    "- Are first missing differences acceptable downstream?\n",
    "\n",
    "- Do irregular time gaps need resampling before diff?\n",
    "\n",
    "- Do you need absolute diff or relative change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704b3c6",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94ee9d",
   "metadata": {},
   "source": [
    "Use `diff` on time-indexed Series to measure step-to-step absolute movement at each timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d170b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Track day-over-day temperature changes to detect abrupt weather-driven demand shifts.\n",
    "\n",
    "Scenario: each output value remains linked to its calendar day label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "d0651806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily temperature change: {Timestamp('2025-03-01 00:00:00'): nan, Timestamp('2025-03-02 00:00:00'): 2.5, Timestamp('2025-03-03 00:00:00'): -1.5, Timestamp('2025-03-04 00:00:00'): 3.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temperature = pd.Series(\n",
    "    [20.0, 22.5, 21.0, 24.0],\n",
    "    index=pd.to_datetime([\"2025-03-01\", \"2025-03-02\", \"2025-03-03\", \"2025-03-04\"]),\n",
    "    name=\"temp_c\",\n",
    ")\n",
    "\n",
    "daily_change = temperature.diff()\n",
    "print(\"Daily temperature change:\", daily_change.to_dict())\n",
    "\n",
    "assert pd.isna(daily_change.loc[pd.Timestamp(\"2025-03-01\")])\n",
    "assert float(daily_change.loc[pd.Timestamp(\"2025-03-02\")]) == 2.5\n",
    "assert float(daily_change.loc[pd.Timestamp(\"2025-03-04\")]) == 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc817b",
   "metadata": {},
   "source": [
    "##### Series.pct_change(periods=1)\n",
    "`pct_change(periods=1)` computes relative growth/decline between each timestamp and its lag. It is commonly used for returns, growth rates, and momentum signals. Results are decimal rates (`0.10` means 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "2ab01a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-04-01    100.0\n",
       "2025-04-02    110.0\n",
       "2025-04-03    121.0\n",
       "Name: visits, dtype: float64"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [100.0, 110.0, 121.0],\n",
    "    index=pd.to_datetime([\"2025-04-01\", \"2025-04-02\", \"2025-04-03\"]),\n",
    "    name=\"visits\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "f3c84384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-04-01    NaN\n",
       "2025-04-02    0.1\n",
       "2025-04-03    0.1\n",
       "Name: visits, dtype: float64"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.pct_change(periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f7fbf",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae296f2",
   "metadata": {},
   "source": [
    "`series.pct_change()` tells you the percentage-style rate change from the previous timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61e21e",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68454f70",
   "metadata": {},
   "source": [
    "- `periods` (`int`, default `1`): lag used for relative comparison.\n",
    "\n",
    "- `fill_method` (`None`, default `None`): optional filling before computing change.\n",
    "\n",
    "- `freq` (offset or `None`): time-based shift for comparison on datetime-like index.\n",
    "\n",
    "- `**kwargs`: extra options passed to internal shift behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12768e06",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0ae2e",
   "metadata": {},
   "source": [
    "Think of a growth-rate column in a time spreadsheet.\n",
    "\n",
    "- `0.10` means 10% up from prior row.\n",
    "\n",
    "- `-0.10` means 10% down.\n",
    "\n",
    "You track relative movement, not raw units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88004045",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b331c0",
   "metadata": {},
   "source": [
    "- Pandas aligns each timestamp with its lagged observation.\n",
    "\n",
    "- It computes `(current / lagged) - 1` element-wise.\n",
    "\n",
    "- Initial rows without lag context are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84f012",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbea55",
   "metadata": {},
   "source": [
    "- Division by zero can yield infinite or invalid values.\n",
    "\n",
    "- First lagged positions are `NaN`.\n",
    "\n",
    "- Unsorted timestamps distort growth interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcdc94",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5e2f3",
   "metadata": {},
   "source": [
    "- Is time ordering guaranteed before computing growth?\n",
    "\n",
    "- Are zeros possible in the lagged denominator?\n",
    "\n",
    "- Should output be displayed as decimal or percent format?\n",
    "\n",
    "- Do missing intervals require resampling first?\n",
    "\n",
    "- Is lag 1 period correct for business cadence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70544978",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec2350",
   "metadata": {},
   "source": [
    "Use `pct_change` on time-indexed data to quantify relative change between consecutive timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521bc01",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Compute day-over-day session growth to monitor traffic momentum.\n",
    "\n",
    "Scenario: each day keeps its date label for dashboard joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "32217b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session growth: {Timestamp('2025-04-01 00:00:00'): nan, Timestamp('2025-04-02 00:00:00'): 0.19999999999999996, Timestamp('2025-04-03 00:00:00'): -0.09999999999999998}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sessions = pd.Series(\n",
    "    [100.0, 120.0, 108.0],\n",
    "    index=pd.to_datetime([\"2025-04-01\", \"2025-04-02\", \"2025-04-03\"]),\n",
    "    name=\"sessions\",\n",
    ")\n",
    "\n",
    "growth = sessions.pct_change()\n",
    "print(\"Session growth:\", growth.to_dict())\n",
    "\n",
    "assert pd.isna(growth.loc[pd.Timestamp(\"2025-04-01\")])\n",
    "assert round(float(growth.loc[pd.Timestamp(\"2025-04-02\")]), 4) == 0.2\n",
    "assert round(float(growth.loc[pd.Timestamp(\"2025-04-03\")]), 4) == -0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5457b9",
   "metadata": {},
   "source": [
    "##### Series.to_period(freq)\n",
    "`to_period(freq)` converts a DatetimeIndex Series into a PeriodIndex at the requested frequency. It is useful when analysis is period-based (month, quarter) rather than point-in-time. Values are unchanged; the index representation changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "3c8ad118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-15    10\n",
       "2025-02-15    12\n",
       "2025-03-15    11\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts = pd.Series(\n",
    "    [10, 12, 11],\n",
    "    index=pd.to_datetime([\"2025-01-15\", \"2025-02-15\", \"2025-03-15\"]),\n",
    "    name=\"sales\",\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "6aef8a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01    10\n",
       "2025-02    12\n",
       "2025-03    11\n",
       "Freq: M, Name: sales, dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e97fb",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414de5b",
   "metadata": {},
   "source": [
    "`series.to_period(freq)` switches timestamp labels into period labels like months or quarters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c15104",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0e6ac",
   "metadata": {},
   "source": [
    "- `freq` (`str` or `None`): target period frequency (`\"M\"`, `\"Q\"`, etc.).\n",
    "\n",
    "- `copy` (`bool`, optional): whether to copy underlying data during conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907a2a0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05f600",
   "metadata": {},
   "source": [
    "Think of relabeling exact calendar dates as month buckets in a spreadsheet.\n",
    "\n",
    "- `2025-01-15` becomes `2025-01`.\n",
    "\n",
    "- Data values stay the same.\n",
    "\n",
    "Only time label granularity changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2e1f6",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c787f9",
   "metadata": {},
   "source": [
    "- Pandas reads each datetime label and maps it to a period at `freq`.\n",
    "\n",
    "- The index class changes from `DatetimeIndex` to `PeriodIndex`.\n",
    "\n",
    "- Series values are preserved and remain aligned to new period labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555f97c",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66283b",
   "metadata": {},
   "source": [
    "- Requires datetime-like index for direct conversion.\n",
    "\n",
    "- Choosing wrong `freq` can misalign reporting logic.\n",
    "\n",
    "- After conversion, methods expecting timestamps may need `to_timestamp` first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfb454",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34699a",
   "metadata": {},
   "source": [
    "- Do you need point-in-time timestamps or period buckets?\n",
    "\n",
    "- Is frequency `M`, `Q`, or `Y` correct for reporting?\n",
    "\n",
    "- Will downstream operations accept a `PeriodIndex`?\n",
    "\n",
    "- Should conversion happen before or after aggregation?\n",
    "\n",
    "- Are period labels clearly documented for consumers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9e91c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18116c5",
   "metadata": {},
   "source": [
    "Use `to_period` to represent time labels as periods (like months) without changing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f337319",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert daily billing timestamps to monthly period labels before period-based joins.\n",
    "\n",
    "Scenario: analysis keys are monthly periods, not exact dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "b379c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly index: [Period('2025-01', 'M'), Period('2025-02', 'M'), Period('2025-03', 'M')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "billing = pd.Series(\n",
    "    [300, 320, 310],\n",
    "    index=pd.to_datetime([\"2025-01-10\", \"2025-02-10\", \"2025-03-10\"]),\n",
    "    name=\"amount\",\n",
    ")\n",
    "\n",
    "monthly = billing.to_period(\"M\")\n",
    "print(\"Monthly index:\", monthly.index.tolist())\n",
    "\n",
    "assert isinstance(monthly.index, pd.PeriodIndex)\n",
    "assert str(monthly.index[0]) == \"2025-01\"\n",
    "assert int(monthly.loc[pd.Period(\"2025-02\", freq=\"M\")]) == 320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786a44f",
   "metadata": {},
   "source": [
    "##### Series.to_timestamp(freq=None, how=\"start\")\n",
    "`to_timestamp(...)` converts a PeriodIndex Series back to a DatetimeIndex. It is useful when period-labeled data must rejoin timestamp-based pipelines. You control whether each period maps to its start or end timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "9c06faa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01    300\n",
       "2025-02    320\n",
       "2025-03    310\n",
       "Freq: M, Name: amount, dtype: int64"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ps = pd.Series(\n",
    "    [300, 320, 310],\n",
    "    index=pd.period_range(\"2025-01\", periods=3, freq=\"M\"),\n",
    "    name=\"amount\",\n",
    ")\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "f01a2056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-01    300\n",
       "2025-02-01    320\n",
       "2025-03-01    310\n",
       "Freq: MS, Name: amount, dtype: int64"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.to_timestamp(how=\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45a417",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f0c0e",
   "metadata": {},
   "source": [
    "`series.to_timestamp()` turns period labels back into exact timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5c2f9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136b9e6",
   "metadata": {},
   "source": [
    "- `freq` (frequency or `None`): target timestamp frequency when needed.\n",
    "\n",
    "- `how` (`\"start\"`, `\"end\"`, `\"s\"`, `\"e\"`, default `\"start\"`): choose period boundary timestamp.\n",
    "\n",
    "- `copy` (`bool`, optional): whether to copy data during conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc1593",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36806643",
   "metadata": {},
   "source": [
    "Think of expanding monthly spreadsheet labels into precise boundary dates.\n",
    "\n",
    "- Month label can map to first day or last day.\n",
    "\n",
    "- Values stay unchanged.\n",
    "\n",
    "This restores timestamp compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595de8e",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0baf7f",
   "metadata": {},
   "source": [
    "- Pandas reads each period label and computes its timestamp boundary.\n",
    "\n",
    "- `how` decides start or end boundary.\n",
    "\n",
    "- Index class changes from `PeriodIndex` to `DatetimeIndex` with values preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4987b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464062b",
   "metadata": {},
   "source": [
    "- Start vs end choice can shift temporal alignment in joins/charts.\n",
    "\n",
    "- Converting at incompatible frequencies can confuse granularity.\n",
    "\n",
    "- Downstream logic may require timezone localization after conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa56fb",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78414aa",
   "metadata": {},
   "source": [
    "- Should period map to start or end timestamp for your KPI definition?\n",
    "\n",
    "- Is target frequency consistent with downstream models/charts?\n",
    "\n",
    "- Do you need timezone handling after conversion?\n",
    "\n",
    "- Are joins expecting datetime keys rather than period keys?\n",
    "\n",
    "- Have you documented the boundary convention (`start`/`end`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ea660",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c6f21",
   "metadata": {},
   "source": [
    "Use `to_timestamp` to convert period-based labels back to concrete datetime labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500dc65",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert monthly period KPIs to month-start timestamps so they align with datetime-indexed forecast tables.\n",
    "\n",
    "Scenario: downstream models expect DatetimeIndex keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "6e98a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp index: [Timestamp('2025-01-01 00:00:00'), Timestamp('2025-02-01 00:00:00'), Timestamp('2025-03-01 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "monthly_kpi = pd.Series(\n",
    "    [1.2, 1.3, 1.25],\n",
    "    index=pd.period_range(\"2025-01\", periods=3, freq=\"M\"),\n",
    "    name=\"kpi\",\n",
    ")\n",
    "\n",
    "kpi_ts = monthly_kpi.to_timestamp(how=\"start\")\n",
    "print(\"Timestamp index:\", kpi_ts.index.tolist())\n",
    "\n",
    "assert isinstance(kpi_ts.index, pd.DatetimeIndex)\n",
    "assert kpi_ts.index[0] == pd.Timestamp(\"2025-01-01\")\n",
    "assert float(kpi_ts.loc[pd.Timestamp(\"2025-03-01\")]) == 1.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ec28c",
   "metadata": {},
   "source": [
    "#### Reindexing and alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a1f71",
   "metadata": {},
   "source": [
    "##### Series.reindex(new_index)\n",
    "`reindex(new_index)` conforms a Series to a target index layout. It is useful when you need a standard key set across multiple datasets. Missing labels are introduced as `NaN` unless you provide fill behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "0494ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku_a    10\n",
       "sku_c    30\n",
       "Name: units, dtype: int64"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([10, 30], index=[\"sku_a\", \"sku_c\"], name=\"units\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "518ad02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku_a    10.0\n",
       "sku_b     NaN\n",
       "sku_c    30.0\n",
       "Name: units, dtype: float64"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.reindex([\"sku_a\", \"sku_b\", \"sku_c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3c858",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0e430",
   "metadata": {},
   "source": [
    "`series.reindex(...)` reshapes labels to match a requested index, adding missing rows if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb6c37",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b8f0f",
   "metadata": {},
   "source": [
    "- `index` (array-like or `None`): target index labels/order for the result.\n",
    "\n",
    "- `axis` (`0`/`\"index\"` or `None`): axis selector (Series uses index axis).\n",
    "\n",
    "- `method` (`\"ffill\"`, `\"bfill\"`, `\"nearest\"`, or `None`): fill strategy when reindexing on ordered indexes.\n",
    "\n",
    "- `copy` (`bool`, optional): whether to force a copy behavior.\n",
    "\n",
    "- `level` (int/label or `None`): reindex over a MultiIndex level.\n",
    "\n",
    "- `fill_value` (scalar or `None`): value used for newly introduced labels.\n",
    "\n",
    "- `limit` (`int` or `None`): maximum fill size for fill methods.\n",
    "\n",
    "- `tolerance` (scalar/list-like or `None`): maximum distance for inexact matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c65dd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100a169",
   "metadata": {},
   "source": [
    "Think of forcing a spreadsheet column to follow a master list of row labels.\n",
    "\n",
    "- Known labels keep their values.\n",
    "\n",
    "- Missing labels appear as blanks or defaults.\n",
    "\n",
    "You get a consistent structure across tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721819e9",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad5fd3",
   "metadata": {},
   "source": [
    "- Pandas builds output on the target index you provide.\n",
    "\n",
    "- Existing labels are aligned into new positions.\n",
    "\n",
    "- Missing target labels get `NaN` or `fill_value`/fill-method outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336d5d0",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d06758",
   "metadata": {},
   "source": [
    "- Unexpected extra/missing labels can appear if master index is wrong.\n",
    "\n",
    "- Fill methods require ordered context to be meaningful.\n",
    "\n",
    "- Reindexing large objects repeatedly can be costly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0b810",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd366f8",
   "metadata": {},
   "source": [
    "- Is target index the true business key standard?\n",
    "\n",
    "- Should missing labels remain `NaN` or be default-filled?\n",
    "\n",
    "- Do you need strict ordering guarantees after reindex?\n",
    "\n",
    "- Is index uniqueness validated before reindexing?\n",
    "\n",
    "- Could reindex be pushed earlier to simplify alignment downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd65d3",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4fa02",
   "metadata": {},
   "source": [
    "Use `reindex` to force a Series onto a standard label set and order before comparison or joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949343c5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Standardize product coverage to a master SKU list before feeding a reconciliation report.\n",
    "\n",
    "Scenario: missing SKUs must appear explicitly as zero demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "dbddc273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized demand: {'sku_a': 15, 'sku_b': 0, 'sku_c': 9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "demand = pd.Series([15, 9], index=[\"sku_a\", \"sku_c\"], name=\"demand\")\n",
    "master_skus = [\"sku_a\", \"sku_b\", \"sku_c\"]\n",
    "\n",
    "demand_std = demand.reindex(master_skus, fill_value=0)\n",
    "print(\"Standardized demand:\", demand_std.to_dict())\n",
    "\n",
    "assert list(demand_std.index) == master_skus\n",
    "assert int(demand_std.loc[\"sku_b\"]) == 0\n",
    "assert int(demand_std.loc[\"sku_c\"]) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01049ae",
   "metadata": {},
   "source": [
    "##### Series.align(other)\n",
    "`align(other)` returns two objects aligned to a shared index strategy. It is useful before arithmetic or comparisons where key alignment must be explicit. You can control join behavior and default fill values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "5c8ad43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a    1\n",
       " b    2\n",
       " Name: left, dtype: int64,\n",
       " b    10\n",
       " c    20\n",
       " Name: right, dtype: int64)"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.Series([1, 2], index=[\"a\", \"b\"], name=\"left\")\n",
    "right = pd.Series([10, 20], index=[\"b\", \"c\"], name=\"right\")\n",
    "left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "05e892db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a    1.0\n",
       " b    2.0\n",
       " c    NaN\n",
       " Name: left, dtype: float64,\n",
       " a     NaN\n",
       " b    10.0\n",
       " c    20.0\n",
       " Name: right, dtype: float64)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left.align(right, join=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc44d2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fe2c2",
   "metadata": {},
   "source": [
    "`series.align(other)` gives you two index-aligned Series ready for safe element-wise operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af515d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b3ec2",
   "metadata": {},
   "source": [
    "- `other` (`Series` or compatible object): object to align with.\n",
    "\n",
    "- `join` (`\"outer\"`, `\"inner\"`, `\"left\"`, `\"right\"`; default `\"outer\"`): index join strategy.\n",
    "\n",
    "- `axis` (`0`/`\"index\"` or `None`): axis to align on (Series uses index).\n",
    "\n",
    "- `level` (int/label or `None`): align on a MultiIndex level.\n",
    "\n",
    "- `copy` (`bool`, optional): whether to force copy semantics.\n",
    "\n",
    "- `fill_value` (scalar or `None`): value used to fill missing keys after alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda02843",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda56382",
   "metadata": {},
   "source": [
    "Think of preparing two spreadsheet columns so they use the same row labels before any formula.\n",
    "\n",
    "- Labels are matched first.\n",
    "\n",
    "- Missing sides can be filled.\n",
    "\n",
    "Then arithmetic becomes reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315fc96",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c09bb",
   "metadata": {},
   "source": [
    "- Pandas computes the target index based on `join`.\n",
    "\n",
    "- Both objects are reindexed to that shared target.\n",
    "\n",
    "- Missing positions can be filled with `fill_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe1ad2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709cc10",
   "metadata": {},
   "source": [
    "- Outer joins can grow index size unexpectedly.\n",
    "\n",
    "- Default missing values may propagate into later metrics if not handled.\n",
    "\n",
    "- Misunderstanding join type can silently change analysis scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d910a0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b004e21",
   "metadata": {},
   "source": [
    "- Should alignment keep only shared keys (`inner`) or all keys (`outer`)?\n",
    "\n",
    "- Are missing aligned values acceptable or should they be filled?\n",
    "\n",
    "- Is index uniqueness guaranteed on both sides?\n",
    "\n",
    "- Have you checked that alignment direction matches business semantics?\n",
    "\n",
    "- Is explicit `align` clearer than implicit arithmetic alignment in this step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9370f0e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2400a",
   "metadata": {},
   "source": [
    "Use `align` to make key matching explicit and prevent accidental misalignment before math or comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23cf1e5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Align forecast and actual demand series before calculating per-SKU error.\n",
    "\n",
    "Scenario: each side has partial SKU coverage and must be reconciled first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "20fec678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast aligned: {'sku_a': 100.0, 'sku_b': 80.0, 'sku_c': 0.0}\n",
      "Actual aligned: {'sku_a': 0.0, 'sku_b': 95.0, 'sku_c': 70.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "forecast = pd.Series([100, 80], index=[\"sku_a\", \"sku_b\"], name=\"forecast\")\n",
    "actual = pd.Series([95, 70], index=[\"sku_b\", \"sku_c\"], name=\"actual\")\n",
    "\n",
    "f_aligned, a_aligned = forecast.align(actual, join=\"outer\", fill_value=0)\n",
    "print(\"Forecast aligned:\", f_aligned.to_dict())\n",
    "print(\"Actual aligned:\", a_aligned.to_dict())\n",
    "\n",
    "assert list(f_aligned.index) == [\"sku_a\", \"sku_b\", \"sku_c\"]\n",
    "assert int(a_aligned.loc[\"sku_a\"]) == 0\n",
    "assert int(f_aligned.loc[\"sku_c\"]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5e027",
   "metadata": {},
   "source": [
    "##### Series.update(other)\n",
    "`update(other)` modifies the current Series in place using non-missing values from `other`, aligned by index. It is useful for patching corrected records without rebuilding the full Series. The method returns `None` and mutates the original object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "3a7bcf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sku1    50\n",
       " sku2    40\n",
       " sku3    30\n",
       " Name: stock, dtype: int64,\n",
       " sku2    45.0\n",
       " sku3     NaN\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "series = pd.Series([50, 40, 30], index=[\"sku1\", \"sku2\", \"sku3\"], name=\"stock\")\n",
    "patch = pd.Series([45, np.nan], index=[\"sku2\", \"sku3\"])\n",
    "series, patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "7dc137ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku1    50\n",
       "sku2    45\n",
       "sku3    30\n",
       "Name: stock, dtype: int64"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.update(patch)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1349f64",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b06188",
   "metadata": {},
   "source": [
    "`series.update(other)` overwrites matching labels with non-null values from the patch Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad1bf0",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef33b6",
   "metadata": {},
   "source": [
    "- `other` (`Series`, sequence, or mapping): source of replacement values; aligned by index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36af659",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f6993",
   "metadata": {},
   "source": [
    "Think of applying a correction sheet to an existing spreadsheet column.\n",
    "\n",
    "- Matching rows are updated.\n",
    "\n",
    "- Blank corrections are ignored.\n",
    "\n",
    "The original column is edited directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b40ad",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d00279",
   "metadata": {},
   "source": [
    "- Pandas aligns `other` to current index labels.\n",
    "\n",
    "- For each matching label, non-missing values replace current values.\n",
    "\n",
    "- Missing values in `other` do not overwrite existing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c0b9b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebeaca5",
   "metadata": {},
   "source": [
    "- In-place mutation can hide lineage if not documented.\n",
    "\n",
    "- No return object means chained usage can be confusing.\n",
    "\n",
    "- Unexpected index overlaps may overwrite more than intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea5a17",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a5d87",
   "metadata": {},
   "source": [
    "- Do you explicitly want in-place mutation here?\n",
    "\n",
    "- Is patch data validated before update?\n",
    "\n",
    "- Should missing patch values be ignored or explicitly set?\n",
    "\n",
    "- Are index labels unique and trusted?\n",
    "\n",
    "- Do you need a snapshot copy before applying updates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649bcf9",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc27e09",
   "metadata": {},
   "source": [
    "Use `update` for targeted in-place patching of labeled values, especially for corrected records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61c22a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Apply audited stock corrections from QA onto the latest inventory Series.\n",
    "\n",
    "Scenario: only corrected SKUs should change; missing corrections must not overwrite valid stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "f1c0610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched inventory: {'sku1': 50, 'sku2': 45, 'sku3': 30}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "inventory = pd.Series([50, 40, 30], index=[\"sku1\", \"sku2\", \"sku3\"], name=\"stock\")\n",
    "qa_patch = pd.Series([45, np.nan], index=[\"sku2\", \"sku3\"])\n",
    "\n",
    "inventory.update(qa_patch)\n",
    "print(\"Patched inventory:\", inventory.to_dict())\n",
    "\n",
    "assert int(inventory.loc[\"sku2\"]) == 45\n",
    "assert int(inventory.loc[\"sku3\"]) == 30\n",
    "assert int(inventory.loc[\"sku1\"]) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd41fac",
   "metadata": {},
   "source": [
    "##### Series.combine_first(other)\n",
    "`combine_first(other)` fills missing values in the current Series using aligned values from `other`. It is useful when you have a primary source plus a fallback source. The result includes the union of indexes from both objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "eafb860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a    1.0\n",
       " b    NaN\n",
       " c    3.0\n",
       " Name: score, dtype: float64,\n",
       " a    0.5\n",
       " b    2.0\n",
       " d    2.5\n",
       " Name: score_fb, dtype: float64)"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "primary = pd.Series([1.0, None, 3.0], index=[\"a\", \"b\", \"c\"], name=\"score\")\n",
    "fallback = pd.Series([0.5, 2.0, 2.5], index=[\"a\", \"b\", \"d\"], name=\"score_fb\")\n",
    "primary, fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "2228f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "d    2.5\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary.combine_first(fallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5b3c7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9442c",
   "metadata": {},
   "source": [
    "`series.combine_first(other)` keeps your current values and only fills gaps from another Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e4c6a",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59144d5",
   "metadata": {},
   "source": [
    "- `other` (`Series`-like): fallback source used where current Series has missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e9e9a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8f250",
   "metadata": {},
   "source": [
    "Think of two spreadsheet columns: preferred source and backup source.\n",
    "\n",
    "- Preferred values stay when present.\n",
    "\n",
    "- Backup fills only blanks.\n",
    "\n",
    "You build one consolidated column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68780898",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5305f",
   "metadata": {},
   "source": [
    "- Pandas aligns both Series on union index labels.\n",
    "\n",
    "- At each label, it takes current value if not missing.\n",
    "\n",
    "- Otherwise it takes value from `other` if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b667de0",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b04c3",
   "metadata": {},
   "source": [
    "- Can introduce extra labels from fallback source unexpectedly.\n",
    "\n",
    "- Missing-value definitions (`NaN`, `None`, `pd.NA`) must be understood.\n",
    "\n",
    "- Does not resolve conflicts when both sides are non-missing (keeps left side)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c9a61",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757384e4",
   "metadata": {},
   "source": [
    "- Is left Series truly your priority source?\n",
    "\n",
    "- Do you want union index behavior or only existing left keys?\n",
    "\n",
    "- Should conflicting non-missing values ever be compared before keeping left?\n",
    "\n",
    "- Are fallback values quality-checked?\n",
    "\n",
    "- Are added labels acceptable for downstream joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbddd1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50b31e",
   "metadata": {},
   "source": [
    "Use `combine_first` to fill gaps from a fallback Series while preserving primary values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eeac6b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Merge primary sensor readings with backup sensor feed to maximize coverage.\n",
    "\n",
    "Scenario: keep primary readings when present; use backup only for missing timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "3ccbec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged readings: {'t1': 10.0, 't2': 11.0, 't3': 12.0, 't4': 10.8}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "primary = pd.Series([10.0, None, 12.0], index=[\"t1\", \"t2\", \"t3\"], name=\"reading\")\n",
    "backup = pd.Series([9.5, 11.0, 10.8], index=[\"t1\", \"t2\", \"t4\"], name=\"backup\")\n",
    "\n",
    "merged = primary.combine_first(backup)\n",
    "print(\"Merged readings:\", merged.to_dict())\n",
    "\n",
    "assert float(merged.loc[\"t2\"]) == 11.0\n",
    "assert float(merged.loc[\"t1\"]) == 10.0\n",
    "assert float(merged.loc[\"t4\"]) == 10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ccf3a",
   "metadata": {},
   "source": [
    "##### Series.rename(new_name)\n",
    "`rename(...)` can rename index labels or set the Series name, depending on what you pass. It is useful for consistent naming before merges, exports, or plotting. The default behavior returns a new object unless `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "55dc06dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "north    100\n",
       "south    120\n",
       "Name: rev_raw, dtype: int64"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([100, 120], index=[\"north\", \"south\"], name=\"rev_raw\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "5a462935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "north    100\n",
       "south    120\n",
       "Name: revenue_usd, dtype: int64"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.rename(\"revenue_usd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126288b0",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dff6de",
   "metadata": {},
   "source": [
    "`series.rename(...)` lets you rename the series itself or relabel index entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b7508",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54317373",
   "metadata": {},
   "source": [
    "- `index` (mapping/function/scalar or `None`): index relabeler, or scalar Series name when passed positionally.\n",
    "\n",
    "- `axis` (`0`/`\"index\"` or `None`): axis selector for API consistency.\n",
    "\n",
    "- `copy` (`bool`, optional): whether to force copy behavior.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify current Series directly.\n",
    "\n",
    "- `level` (int/label or `None`): target MultiIndex level for relabeling.\n",
    "\n",
    "- `errors` (`\"ignore\"` or `\"raise\"`, default `\"ignore\"`): behavior for missing labels when mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fba6a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd35da",
   "metadata": {},
   "source": [
    "Think of cleaning spreadsheet headers and row labels before sharing.\n",
    "\n",
    "- You can rename the column title.\n",
    "\n",
    "- You can also rename row keys.\n",
    "\n",
    "Names become consistent for downstream work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713a24b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba0445e",
   "metadata": {},
   "source": [
    "- Pandas interprets the renamer (name scalar vs index mapper).\n",
    "\n",
    "- It applies relabeling to the requested target without changing values.\n",
    "\n",
    "- Unless `inplace=True`, it returns a renamed copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912239a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132a6b7",
   "metadata": {},
   "source": [
    "- Ambiguity between renaming Series name and index labels can confuse readers.\n",
    "\n",
    "- In-place rename can obscure original naming lineage.\n",
    "\n",
    "- Missing mapper keys may be silently ignored with default `errors`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebd0b2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700a3fa",
   "metadata": {},
   "source": [
    "- Are you renaming the Series name or index labels in this step?\n",
    "\n",
    "- Should unknown mapper keys raise errors?\n",
    "\n",
    "- Is `inplace` mutation acceptable for pipeline traceability?\n",
    "\n",
    "- Are downstream joins dependent on exact names?\n",
    "\n",
    "- Should naming standards be centralized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6712504",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d1efd",
   "metadata": {},
   "source": [
    "Use `rename` to standardize names and labels explicitly before downstream integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239c5bd",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Standardize metric naming before concatenating multiple KPI Series into a report table.\n",
    "\n",
    "Scenario: same index labels, but output Series name must match reporting schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "bb124111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed series name: auc_score\n",
      "Values: {'model_a': 0.91, 'model_b': 0.87}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc_raw\")\n",
    "kpi_named = kpi.rename(\"auc_score\")\n",
    "print(\"Renamed series name:\", kpi_named.name)\n",
    "print(\"Values:\", kpi_named.to_dict())\n",
    "\n",
    "assert kpi_named.name == \"auc_score\"\n",
    "assert kpi.name == \"auc_raw\"\n",
    "assert kpi_named.index.equals(kpi.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b20f76",
   "metadata": {},
   "source": [
    "##### Series.rename_axis(new_name)\n",
    "`rename_axis(new_name)` sets or changes the index axis name metadata. It is useful for cleaner exports and reset operations where index name becomes a column name. Values are unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "3c696ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    4\n",
       "u2    5\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([4, 5], index=[\"u1\", \"u2\"], name=\"score\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "35c08d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "u1    4\n",
       "u2    5\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.rename_axis(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b014ae0",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942b3e8",
   "metadata": {},
   "source": [
    "`series.rename_axis(...)` names the index axis (the label of label column), not the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb54a6",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a82439",
   "metadata": {},
   "source": [
    "- `mapper` (label or mapper, optional): new axis name/value mapping when used directly.\n",
    "\n",
    "- `index` (label or mapper, optional): explicit index-axis renaming argument.\n",
    "\n",
    "- `axis` (`0`/`\"index\"`, default `0`): axis selector.\n",
    "\n",
    "- `copy` (`bool`, optional): whether to force copy behavior.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): mutate current object instead of returning a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090c9a8",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cb0b6",
   "metadata": {},
   "source": [
    "Think of naming the row-key column in a spreadsheet export.\n",
    "\n",
    "- Data values stay the same.\n",
    "\n",
    "- Only the index title changes.\n",
    "\n",
    "This improves readability and downstream joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248217ab",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fbb20",
   "metadata": {},
   "source": [
    "- Pandas updates index name metadata on the selected axis.\n",
    "\n",
    "- Index labels and values themselves are not changed.\n",
    "\n",
    "- Returned object or in-place mutation depends on `inplace`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e92b6",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf788ac",
   "metadata": {},
   "source": [
    "- Easy to confuse with `rename`, which can change labels.\n",
    "\n",
    "- Metadata-only changes may be overlooked in quick checks.\n",
    "\n",
    "- Inconsistent axis names can break conventions in exported tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c3b90",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90488e0b",
   "metadata": {},
   "source": [
    "- Do you need to rename labels (`rename`) or axis name (`rename_axis`)?\n",
    "\n",
    "- Should index name follow a team naming convention?\n",
    "\n",
    "- Will `reset_index` later depend on this axis name?\n",
    "\n",
    "- Is inplace mutation desirable here?\n",
    "\n",
    "- Are consumers expecting a specific index metadata name?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848298bd",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcc3dd",
   "metadata": {},
   "source": [
    "Use `rename_axis` to set a clear index-name metadata label without touching data values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05343b02",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Name the index before `reset_index` so exported tables get meaningful key column headers.\n",
    "\n",
    "Scenario: row keys represent customer IDs and should carry that label into output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "ababf9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index name: user_id\n",
      "Series: {'u1': 4, 'u2': 5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.Series([4, 5], index=[\"u1\", \"u2\"], name=\"score\")\n",
    "score_named_axis = score.rename_axis(\"user_id\")\n",
    "print(\"Index name:\", score_named_axis.index.name)\n",
    "print(\"Series:\", score_named_axis.to_dict())\n",
    "\n",
    "assert score_named_axis.index.name == \"user_id\"\n",
    "assert int(score_named_axis.loc[\"u1\"]) == 4\n",
    "assert score.index.name is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35964883",
   "metadata": {},
   "source": [
    "##### Series.reset_index()\n",
    "`reset_index()` converts index labels into regular columns. For Series, it usually returns a DataFrame unless `drop=True`. It is useful when you need tabular output for merges, exports, or SQL-style operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "062b07a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_a    0.91\n",
       "model_b    0.87\n",
       "Name: auc, dtype: float64"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "b6b84ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_a</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_b</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  auc_score\n",
       "0  model_a       0.91\n",
       "1  model_b       0.87"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.reset_index(name=\"auc_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b87f9",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193eeee8",
   "metadata": {},
   "source": [
    "`series.reset_index()` moves index labels into columns and gives you a flat table-like structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e4b95",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb2226",
   "metadata": {},
   "source": [
    "- `level` (label/int or `None`): which index level(s) to reset.\n",
    "\n",
    "- `drop` (`bool`, default `False`): drop index instead of converting it to columns.\n",
    "\n",
    "- `name` (label, optional): column name for Series values in result DataFrame.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify object in place when supported.\n",
    "\n",
    "- `allow_duplicates` (`bool`, default `False`): allow duplicate column labels in result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28463c4c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7831d21",
   "metadata": {},
   "source": [
    "Think of flattening spreadsheet row labels into a normal data column.\n",
    "\n",
    "- Row keys become visible data.\n",
    "\n",
    "- Table is easier to join/export.\n",
    "\n",
    "Index stops being hidden structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0035a73",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b65c51",
   "metadata": {},
   "source": [
    "- Pandas takes index labels and turns them into one or more columns.\n",
    "\n",
    "- Series values become another column (with `name` if provided).\n",
    "\n",
    "- Result is DataFrame unless you choose `drop=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fa7d8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69874b",
   "metadata": {},
   "source": [
    "- Can change object type (Series to DataFrame), affecting downstream code.\n",
    "\n",
    "- Column naming collisions may occur without planning.\n",
    "\n",
    "- Dropping index may lose key information if not intentional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f3969",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f51532",
   "metadata": {},
   "source": [
    "- Do downstream steps expect Series or DataFrame after this point?\n",
    "\n",
    "- Should index labels be preserved as columns or dropped?\n",
    "\n",
    "- Is value column name explicit and clear?\n",
    "\n",
    "- Could column-name collisions happen in merge targets?\n",
    "\n",
    "- Is index name set properly before reset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160b980",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ab78c",
   "metadata": {},
   "source": [
    "Use `reset_index` when index labels need to become regular columns for table-based workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d414b0",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert model-metric Series into a tidy DataFrame before writing to a reporting table.\n",
    "\n",
    "Scenario: model ID must be a visible column for SQL ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "0f43b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_id  auc_score\n",
      "0  model_a       0.91\n",
      "1  model_b       0.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "auc = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc\")\n",
    "auc = auc.rename_axis(\"model_id\")\n",
    "auc_df = auc.reset_index(name=\"auc_score\")\n",
    "print(auc_df)\n",
    "\n",
    "assert list(auc_df.columns) == [\"model_id\", \"auc_score\"]\n",
    "assert auc_df.shape == (2, 2)\n",
    "assert float(auc_df.loc[auc_df[\"model_id\"] == \"model_b\", \"auc_score\"].iloc[0]) == 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ec3a7",
   "metadata": {},
   "source": [
    "##### Series.set_axis(labels)\n",
    "`set_axis(labels)` replaces the index labels with a new label sequence of the same length. It is useful when keys were loaded incorrectly and need deterministic replacement. Values stay in the same order; only labels change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "f8ed7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([10, 20, 30], index=[\"a\", \"b\", \"c\"], name=\"score\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "52251eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id1    10\n",
       "id2    20\n",
       "id3    30\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.set_axis([\"id1\", \"id2\", \"id3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4390cf8",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d156e9",
   "metadata": {},
   "source": [
    "`series.set_axis(labels)` swaps current index labels with a new label list, position by position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707de099",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f509a6",
   "metadata": {},
   "source": [
    "- `labels` (list-like): new axis labels; length must match current axis length.\n",
    "\n",
    "- `axis` (`0`/`\"index\"`, default `0`): axis selector (Series index axis).\n",
    "\n",
    "- `copy` (`bool`, optional): whether to force copy semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49201f7e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be48b65",
   "metadata": {},
   "source": [
    "Think of replacing row IDs in a spreadsheet while keeping row values in place.\n",
    "\n",
    "- Row 1 value stays row 1 value.\n",
    "\n",
    "- Only the label text changes.\n",
    "\n",
    "This is positional relabeling, not data sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85a383",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a6b9b",
   "metadata": {},
   "source": [
    "- Pandas checks that new label count matches axis length.\n",
    "\n",
    "- It assigns new labels by position to the existing values.\n",
    "\n",
    "- Data order remains unchanged; only axis metadata changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302df58d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad701741",
   "metadata": {},
   "source": [
    "- Wrong label order can silently misidentify rows.\n",
    "\n",
    "- Length mismatch raises an error.\n",
    "\n",
    "- Can hide original key meaning if remapping is not documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb999f59",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff31710",
   "metadata": {},
   "source": [
    "- Are new labels in exactly the intended positional order?\n",
    "\n",
    "- Should you map labels (`rename`) instead of positional replace (`set_axis`)?\n",
    "\n",
    "- Do you need to preserve original labels for audit?\n",
    "\n",
    "- Is label length guaranteed to match Series length?\n",
    "\n",
    "- Could downstream merges break if IDs are replaced here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a160c824",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a402fe",
   "metadata": {},
   "source": [
    "Use `set_axis` for full positional relabeling when you already trust value order and need new keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f8672",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Replace temporary row IDs with official customer IDs after a validated ordering step.\n",
    "\n",
    "Scenario: values are correct, but labels must be swapped to production IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "9964a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official labels: {'cust_101': 10, 'cust_102': 20, 'cust_103': 30}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.Series([10, 20, 30], index=[\"tmp1\", \"tmp2\", \"tmp3\"], name=\"score\")\n",
    "official = [\"cust_101\", \"cust_102\", \"cust_103\"]\n",
    "\n",
    "score_official = score.set_axis(official)\n",
    "print(\"Official labels:\", score_official.to_dict())\n",
    "\n",
    "assert list(score_official.index) == official\n",
    "assert int(score_official.loc[\"cust_102\"]) == 20\n",
    "assert list(score.index) == [\"tmp1\", \"tmp2\", \"tmp3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d54124",
   "metadata": {},
   "source": [
    "#### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3ce9b",
   "metadata": {},
   "source": [
    "##### Series.groupby(by=None, level=None, ...)\n",
    "`groupby(...)` splits a Series into groups based on keys, then lets you aggregate or transform each group. It is a core operation for segment-level analytics (region, channel, category). Grouping keeps label-aware behavior, so grouped outputs remain interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "33ce3ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ord1    100\n",
       " ord2    120\n",
       " ord3     80\n",
       " ord4     90\n",
       " Name: sales, dtype: int64,\n",
       " ord1    online\n",
       " ord2    online\n",
       " ord3     store\n",
       " ord4     store\n",
       " Name: segment, dtype: str)"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales = pd.Series([100, 120, 80, 90], index=[\"ord1\", \"ord2\", \"ord3\", \"ord4\"], name=\"sales\")\n",
    "segment = pd.Series([\"online\", \"online\", \"store\", \"store\"], index=sales.index, name=\"segment\")\n",
    "sales, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "5d49ddb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment\n",
       "online    220\n",
       "store     170\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.groupby(segment).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc81ff",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1b66e",
   "metadata": {},
   "source": [
    "`series.groupby(keys)` puts rows into labeled buckets, then you run stats per bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49595d46",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95446cba",
   "metadata": {},
   "source": [
    "- `by` (mapping, array-like, function, label, or `None`): grouping keys that assign each row to a group.\n",
    "\n",
    "- `level` (int/label or `None`): group by a specific MultiIndex level.\n",
    "\n",
    "- `as_index` (`bool`, default `True`): whether grouped keys become index in output (relevant in grouped results).\n",
    "\n",
    "- `sort` (`bool`, default `True`): sort group keys in the result.\n",
    "\n",
    "- `group_keys` (`bool`, default `True`): include group labels when applying certain operations.\n",
    "\n",
    "- `observed` (`bool`, default `True`): for categorical groupers, include only observed categories.\n",
    "\n",
    "- `dropna` (`bool`, default `True`): exclude or include `NaN` group keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443e642",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c832d",
   "metadata": {},
   "source": [
    "Think of a spreadsheet pivot where rows are first sorted into category buckets.\n",
    "\n",
    "- Each bucket collects matching rows.\n",
    "\n",
    "- You compute one metric per bucket.\n",
    "\n",
    "This turns row-level data into segment summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7471a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12b4bd",
   "metadata": {},
   "source": [
    "- Pandas maps each row label/value to a group key from `by`/`level`.\n",
    "\n",
    "- It builds internal groups of row positions.\n",
    "\n",
    "- Aggregations (`sum`, `mean`, etc.) run per group and return grouped output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4e6fb",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77632147",
   "metadata": {},
   "source": [
    "- Misaligned grouping keys can assign rows to wrong groups.\n",
    "\n",
    "- Default sorting may change expected key order.\n",
    "\n",
    "- Missing group keys may be dropped unless `dropna=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a875df1",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95601c",
   "metadata": {},
   "source": [
    "- Are grouping keys aligned exactly to Series index labels?\n",
    "\n",
    "- Should groups with missing keys be kept or dropped?\n",
    "\n",
    "- Is sorted group order desired for downstream logic?\n",
    "\n",
    "- Do you need aggregation, transform, or filter semantics?\n",
    "\n",
    "- Are segment definitions versioned and auditable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f220c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33c807",
   "metadata": {},
   "source": [
    "Use `groupby` to bucket Series rows by keys and compute per-group metrics in a controlled way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2000a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Aggregate order revenue by sales channel before creating a channel performance dashboard.\n",
    "\n",
    "Scenario: each order row has a channel label, and totals must be channel-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "e2bd3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue by channel: {'online': 320, 'store': 330}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.Series([200, 150, 120, 180], index=[\"o1\", \"o2\", \"o3\", \"o4\"], name=\"revenue\")\n",
    "channel = pd.Series([\"online\", \"store\", \"online\", \"store\"], index=revenue.index, name=\"channel\")\n",
    "\n",
    "channel_totals = revenue.groupby(channel).sum()\n",
    "print(\"Revenue by channel:\", channel_totals.to_dict())\n",
    "\n",
    "assert int(channel_totals.loc[\"online\"]) == 320\n",
    "assert int(channel_totals.loc[\"store\"]) == 330\n",
    "assert set(channel_totals.index.tolist()) == {\"online\", \"store\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db6a73",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2ba9d",
   "metadata": {},
   "source": [
    "##### Series.duplicated(keep=\"first\")\n",
    "`duplicated(...)` returns a boolean mask marking repeated values in a Series. It is used for QA checks and deduplication planning before record selection. You control which occurrence is considered the original via `keep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "5bf4d355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    u1\n",
       "r2    u2\n",
       "r3    u1\n",
       "r4    u3\n",
       "r5    u2\n",
       "Name: user_id, dtype: str"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = pd.Series([\"u1\", \"u2\", \"u1\", \"u3\", \"u2\"], index=[\"r1\", \"r2\", \"r3\", \"r4\", \"r5\"], name=\"user_id\")\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "99e46261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    False\n",
       "r2    False\n",
       "r3     True\n",
       "r4    False\n",
       "r5     True\n",
       "Name: user_id, dtype: bool"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.duplicated(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d7984",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a359a8",
   "metadata": {},
   "source": [
    "`series.duplicated()` tells you which rows are repeats of values seen earlier (or later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec13b4",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b07d7",
   "metadata": {},
   "source": [
    "- `keep` (`\"first\"`, `\"last\"`, or `False`; default `\"first\"`): choose which occurrence is not marked as duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13994613",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd941e",
   "metadata": {},
   "source": [
    "Think of scanning a spreadsheet column for repeated IDs.\n",
    "\n",
    "- First time you see an ID can be kept as original.\n",
    "\n",
    "- Later repeats are flagged.\n",
    "\n",
    "You get a precise duplicate mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5fac7",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce048800",
   "metadata": {},
   "source": [
    "- Pandas tracks values already seen while scanning rows.\n",
    "\n",
    "- It marks rows as `True` when value repetition matches `keep` rules.\n",
    "\n",
    "- Output is a boolean Series aligned to original index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0ab2e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ab1af",
   "metadata": {},
   "source": [
    "- Duplicate logic is value-based; index labels are not considered.\n",
    "\n",
    "- `keep` choice changes which rows are flagged.\n",
    "\n",
    "- Missing values can also be treated as duplicates depending on context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e3f5",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a1285",
   "metadata": {},
   "source": [
    "- Are you deduplicating by value only, or do you need key combinations (DataFrame case)?\n",
    "\n",
    "- Should first, last, or all duplicates be flagged?\n",
    "\n",
    "- Do missing values require special handling?\n",
    "\n",
    "- Are flagged rows reviewed before dropping?\n",
    "\n",
    "- Will index labels be needed to trace duplicate sources?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675022b9",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd915dc1",
   "metadata": {},
   "source": [
    "Use `duplicated` to build a boolean map of repeated values before deciding what to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52de9a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Flag repeated customer IDs in a signup stream before counting unique users.\n",
    "\n",
    "Scenario: keep the first occurrence and mark later repeats for audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "79ed69f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate mask: {'e1': False, 'e2': False, 'e3': True, 'e4': False, 'e5': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signup_user = pd.Series([\"u1\", \"u2\", \"u1\", \"u3\", \"u2\"], index=[\"e1\", \"e2\", \"e3\", \"e4\", \"e5\"], name=\"user_id\")\n",
    "dup_mask = signup_user.duplicated(keep=\"first\")\n",
    "print(\"Duplicate mask:\", dup_mask.to_dict())\n",
    "\n",
    "assert bool(dup_mask.loc[\"e3\"]) is True\n",
    "assert bool(dup_mask.loc[\"e2\"]) is False\n",
    "assert int(dup_mask.sum()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bedea",
   "metadata": {},
   "source": [
    "##### Series.drop_duplicates()\n",
    "`drop_duplicates()` removes repeated values and keeps selected occurrences based on `keep`. It is the direct cleaning step after identifying duplicates. The returned Series preserves original index labels unless you request index reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "c0517348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    u1\n",
       "r2    u2\n",
       "r3    u1\n",
       "r4    u3\n",
       "r5    u2\n",
       "Name: user_id, dtype: str"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = pd.Series([\"u1\", \"u2\", \"u1\", \"u3\", \"u2\"], index=[\"r1\", \"r2\", \"r3\", \"r4\", \"r5\"], name=\"user_id\")\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "08c4d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    u1\n",
       "r2    u2\n",
       "r4    u3\n",
       "Name: user_id, dtype: str"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168aab47",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676040e8",
   "metadata": {},
   "source": [
    "`series.drop_duplicates()` returns one occurrence per value according to your keep rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77777d9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c01cf2",
   "metadata": {},
   "source": [
    "- `keep` (`\"first\"`, `\"last\"`, or `False`; default `\"first\"`): choose which duplicates to retain.\n",
    "\n",
    "- `inplace` (`bool`, default `False`): modify current Series directly instead of returning a new one.\n",
    "\n",
    "- `ignore_index` (`bool`, default `False`): reset result index to `0..n-1` after dropping duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd200831",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4aebb9",
   "metadata": {},
   "source": [
    "Think of cleaning a spreadsheet column so each ID appears once.\n",
    "\n",
    "- You choose whether first or last appearance survives.\n",
    "\n",
    "- The rest are removed.\n",
    "\n",
    "You end up with unique values list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6d95e",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f293485",
   "metadata": {},
   "source": [
    "- Pandas evaluates duplicate status using value comparisons.\n",
    "\n",
    "- Rows marked for removal by `keep` are excluded.\n",
    "\n",
    "- Remaining rows are returned with original or reset index based on `ignore_index`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6c8d2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07bdd2f",
   "metadata": {},
   "source": [
    "- Value-only dedup may be insufficient when business uniqueness uses multiple fields.\n",
    "\n",
    "- `keep=False` can drop all repeated values, not just extras.\n",
    "\n",
    "- In-place mutation can make debugging harder if not tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c3e39",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6bad3",
   "metadata": {},
   "source": [
    "- Should first or last occurrence be retained for business rules?\n",
    "\n",
    "- Do you need to preserve original index labels after deduplication?\n",
    "\n",
    "- Is removing all repeats (`keep=False`) too aggressive?\n",
    "\n",
    "- Should duplicate rows be stored separately before dropping?\n",
    "\n",
    "- Is this Series enough, or do you need DataFrame-level dedup keys?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf230df",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83335c3c",
   "metadata": {},
   "source": [
    "Use `drop_duplicates` to keep one chosen occurrence of each value and remove repeats cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba943f4b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create a unique customer ID list from event logs before joining with CRM attributes.\n",
    "\n",
    "Scenario: keep first-seen IDs while preserving event-label traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "a6b4c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: {'ev1': 'u1', 'ev2': 'u2', 'ev4': 'u3'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "event_user = pd.Series([\"u1\", \"u2\", \"u1\", \"u3\", \"u2\"], index=[\"ev1\", \"ev2\", \"ev3\", \"ev4\", \"ev5\"], name=\"user_id\")\n",
    "unique_users = event_user.drop_duplicates(keep=\"first\")\n",
    "print(\"Unique users:\", unique_users.to_dict())\n",
    "\n",
    "assert list(unique_users.index) == [\"ev1\", \"ev2\", \"ev4\"]\n",
    "assert unique_users.loc[\"ev1\"] == \"u1\"\n",
    "assert len(unique_users) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34225a62",
   "metadata": {},
   "source": [
    "#### Conversion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16e9d7",
   "metadata": {},
   "source": [
    "##### Series.to_list()\n",
    "`to_list()` converts Series values into a plain Python list in index order. It is useful when a downstream API expects native Python containers. Only values are exported; index labels are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "1cacafc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    3\n",
       "b    1\n",
       "c    4\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([3, 1, 4], index=[\"a\", \"b\", \"c\"], name=\"score\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "8fda24d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4]"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567fa34",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa65471",
   "metadata": {},
   "source": [
    "`series.to_list()` returns just the values as a Python list, keeping their current order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0dfdc",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3d027",
   "metadata": {},
   "source": [
    "- `(none)`: `to_list()` takes no arguments and returns a Python `list` of Series values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a09a0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fe2df",
   "metadata": {},
   "source": [
    "Think of copying one spreadsheet column values into a simple checklist.\n",
    "\n",
    "- Values are kept in row order.\n",
    "\n",
    "- Row labels are dropped.\n",
    "\n",
    "You get a plain Python list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa73b3",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba254e35",
   "metadata": {},
   "source": [
    "- Pandas iterates over Series values in index order.\n",
    "\n",
    "- It materializes them into a native Python `list`.\n",
    "\n",
    "- Index metadata is not transferred to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56d15",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18be59",
   "metadata": {},
   "source": [
    "- Index labels are lost, so traceability can decrease.\n",
    "\n",
    "- Large Series conversion can increase memory usage.\n",
    "\n",
    "- Mixed dtypes remain mixed Python objects in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377bec2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa321c76",
   "metadata": {},
   "source": [
    "- Do you still need index labels after conversion?\n",
    "\n",
    "- Is value order guaranteed before calling `to_list()`?\n",
    "\n",
    "- Could array/Series types be better for performance?\n",
    "\n",
    "- Is list output required by the target API?\n",
    "\n",
    "- Are values validated before exporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05969e75",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b30be",
   "metadata": {},
   "source": [
    "Use `to_list()` when you need a lightweight Python list of values and no index context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f71cec",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Send a ranked recommendation score list to a service that accepts JSON arrays.\n",
    "\n",
    "Scenario: service needs ordered values only, not labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "b8827e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload list: [0.9, 0.7, 0.6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rec_score = pd.Series([0.9, 0.7, 0.6], index=[\"item1\", \"item2\", \"item3\"], name=\"score\")\n",
    "payload_scores = rec_score.to_list()\n",
    "print(\"Payload list:\", payload_scores)\n",
    "\n",
    "assert payload_scores == [0.9, 0.7, 0.6]\n",
    "assert isinstance(payload_scores, list)\n",
    "assert len(payload_scores) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8fc8d",
   "metadata": {},
   "source": [
    "##### Series.to_dict()\n",
    "`to_dict()` converts a Series into a dictionary mapping index labels to values. It is useful for quick lookups and config-style payloads. This conversion keeps label-to-value relationships explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "785b3e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    10\n",
       "y    20\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([10, 20], index=[\"x\", \"y\"], name=\"value\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "5761bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 10, 'y': 20}"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55317da3",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c95383",
   "metadata": {},
   "source": [
    "`series.to_dict()` gives you `{index_label: value}` pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a7cda",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c41fa",
   "metadata": {},
   "source": [
    "- `into` (mapping class/instance, default `dict`): target mapping type for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73024848",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6c9bb",
   "metadata": {},
   "source": [
    "Think of turning a labeled spreadsheet column into a key-value table.\n",
    "\n",
    "- Row labels become keys.\n",
    "\n",
    "- Cell contents become values.\n",
    "\n",
    "Great for fast lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1eca1d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b8118",
   "metadata": {},
   "source": [
    "- Pandas iterates through index/value pairs.\n",
    "\n",
    "- It inserts each pair into the chosen mapping type.\n",
    "\n",
    "- Output preserves label-value association clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409f937",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a9d9c",
   "metadata": {},
   "source": [
    "- Duplicate index labels overwrite earlier keys in plain dict output.\n",
    "\n",
    "- Type conversion to Python objects may lose pandas-specific metadata.\n",
    "\n",
    "- Very large dicts can consume significant memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789418de",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ff110",
   "metadata": {},
   "source": [
    "- Is index uniqueness guaranteed before conversion?\n",
    "\n",
    "- Do you need a custom mapping type via `into`?\n",
    "\n",
    "- Are keys expected to be strings in downstream systems?\n",
    "\n",
    "- Is dictionary size manageable for the target context?\n",
    "\n",
    "- Should missing values be cleaned before export?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d532c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f762e99",
   "metadata": {},
   "source": [
    "Use `to_dict()` for explicit label-to-value export when key-based access is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3dc976",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build a threshold lookup table keyed by metric name for rule evaluation.\n",
    "\n",
    "Scenario: each metric label must map directly to its threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "5a4cefd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold map: {'precision': 0.8, 'recall': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "threshold = pd.Series([0.8, 0.6], index=[\"precision\", \"recall\"], name=\"threshold\")\n",
    "threshold_map = threshold.to_dict()\n",
    "print(\"Threshold map:\", threshold_map)\n",
    "\n",
    "assert threshold_map[\"precision\"] == 0.8\n",
    "assert threshold_map[\"recall\"] == 0.6\n",
    "assert set(threshold_map.keys()) == {\"precision\", \"recall\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e7ba4",
   "metadata": {},
   "source": [
    "##### Series.to_frame()\n",
    "`to_frame()` converts a Series into a single-column DataFrame. It is useful when a workflow expects tabular structure (joins, merges, SQL-like operations). Index labels are preserved as the DataFrame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "9ecc8032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    5\n",
       "u2    7\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([5, 7], index=[\"u1\", \"u2\"], name=\"score\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "9547825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score\n",
       "u1      5\n",
       "u2      7"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6232aa39",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90356e",
   "metadata": {},
   "source": [
    "`series.to_frame()` wraps a Series into a one-column DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9645d80",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade1aca",
   "metadata": {},
   "source": [
    "- `name` (hashable, optional): column name in output DataFrame; defaults to `series.name` when available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1b563",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5782b5e",
   "metadata": {},
   "source": [
    "Think of turning one spreadsheet column into a mini table object.\n",
    "\n",
    "- Same values.\n",
    "\n",
    "- Same row labels.\n",
    "\n",
    "Now it behaves like a DataFrame for joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff72a5d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d914f9",
   "metadata": {},
   "source": [
    "- Pandas creates a DataFrame using Series values as one column.\n",
    "\n",
    "- Index is preserved exactly.\n",
    "\n",
    "- Column name comes from `name` argument or Series name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcea032",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2ecfb",
   "metadata": {},
   "source": [
    "- Output type changes from Series to DataFrame, affecting downstream method calls.\n",
    "\n",
    "- Missing/ambiguous column names can create confusion in merges.\n",
    "\n",
    "- Extra structure may be unnecessary for simple vector operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b4eafe",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db77ed8",
   "metadata": {},
   "source": [
    "- Do downstream steps require DataFrame APIs?\n",
    "\n",
    "- Is output column name explicit and stable?\n",
    "\n",
    "- Should index remain as index or be reset afterward?\n",
    "\n",
    "- Is one-column DataFrame the right contract for consumers?\n",
    "\n",
    "- Are type expectations updated after conversion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52479378",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f0ebc",
   "metadata": {},
   "source": [
    "Use `to_frame()` when you need tabular compatibility while preserving the Series index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c07fc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert a KPI Series into a DataFrame before joining with metadata tables.\n",
    "\n",
    "Scenario: model scores need a tabular form for merge operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "33844bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          auc\n",
      "model_a  0.91\n",
      "model_b  0.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc\")\n",
    "score_df = score.to_frame()\n",
    "print(score_df)\n",
    "\n",
    "assert list(score_df.columns) == [\"auc\"]\n",
    "assert score_df.shape == (2, 1)\n",
    "assert float(score_df.loc[\"model_b\", \"auc\"]) == 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4372df",
   "metadata": {},
   "source": [
    "##### Series.to_numpy()\n",
    "`to_numpy()` converts Series values to a NumPy array. It is useful for numerical libraries that operate on ndarray inputs. The index is not carried into the array, so label context is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "8b1943f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    1.0\n",
       "r2    2.5\n",
       "r3    3.5\n",
       "Name: feature, dtype: float64"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([1.0, 2.5, 3.5], index=[\"r1\", \"r2\", \"r3\"], name=\"feature\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "7005e56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 2.5, 3.5])"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85549268",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4596e66",
   "metadata": {},
   "source": [
    "`series.to_numpy()` gives you raw values as a NumPy array without index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f136337",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e717d",
   "metadata": {},
   "source": [
    "- `dtype` (NumPy dtype or `None`): requested output dtype.\n",
    "\n",
    "- `copy` (`bool`, default `False`): request copying data rather than returning a view when possible.\n",
    "\n",
    "- `na_value` (object, optional): value to use for missing data in output.\n",
    "\n",
    "- `**kwargs`: additional compatibility options forwarded internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c49db",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89463be1",
   "metadata": {},
   "source": [
    "Think of stripping a labeled spreadsheet column down to just numeric cells for math engines.\n",
    "\n",
    "- Labels are removed.\n",
    "\n",
    "- Values become a dense array object.\n",
    "\n",
    "Best for numeric computation APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351911d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e83dd",
   "metadata": {},
   "source": [
    "- Pandas extracts underlying values from the Series.\n",
    "\n",
    "- It materializes them as an ndarray with requested dtype/copy behavior.\n",
    "\n",
    "- Index metadata is dropped during conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d56205",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e027eb",
   "metadata": {},
   "source": [
    "- Losing labels can cause alignment mistakes if reused later.\n",
    "\n",
    "- Dtype coercion may occur depending on mixed values/missing data.\n",
    "\n",
    "- `copy=False` may still copy in some cases; memory assumptions should be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec2e83",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847b15b",
   "metadata": {},
   "source": [
    "- Do you still need index labels after conversion?\n",
    "\n",
    "- Is output dtype explicit for downstream math?\n",
    "\n",
    "- Are missing values handled before array export?\n",
    "\n",
    "- Is a copy required for safe mutation isolation?\n",
    "\n",
    "- Will array order remain aligned with target feature mapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ed75c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dd143",
   "metadata": {},
   "source": [
    "Use `to_numpy()` for fast numeric interoperability, but preserve label mapping separately if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78786f7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Export a feature Series to ndarray for matrix-based scoring code.\n",
    "\n",
    "Scenario: labels are tracked separately, while model scoring consumes arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "0e6c9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1.  2.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature = pd.Series([1.0, 2.5, 3.5], index=[\"u1\", \"u2\", \"u3\"], name=\"x\")\n",
    "arr = feature.to_numpy(dtype=float)\n",
    "print(\"Array:\", arr)\n",
    "\n",
    "assert isinstance(arr, np.ndarray)\n",
    "assert arr.shape == (3,)\n",
    "assert float(arr[1]) == 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24901377",
   "metadata": {},
   "source": [
    "##### Series.to_csv(path_or_buf)\n",
    "`to_csv(...)` serializes a Series into CSV text or writes it to a file/buffer. It is useful for exports, logging snapshots, and data handoff to non-Python tools. You can control separators, headers, index inclusion, and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "de5b97a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([10, 20], index=[\"a\", \"b\"], name=\"value\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "2f5168ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',value\\r\\na,10\\r\\nb,20\\r\\n'"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13479d2a",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61070a69",
   "metadata": {},
   "source": [
    "`series.to_csv(...)` turns a Series into CSV-formatted output for sharing or storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9decd",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd1561",
   "metadata": {},
   "source": [
    "- `path_or_buf` (path, buffer, or `None`): destination target; if `None`, returns CSV string.\n",
    "\n",
    "- `sep` (`str`, default `\",\"`): delimiter between fields.\n",
    "\n",
    "- `header` (`bool` or list, default `True`): include column header in output.\n",
    "\n",
    "- `index` (`bool`, default `True`): include index labels in CSV.\n",
    "\n",
    "- `index_label` (label or `None`): explicit index column name in output.\n",
    "\n",
    "- `na_rep` (`str`, default `\"\"`): text representation for missing values.\n",
    "\n",
    "- `encoding` (`str` or `None`): output encoding when writing to files.\n",
    "\n",
    "- `mode` (`str`, default `\"w\"`): file write mode when using path outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800412c8",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b105a0",
   "metadata": {},
   "source": [
    "Think of exporting a spreadsheet column to a CSV file for another team.\n",
    "\n",
    "- You choose whether row labels are included.\n",
    "\n",
    "- You choose delimiter and header style.\n",
    "\n",
    "Output becomes tool-agnostic text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41d694",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ad338",
   "metadata": {},
   "source": [
    "- Pandas formats index and values row-by-row into CSV records.\n",
    "\n",
    "- Output is written to destination or returned as text when no path is given.\n",
    "\n",
    "- Formatting parameters control representation details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c9c15",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa144c0b",
   "metadata": {},
   "source": [
    "- CSV has limited type fidelity compared to binary formats.\n",
    "\n",
    "- Locale/encoding settings can break downstream parsing if inconsistent.\n",
    "\n",
    "- Index inclusion choices can cause import mismatches later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1910936",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb8381",
   "metadata": {},
   "source": [
    "- Should index labels be exported or suppressed?\n",
    "\n",
    "- Is delimiter compatible with consuming system?\n",
    "\n",
    "- Do you need stable encoding and float formatting rules?\n",
    "\n",
    "- Should missing values use explicit tokens?\n",
    "\n",
    "- Is returning a string (`path_or_buf=None`) enough or is file output required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39ea50",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe96068",
   "metadata": {},
   "source": [
    "Use `to_csv` to create shareable text exports, with explicit control over index/header formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1d7ed",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create a lightweight CSV snapshot of daily KPIs for ingestion into a legacy scheduler.\n",
    "\n",
    "Scenario: pipeline needs CSV text payload without writing external files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "7dd6a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",orders\n",
      "2025-06-01,120\n",
      "2025-06-02,135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kpi = pd.Series([120, 135], index=[\"2025-06-01\", \"2025-06-02\"], name=\"orders\")\n",
    "csv_text = kpi.to_csv()\n",
    "print(csv_text)\n",
    "\n",
    "assert \",orders\" in csv_text\n",
    "assert \"2025-06-01,120\" in csv_text\n",
    "assert \"2025-06-02,135\" in csv_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f75b7",
   "metadata": {},
   "source": [
    "##### Series.to_json(path_or_buf)\n",
    "`to_json(...)` serializes a Series to JSON text or writes JSON to a destination buffer/path. It is useful for API payloads and lightweight data exchange. You can control orientation, precision, and index handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "e5fc9a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-06-01    120\n",
       "2025-06-02    135\n",
       "Name: orders, dtype: int64"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([120, 135], index=[\"2025-06-01\", \"2025-06-02\"], name=\"orders\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "76d37c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"2025-06-01\":120,\"2025-06-02\":135}'"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_json(orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e4eef",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67721185",
   "metadata": {},
   "source": [
    "`series.to_json(...)` turns labeled Series data into JSON format for transport or storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c9a27",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82528a12",
   "metadata": {},
   "source": [
    "- `path_or_buf` (path, buffer, or `None`): destination target; if `None`, returns JSON string.\n",
    "\n",
    "- `orient` (`\"index\"`, `\"split\"`, `\"records\"`, etc.): JSON layout style.\n",
    "\n",
    "- `index` (`bool` or `None`): include index info depending on orient.\n",
    "\n",
    "- `date_format` / `date_unit`: control datetime serialization.\n",
    "\n",
    "- `double_precision` (`int`, default `10`): floating precision in output.\n",
    "\n",
    "- `lines` (`bool`, default `False`): line-delimited JSON output mode.\n",
    "\n",
    "- `indent` (`int` or `None`): pretty-print indentation level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0df4cd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6e04c",
   "metadata": {},
   "source": [
    "Think of exporting a spreadsheet column into JSON key-value text.\n",
    "\n",
    "- Labels can become JSON keys.\n",
    "\n",
    "- Values become JSON values.\n",
    "\n",
    "Useful for web/service integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4506467",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe952cb4",
   "metadata": {},
   "source": [
    "- Pandas maps index/value pairs into the chosen JSON orientation.\n",
    "\n",
    "- Values are converted into JSON-serializable representations.\n",
    "\n",
    "- Output is returned as a string or written to destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829ecbe",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f44e0",
   "metadata": {},
   "source": [
    "- Orientation choice can confuse downstream consumers if not documented.\n",
    "\n",
    "- Datetime and float formatting may lose precision/context if misconfigured.\n",
    "\n",
    "- Large JSON payloads can be memory-heavy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4712f",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92464c46",
   "metadata": {},
   "source": [
    "- Which JSON orientation does the consuming system expect?\n",
    "\n",
    "- Should index labels be preserved in payload?\n",
    "\n",
    "- Are datetime/float formatting settings explicit?\n",
    "\n",
    "- Do you need line-delimited output for streaming tools?\n",
    "\n",
    "- Is payload size acceptable for transport limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44773668",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749183",
   "metadata": {},
   "source": [
    "Use `to_json` for service-friendly serialization with explicit orient and formatting choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96224d9a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create a JSON payload of daily KPI values for an internal monitoring API.\n",
    "\n",
    "Scenario: date labels must remain keys so the API can map values to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "0b27e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON payload: {'2025-06-01': 120, '2025-06-02': 135}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "daily_kpi = pd.Series([120, 135], index=[\"2025-06-01\", \"2025-06-02\"], name=\"orders\")\n",
    "json_text = daily_kpi.to_json(orient=\"index\")\n",
    "payload = json.loads(json_text)\n",
    "print(\"JSON payload:\", payload)\n",
    "\n",
    "assert payload[\"2025-06-01\"] == 120\n",
    "assert payload[\"2025-06-02\"] == 135\n",
    "assert isinstance(json_text, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecc241",
   "metadata": {},
   "source": [
    "##### Series.to_excel(excel_writer)\n",
    "`to_excel(...)` writes Series data to Excel format through a writer or path. It is useful for stakeholder-friendly spreadsheet exports. Excel writing typically requires an engine package such as `openpyxl` or `xlsxwriter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "347fb7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "series = pd.Series([10, 20], index=[\"a\", \"b\"], name=\"value\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "403b8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.to_excel(BytesIO())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba71fa",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99ea50",
   "metadata": {},
   "source": [
    "`series.to_excel(...)` exports a Series into Excel workbook format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7e7b6",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e8c56",
   "metadata": {},
   "source": [
    "- `excel_writer` (path, buffer, or `ExcelWriter`): output destination.\n",
    "\n",
    "- `sheet_name` (`str`, default `\"Sheet1\"`): target worksheet name.\n",
    "\n",
    "- `index` (`bool`, default `True`): include index labels in output.\n",
    "\n",
    "- `header` (`bool`/labels, default `True`): include value column header.\n",
    "\n",
    "- `engine` (`\"openpyxl\"`, `\"xlsxwriter\"`, or `None`): Excel engine backend.\n",
    "\n",
    "- `startrow` / `startcol` (`int`): output offset placement in sheet.\n",
    "\n",
    "- `na_rep` / `float_format`: formatting controls for missing/numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf36ec9",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3b297",
   "metadata": {},
   "source": [
    "Think of saving a spreadsheet-ready column for business users.\n",
    "\n",
    "- Labels and values become worksheet rows.\n",
    "\n",
    "- Formatting options control how cells appear.\n",
    "\n",
    "Output is easy to share outside Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248eeddb",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6044f",
   "metadata": {},
   "source": [
    "- Pandas converts Series into tabular sheet rows (index + values).\n",
    "\n",
    "- An Excel engine creates workbook bytes from that table.\n",
    "\n",
    "- Data is written to file/buffer according to writer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184fb44",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb246e",
   "metadata": {},
   "source": [
    "- Requires external Excel engine package.\n",
    "\n",
    "- Engine differences can affect formatting features.\n",
    "\n",
    "- Binary workbook output is less diff-friendly than text formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6c498",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf023c0",
   "metadata": {},
   "source": [
    "- Is an Excel engine available in the runtime environment?\n",
    "\n",
    "- Should index labels appear in exported sheet?\n",
    "\n",
    "- Is workbook output required, or would CSV suffice?\n",
    "\n",
    "- Are sheet names and positions standardized?\n",
    "\n",
    "- Do consumers need strict numeric formatting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b24711",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e75df",
   "metadata": {},
   "source": [
    "Use `to_excel` for spreadsheet distribution; check engine availability and fallback when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c964b9",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Produce a weekly KPI Excel payload for non-technical stakeholders.\n",
    "\n",
    "Scenario: when Excel engine is unavailable, fallback to CSV text to keep pipeline alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "3f002932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel bytes: 4892 engine: openpyxl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import importlib.util\n",
    "\n",
    "weekly_kpi = pd.Series([120, 135], index=[\"2025-06-01\", \"2025-06-08\"], name=\"orders\")\n",
    "buf = BytesIO()\n",
    "engine = \"openpyxl\" if importlib.util.find_spec(\"openpyxl\") else (\"xlsxwriter\" if importlib.util.find_spec(\"xlsxwriter\") else None)\n",
    "\n",
    "if engine is not None:\n",
    "    weekly_kpi.to_excel(buf, engine=engine, sheet_name=\"kpi\", index=True, header=True)\n",
    "    excel_bytes = buf.getvalue()\n",
    "    print(\"Excel bytes:\", len(excel_bytes), \"engine:\", engine)\n",
    "    assert len(excel_bytes) > 0\n",
    "    assert engine in {\"openpyxl\", \"xlsxwriter\"}\n",
    "else:\n",
    "    csv_fallback = weekly_kpi.to_csv()\n",
    "    print(\"Excel engine unavailable; CSV fallback length:\", len(csv_fallback))\n",
    "    assert len(csv_fallback) > 0\n",
    "    assert \"2025-06-01,120\" in csv_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea598928",
   "metadata": {},
   "source": [
    "##### Series.to_sql(name, con)\n",
    "`to_sql(name, con)` writes Series data into a SQL table via a database connection. It is useful for persistence and BI consumption. With index enabled, index labels become a database column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "878015c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_a    0.91\n",
       "model_b    0.87\n",
       "Name: auc, dtype: float64"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "series = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "0e82fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\":memory:\")\n",
    "series.to_sql(\"auc_table\", con, if_exists=\"replace\", index=True, index_label=\"model_id\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86997004",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61962e67",
   "metadata": {},
   "source": [
    "`series.to_sql(...)` saves Series rows into a SQL table for querying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73204365",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef7d8b",
   "metadata": {},
   "source": [
    "- `name` (`str`): destination SQL table name.\n",
    "\n",
    "- `con` (connection/engine): database connection target.\n",
    "\n",
    "- `if_exists` (`\"fail\"`, `\"replace\"`, `\"append\"`, `\"delete_rows\"`): behavior if table already exists.\n",
    "\n",
    "- `index` (`bool`, default `True`): write index as a database column.\n",
    "\n",
    "- `index_label` (label or `None`): name for written index column.\n",
    "\n",
    "- `chunksize` (`int` or `None`): rows per batch write.\n",
    "\n",
    "- `dtype` (SQL dtype map or `None`): explicit SQL types for columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1811ad",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce9f44",
   "metadata": {},
   "source": [
    "Think of loading a spreadsheet column into a database table.\n",
    "\n",
    "- Each row becomes a DB record.\n",
    "\n",
    "- Index can become key column.\n",
    "\n",
    "Now SQL tools can query it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de074c",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de376ccd",
   "metadata": {},
   "source": [
    "- Pandas converts Series to tabular rows (index + value).\n",
    "\n",
    "- It issues SQL insert operations through the provided connection.\n",
    "\n",
    "- Write mode and schema options control table creation/append behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9022e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a7be4",
   "metadata": {},
   "source": [
    "- Database type mapping can differ across backends.\n",
    "\n",
    "- Large writes may need chunking for performance.\n",
    "\n",
    "- Wrong `if_exists` mode can overwrite tables unexpectedly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e67d1",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240084b4",
   "metadata": {},
   "source": [
    "- Is table replacement/append policy correct for this pipeline?\n",
    "\n",
    "- Should index be written as a key column?\n",
    "\n",
    "- Are SQL dtypes explicitly controlled where needed?\n",
    "\n",
    "- Is transaction/error handling defined for writes?\n",
    "\n",
    "- Do you need idempotent load logic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f4bc1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe7482",
   "metadata": {},
   "source": [
    "Use `to_sql` to persist Series data in SQL with explicit table and index-write choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902ba12",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Store model metrics in an in-memory SQL table for downstream reporting queries.\n",
    "\n",
    "Scenario: each model label must be queryable as a SQL key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "d4b8afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_id   auc\n",
      "0  model_a  0.91\n",
      "1  model_b  0.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "auc = pd.Series([0.91, 0.87], index=[\"model_a\", \"model_b\"], name=\"auc\")\n",
    "con = sqlite3.connect(\":memory:\")\n",
    "rows_written = auc.to_sql(\"model_auc\", con, if_exists=\"replace\", index=True, index_label=\"model_id\")\n",
    "back = pd.read_sql_query(\"SELECT * FROM model_auc ORDER BY model_id\", con)\n",
    "con.close()\n",
    "print(back)\n",
    "\n",
    "assert rows_written == 2\n",
    "assert list(back[\"model_id\"]) == [\"model_a\", \"model_b\"]\n",
    "assert float(back.loc[back[\"model_id\"] == \"model_b\", \"auc\"].iloc[0]) == 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f16e65",
   "metadata": {},
   "source": [
    "##### Series.to_string()\n",
    "`to_string()` renders a Series as plain text for logs, debugging, and quick reports. It gives formatting control over index/header visibility and numeric display. This is useful when you need human-readable output without rich notebook display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "5049b92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "api_1    120.5\n",
       "api_2    130.0\n",
       "Name: p95_ms, dtype: float64"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([120.5, 130.0], index=[\"api_1\", \"api_2\"], name=\"p95_ms\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "4d1d7039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'api_1    120.5\\napi_2    130.0'"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687dfdc7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e3c9d",
   "metadata": {},
   "source": [
    "`series.to_string()` returns a text block representation of your Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e46fa",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19596364",
   "metadata": {},
   "source": [
    "- `buf` (path, buffer, or `None`): destination target; if `None`, returns string.\n",
    "\n",
    "- `index` (`bool`, default `True`): include index labels in text output.\n",
    "\n",
    "- `header` (`bool`, default `True`): include Series header line.\n",
    "\n",
    "- `na_rep` (`str`, default `\"NaN\"`): text for missing values.\n",
    "\n",
    "- `float_format` (`str` or `None`): float formatting template.\n",
    "\n",
    "- `max_rows` / `min_rows` (`int` or `None`): truncation controls for long output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d69090",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01cf52",
   "metadata": {},
   "source": [
    "Think of printing a spreadsheet column as plain console text.\n",
    "\n",
    "- Easy to paste into logs or tickets.\n",
    "\n",
    "- Formatting is predictable.\n",
    "\n",
    "Useful for quick diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328a43b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842487ea",
   "metadata": {},
   "source": [
    "- Pandas formats index and values into aligned text rows.\n",
    "\n",
    "- Formatting options control what metadata and precision appear.\n",
    "\n",
    "- Output is returned as string or written to the provided buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01abf7b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73efc5",
   "metadata": {},
   "source": [
    "- Text output is not ideal for machine-to-machine exchange.\n",
    "\n",
    "- Large Series can produce long, noisy logs.\n",
    "\n",
    "- Fixed-width rendering can vary with content length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4abc2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336fce5",
   "metadata": {},
   "source": [
    "- Is text output intended for humans (logs) or machines (JSON/CSV)?\n",
    "\n",
    "- Should index/header be included for readability?\n",
    "\n",
    "- Are float/NaN display rules standardized?\n",
    "\n",
    "- Do you need truncation for long Series?\n",
    "\n",
    "- Will logs remain parseable if formatting changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ae0c7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995d9d5",
   "metadata": {},
   "source": [
    "Use `to_string` for controlled, readable text snapshots of Series content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2cda0f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Write a compact KPI snapshot to application logs during batch monitoring.\n",
    "\n",
    "Scenario: output must be human-readable in plain text logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "1946b18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_1    120.5\n",
      "api_2    130.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency = pd.Series([120.5, 130.0], index=[\"api_1\", \"api_2\"], name=\"p95_ms\")\n",
    "text_view = latency.to_string()\n",
    "print(text_view)\n",
    "\n",
    "assert isinstance(text_view, str)\n",
    "assert \"api_1\" in text_view\n",
    "assert \"120.5\" in text_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad924cb5",
   "metadata": {},
   "source": [
    "##### Series.to_clipboard()\n",
    "`to_clipboard()` copies Series content to the system clipboard for quick paste into spreadsheets or documents. It is useful for ad-hoc analyst workflows. In headless/runtime environments, clipboard backends may be unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "86a8e984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([10, 20], index=[\"a\", \"b\"], name=\"value\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "88fd8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.to_clipboard(index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294ecd8",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea639d4e",
   "metadata": {},
   "source": [
    "`series.to_clipboard()` sends a text/table representation of Series data to clipboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270e45b",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2b12a",
   "metadata": {},
   "source": [
    "- `excel` (`bool`, default `True`): use tabular format suited for spreadsheet paste.\n",
    "\n",
    "- `sep` (`str` or `None`): delimiter when `excel=False` or custom formatting is needed.\n",
    "\n",
    "- `**kwargs`: additional options forwarded to underlying text conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c2493",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02176cc",
   "metadata": {},
   "source": [
    "Think of copying a spreadsheet-ready column directly from Python.\n",
    "\n",
    "- Data lands in clipboard.\n",
    "\n",
    "- You can paste immediately into Excel or docs.\n",
    "\n",
    "Great for quick manual checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155331ea",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46b67a",
   "metadata": {},
   "source": [
    "- Pandas renders Series into text/tabular clipboard format.\n",
    "\n",
    "- It calls clipboard backend to set clipboard content.\n",
    "\n",
    "- Format depends on `excel`/`sep` settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039e2cf",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719cf01",
   "metadata": {},
   "source": [
    "- Clipboard access can fail in servers, containers, or remote sessions.\n",
    "\n",
    "- Clipboard operations are side-effectful and not always test-friendly.\n",
    "\n",
    "- Locale/tab delimiter assumptions can affect paste behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04843d75",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64959c41",
   "metadata": {},
   "source": [
    "- Is clipboard backend available in target runtime?\n",
    "\n",
    "- Should output be spreadsheet-friendly (`excel=True`) or plain text?\n",
    "\n",
    "- Do you need deterministic tests without touching system clipboard?\n",
    "\n",
    "- Could accidental clipboard overwrite be problematic?\n",
    "\n",
    "- Is a file/string export safer for automation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88618f5c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b8a1b",
   "metadata": {},
   "source": [
    "Use `to_clipboard` for quick manual transfers; use mocks in automated tests to avoid environment dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02b912",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prepare a small exception list for manual triage by pasting directly into a spreadsheet.\n",
    "\n",
    "Scenario: in tests, mock clipboard backend to verify output safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "9b164d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalue\n",
      "row1\t10\n",
      "row2\t20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unittest.mock import patch\n",
    "\n",
    "exceptions = pd.Series([10, 20], index=[\"row1\", \"row2\"], name=\"value\")\n",
    "captured = {}\n",
    "\n",
    "def fake_clipboard_set(text):\n",
    "    captured[\"text\"] = text\n",
    "\n",
    "with patch(\"pandas.io.clipboard.clipboard_set\", fake_clipboard_set):\n",
    "    exceptions.to_clipboard(index=True)\n",
    "\n",
    "print(captured[\"text\"])\n",
    "\n",
    "assert \"row1\" in captured[\"text\"]\n",
    "assert \"10\" in captured[\"text\"]\n",
    "assert len(captured[\"text\"]) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c917f78",
   "metadata": {},
   "source": [
    "##### Series.to_pickle(path)\n",
    "`to_pickle(path)` serializes a Series in Python pickle format for fast round-trip persistence. It preserves index, dtype, and metadata better than plain text formats. This is useful for internal checkpoints between Python jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "22f353bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    1.1\n",
       "u2    2.2\n",
       "Name: feature, dtype: float64"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "series = pd.Series([1.1, 2.2], index=[\"u1\", \"u2\"], name=\"feature\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "96932ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "buf = BytesIO()\n",
    "series.to_pickle(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743cc0bf",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef471e7",
   "metadata": {},
   "source": [
    "`series.to_pickle(...)` saves the Series object in binary form for later exact reload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bcfaa6",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cc429",
   "metadata": {},
   "source": [
    "- `path` (path or binary buffer): destination for serialized bytes.\n",
    "\n",
    "- `compression` (compression option, default `\"infer\"`): optional compression behavior.\n",
    "\n",
    "- `protocol` (`int`, default `5`): pickle protocol version.\n",
    "\n",
    "- `storage_options` (dict or `None`): remote-storage options where supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007db76",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63543fff",
   "metadata": {},
   "source": [
    "Think of freezing a spreadsheet column exactly as-is for later restore.\n",
    "\n",
    "- Labels and values are preserved.\n",
    "\n",
    "- Binary storage is compact and fast for Python reload.\n",
    "\n",
    "Best for Python-to-Python workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f58d2f",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9585be",
   "metadata": {},
   "source": [
    "- Pandas serializes the full Series object structure to pickle bytes.\n",
    "\n",
    "- Bytes are written to path/buffer with chosen protocol/compression.\n",
    "\n",
    "- `read_pickle` can reconstruct the Series faithfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fadd0e",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab81454",
   "metadata": {},
   "source": [
    "- Pickle is Python-specific and not ideal for cross-language sharing.\n",
    "\n",
    "- Untrusted pickle files are a security risk.\n",
    "\n",
    "- Version/environment compatibility should be considered across long-term storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608649b",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdff3ad",
   "metadata": {},
   "source": [
    "- Is this artifact consumed only by trusted Python workflows?\n",
    "\n",
    "- Do you need compression for storage constraints?\n",
    "\n",
    "- Is protocol/version compatibility managed across environments?\n",
    "\n",
    "- Are you avoiding untrusted pickle inputs?\n",
    "\n",
    "- Would a neutral format (CSV/JSON/Parquet) be better for sharing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d335d",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cd8b1",
   "metadata": {},
   "source": [
    "Use `to_pickle` for fast, faithful Python round-trips in trusted internal pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990bbc5b",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Store intermediate feature vectors between ETL and model-scoring steps with exact dtype/index preservation.\n",
    "\n",
    "Scenario: checkpoint stays in memory buffer during a single pipeline run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "a60b0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle bytes: 873\n",
      "Loaded: {'u1': 1.1, 'u2': 2.2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "feature = pd.Series([1.1, 2.2], index=[\"u1\", \"u2\"], name=\"x\")\n",
    "buf = BytesIO()\n",
    "feature.to_pickle(buf)\n",
    "size = len(buf.getvalue())\n",
    "buf.seek(0)\n",
    "loaded = pd.read_pickle(buf)\n",
    "print(\"Pickle bytes:\", size)\n",
    "print(\"Loaded:\", loaded.to_dict())\n",
    "\n",
    "assert size > 0\n",
    "assert loaded.equals(feature)\n",
    "assert list(loaded.index) == [\"u1\", \"u2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e310e61",
   "metadata": {},
   "source": [
    "#### String Accessor Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b24643",
   "metadata": {},
   "source": [
    "##### Series.str.lower()\n",
    "`str.lower()` converts each string value in a Series to lowercase. It is useful for normalization before matching, grouping, or deduplication. Non-string/missing entries are handled according to pandas string accessor rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "098dba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    Alice.SMITH@EXAMPLE.COM\n",
       "u2            BOB@Example.COM\n",
       "Name: email, dtype: str"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"Alice.SMITH@EXAMPLE.COM\", \"BOB@Example.COM\"], index=[\"u1\", \"u2\"], name=\"email\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "a7cef26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    alice.smith@example.com\n",
       "u2            bob@example.com\n",
       "Name: email, dtype: str"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21075c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fdfb5a",
   "metadata": {},
   "source": [
    "`series.str.lower()` makes every text entry lowercase while preserving index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6fc80",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431b929",
   "metadata": {},
   "source": [
    "- `(none)`: `str.lower()` takes no parameters and applies lowercase conversion element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b9162c",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd69952",
   "metadata": {},
   "source": [
    "Think of setting a spreadsheet text column to one consistent case style.\n",
    "\n",
    "- `ABC` becomes `abc`.\n",
    "\n",
    "- Row labels remain unchanged.\n",
    "\n",
    "This avoids case-based mismatches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b437b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd5542",
   "metadata": {},
   "source": [
    "- Pandas applies Python-like lowercase transformation to each string element.\n",
    "\n",
    "- Each transformed value is placed back at the same index label.\n",
    "\n",
    "- Output is a new Series with normalized casing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911df9c5",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e390f9",
   "metadata": {},
   "source": [
    "- Case normalization can lose intentional casing (brand names, acronyms).\n",
    "\n",
    "- Locale/language-specific casing nuances may need extra care.\n",
    "\n",
    "- Non-string object values can produce unexpected results if not cleaned first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbb3d6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5ceec",
   "metadata": {},
   "source": [
    "- Is lowercase the canonical format for your domain?\n",
    "\n",
    "- Do you need to preserve original raw text elsewhere?\n",
    "\n",
    "- Are all entries guaranteed to be string-like?\n",
    "\n",
    "- Could locale-specific casing matter?\n",
    "\n",
    "- Is normalization applied consistently across datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e5c46a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143cb93",
   "metadata": {},
   "source": [
    "Use `str.lower()` to standardize text casing before joins, filters, and deduplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89ef05",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Normalize incoming email addresses before checking uniqueness in user onboarding.\n",
    "\n",
    "Scenario: different casing should map to the same canonical email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "65cdc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized email: {'u1': 'alice.smith@example.com', 'u2': 'bob@example.com'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "email = pd.Series([\"Alice.SMITH@EXAMPLE.COM\", \"BOB@Example.COM\"], index=[\"u1\", \"u2\"], name=\"email\")\n",
    "email_norm = email.str.lower()\n",
    "print(\"Normalized email:\", email_norm.to_dict())\n",
    "\n",
    "assert email_norm.loc[\"u1\"] == \"alice.smith@example.com\"\n",
    "assert email_norm.loc[\"u2\"] == \"bob@example.com\"\n",
    "assert email_norm.index.equals(email.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b8db5",
   "metadata": {},
   "source": [
    "##### Series.str.upper()\n",
    "`str.upper()` converts each string value to uppercase. It is commonly used for standard codes such as country, state, and status flags. Keeping case consistent prevents avoidable grouping mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "ce9ec312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    us\n",
       "r2    de\n",
       "r3    Fr\n",
       "Name: country_code, dtype: str"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"us\", \"de\", \"Fr\"], index=[\"r1\", \"r2\", \"r3\"], name=\"country_code\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "df9d773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    US\n",
       "r2    DE\n",
       "r3    FR\n",
       "Name: country_code, dtype: str"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb327f3e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82480f1a",
   "metadata": {},
   "source": [
    "`series.str.upper()` transforms text values to uppercase, one element at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0dc02",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc017a6f",
   "metadata": {},
   "source": [
    "- `(none)`: `str.upper()` takes no parameters and applies uppercase conversion element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9072b30",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f615836",
   "metadata": {},
   "source": [
    "Think of forcing a code column in a spreadsheet to all caps.\n",
    "\n",
    "- `us` becomes `US`.\n",
    "\n",
    "- Label alignment stays intact.\n",
    "\n",
    "Reports become consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9247754",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f54da4",
   "metadata": {},
   "source": [
    "- Pandas applies uppercase transformation to each string.\n",
    "\n",
    "- Converted values keep their original index positions.\n",
    "\n",
    "- Result is a new uppercase-normalized Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9fd26",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0005cad",
   "metadata": {},
   "source": [
    "- Uppercasing may remove meaningful stylistic casing in free text.\n",
    "\n",
    "- Language-specific characters can have special uppercase behavior.\n",
    "\n",
    "- Non-string noise should be cleaned before transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f60466",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94726156",
   "metadata": {},
   "source": [
    "- Are uppercase codes the agreed standard in downstream systems?\n",
    "\n",
    "- Is the column truly code-like rather than free text?\n",
    "\n",
    "- Do you need to preserve raw casing for audit purposes?\n",
    "\n",
    "- Are non-string values present and handled?\n",
    "\n",
    "- Is this step applied before grouping/joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ab50b",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ccc07",
   "metadata": {},
   "source": [
    "Use `str.upper()` to standardize code fields where uppercase is canonical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a2510",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Standardize market codes before merging campaign data from multiple sources.\n",
    "\n",
    "Scenario: all systems expect uppercase ISO-like region codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "7be6b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper market codes: {'c1': 'US', 'c2': 'DE', 'c3': 'FR'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "market = pd.Series([\"us\", \"de\", \"Fr\"], index=[\"c1\", \"c2\", \"c3\"], name=\"market\")\n",
    "market_std = market.str.upper()\n",
    "print(\"Upper market codes:\", market_std.to_dict())\n",
    "\n",
    "assert market_std.loc[\"c1\"] == \"US\"\n",
    "assert market_std.loc[\"c3\"] == \"FR\"\n",
    "assert list(market_std.index) == [\"c1\", \"c2\", \"c3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b0399",
   "metadata": {},
   "source": [
    "##### Series.str.title()\n",
    "`str.title()` converts text to title case by capitalizing words. It is useful for display-ready labels and reports. It should be used carefully for names with special capitalization conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "4965475d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1         new york\n",
       "r2    san francisco\n",
       "r3      los angeles\n",
       "Name: city, dtype: str"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"new york\", \"san francisco\", \"los angeles\"], index=[\"r1\", \"r2\", \"r3\"], name=\"city\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "0d2232e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1         New York\n",
       "r2    San Francisco\n",
       "r3      Los Angeles\n",
       "Name: city, dtype: str"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55ad5c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4700d",
   "metadata": {},
   "source": [
    "`series.str.title()` makes each word start with an uppercase letter for display formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7059232",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296a7dd",
   "metadata": {},
   "source": [
    "- `(none)`: `str.title()` takes no parameters and applies title-case formatting element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7addeec",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174ed1b",
   "metadata": {},
   "source": [
    "Think of applying proper headline-style capitalization in a spreadsheet column.\n",
    "\n",
    "- `new york` becomes `New York`.\n",
    "\n",
    "- Row labels do not move.\n",
    "\n",
    "This improves readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874a7ed",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c092c1a",
   "metadata": {},
   "source": [
    "- Pandas applies title-casing logic to each string value.\n",
    "\n",
    "- Word-level capitalization is produced per element.\n",
    "\n",
    "- Output keeps original index alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8000e8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc12043",
   "metadata": {},
   "source": [
    "- Not all personal/brand names follow simple title-case rules.\n",
    "\n",
    "- Apostrophes/hyphens can yield imperfect casing in some cases.\n",
    "\n",
    "- Best for presentation, not necessarily canonical storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05460c62",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b2fc3",
   "metadata": {},
   "source": [
    "- Is this transformation for display only or for storage keys?\n",
    "\n",
    "- Are there known naming exceptions that need custom logic?\n",
    "\n",
    "- Could title-casing break brand/person-name conventions?\n",
    "\n",
    "- Do you need locale-aware formatting?\n",
    "\n",
    "- Should raw text be preserved alongside formatted text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4785c7",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740dcfbd",
   "metadata": {},
   "source": [
    "Use `str.title()` to improve readability in outputs, with exceptions handled separately when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93333a73",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prepare city names for a customer-facing report where consistent title casing improves readability.\n",
    "\n",
    "Scenario: internal processing keeps raw values, but report output is normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "ca9e3329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display city names: {'id1': 'New York', 'id2': 'San Francisco', 'id3': 'Los Angeles'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "city = pd.Series([\"new york\", \"san francisco\", \"los angeles\"], index=[\"id1\", \"id2\", \"id3\"], name=\"city\")\n",
    "city_display = city.str.title()\n",
    "print(\"Display city names:\", city_display.to_dict())\n",
    "\n",
    "assert city_display.loc[\"id1\"] == \"New York\"\n",
    "assert city_display.loc[\"id2\"] == \"San Francisco\"\n",
    "assert city_display.index.equals(city.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c64770",
   "metadata": {},
   "source": [
    "##### Series.str.strip(to_strip=None)\n",
    "`str.strip(...)` removes leading and trailing whitespace (or specified characters) from each string. It is essential in cleaning pipelines where hidden spaces break joins and filters. By default, it trims whitespace only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "7b88d8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1      A-100  \n",
       "x2      \\tB-200\n",
       "x3     C-300   \n",
       "Name: sku, dtype: str"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"  A-100  \", \"\tB-200\", \"C-300   \"], index=[\"x1\", \"x2\", \"x3\"], name=\"sku\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "fd574509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    A-100\n",
       "x2    B-200\n",
       "x3    C-300\n",
       "Name: sku, dtype: str"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1188d",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e40bb",
   "metadata": {},
   "source": [
    "`series.str.strip()` trims unwanted characters from both ends of each string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b35f3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fad839",
   "metadata": {},
   "source": [
    "- `to_strip` (`str` or `None`, default `None`): characters to remove from both ends; default trims whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1415db",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44090c4a",
   "metadata": {},
   "source": [
    "Think of cleaning extra spaces around spreadsheet cells before matching values.\n",
    "\n",
    "- `\"  A\"` becomes `\"A\"`.\n",
    "\n",
    "- Core text is unchanged.\n",
    "\n",
    "This prevents silent key mismatches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10144f06",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c63940",
   "metadata": {},
   "source": [
    "- Pandas examines string boundaries on each element.\n",
    "\n",
    "- Matching boundary characters are removed according to `to_strip`.\n",
    "\n",
    "- Cleaned strings are returned with same index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f14ff8",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f1aea",
   "metadata": {},
   "source": [
    "- Only trims ends; internal spaces are not changed.\n",
    "\n",
    "- Custom `to_strip` removes any matching characters at boundaries, not full substrings.\n",
    "\n",
    "- Non-string values may require pre-cleaning/casting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498a3b8",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68654e5",
   "metadata": {},
   "source": [
    "- Are join keys failing due to boundary whitespace?\n",
    "\n",
    "- Do you need boundary trim only, or internal space normalization too?\n",
    "\n",
    "- Should custom characters be stripped beyond whitespace?\n",
    "\n",
    "- Are all entries guaranteed to be strings?\n",
    "\n",
    "- Is cleaning applied consistently across all source tables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941be3fb",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa6402",
   "metadata": {},
   "source": [
    "Use `str.strip()` early to remove boundary noise that often breaks matching logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce891a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Clean imported SKU codes before joining sales and inventory datasets.\n",
    "\n",
    "Scenario: source files contain tabs/spaces around keys that should match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "dc8f8f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean SKUs: {'r1': 'A-100', 'r2': 'B-200', 'r3': 'C-300'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sku_raw = pd.Series([\"  A-100  \", \"\tB-200\", \"C-300   \"], index=[\"r1\", \"r2\", \"r3\"], name=\"sku\")\n",
    "sku_clean = sku_raw.str.strip()\n",
    "print(\"Clean SKUs:\", sku_clean.to_dict())\n",
    "\n",
    "assert sku_clean.loc[\"r1\"] == \"A-100\"\n",
    "assert sku_clean.loc[\"r2\"] == \"B-200\"\n",
    "assert sku_clean.loc[\"r3\"] == \"C-300\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1103066",
   "metadata": {},
   "source": [
    "##### Series.str.replace(pat, repl)\n",
    "`str.replace(pat, repl, ...)` replaces matching text patterns in each string element. It is useful for normalization rules such as removing prefixes, fixing delimiters, or standardizing tokens. In current pandas, `regex=False` by default unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "e57a6b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i1    SKU-001\n",
       "i2    SKU-002\n",
       "i3    SKU-010\n",
       "Name: sku, dtype: str"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"SKU-001\", \"SKU-002\", \"SKU-010\"], index=[\"i1\", \"i2\", \"i3\"], name=\"sku\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "6a395510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i1    001\n",
       "i2    002\n",
       "i3    010\n",
       "Name: sku, dtype: str"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.replace(\"SKU-\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc69ef2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c922b",
   "metadata": {},
   "source": [
    "`series.str.replace(...)` finds text patterns and substitutes them with new text for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64f4ec",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedda88",
   "metadata": {},
   "source": [
    "- `pat` (`str`, compiled regex, or `dict`): pattern(s) to match.\n",
    "\n",
    "- `repl` (`str`, callable, or `None`): replacement value/function.\n",
    "\n",
    "- `n` (`int`, default `-1`): max replacements per string (`-1` means all).\n",
    "\n",
    "- `case` (`bool` or `None`): case-sensitive behavior control.\n",
    "\n",
    "- `flags` (`int`, default `0`): regex flags when regex mode is used.\n",
    "\n",
    "- `regex` (`bool`, default `False`): whether `pat` is interpreted as regex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c05e08",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a70ed6",
   "metadata": {},
   "source": [
    "Think of a find-and-replace operation on a spreadsheet column.\n",
    "\n",
    "- Matched fragments are swapped.\n",
    "\n",
    "- Unmatched values stay as they are.\n",
    "\n",
    "Great for standardizing messy text codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eddd42",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96adf87e",
   "metadata": {},
   "source": [
    "- Pandas applies pattern matching per string element.\n",
    "\n",
    "- Matches are replaced according to `repl` and replacement limits.\n",
    "\n",
    "- Behavior differs between literal and regex modes (`regex` parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82baa1",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53733b",
   "metadata": {},
   "source": [
    "- Regex mode can produce unintended replacements if patterns are broad.\n",
    "\n",
    "- Case sensitivity settings can change match coverage.\n",
    "\n",
    "- Heavy regex operations may be slower on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07157831",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce343e7",
   "metadata": {},
   "source": [
    "- Should replacement be literal text or regex-based?\n",
    "\n",
    "- Is replacement case-sensitive by business rule?\n",
    "\n",
    "- Could pattern match unintended substrings?\n",
    "\n",
    "- Do you need to limit replacements with `n`?\n",
    "\n",
    "- Are transformed keys validated before downstream joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924c127",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5ab68",
   "metadata": {},
   "source": [
    "Use `str.replace` for controlled text standardization, with explicit `regex` choice to avoid ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1673fc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Remove a technical prefix from product codes before matching against master product catalog keys.\n",
    "\n",
    "Scenario: source emits `SKU-xxx`, but master table stores bare numeric code strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "d11dab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog codes: {'p1': '001', 'p2': '002', 'p3': '010'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_code = pd.Series([\"SKU-001\", \"SKU-002\", \"SKU-010\"], index=[\"p1\", \"p2\", \"p3\"], name=\"code\")\n",
    "catalog_code = raw_code.str.replace(\"SKU-\", \"\", regex=False)\n",
    "print(\"Catalog codes:\", catalog_code.to_dict())\n",
    "\n",
    "assert catalog_code.loc[\"p1\"] == \"001\"\n",
    "assert catalog_code.loc[\"p3\"] == \"010\"\n",
    "assert list(catalog_code.index) == [\"p1\", \"p2\", \"p3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a09dc",
   "metadata": {},
   "source": [
    "##### Series.str.contains(pattern)\n",
    "`str.contains(...)` checks whether each string element contains a pattern and returns booleans. It is widely used for keyword filters and QA flags. You can control case sensitivity and regex behavior explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "05effeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1      ERROR timeout\n",
       "r2                 ok\n",
       "r3    warning timeout\n",
       "Name: message, dtype: str"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"ERROR timeout\", \"ok\", \"warning timeout\"], index=[\"r1\", \"r2\", \"r3\"], name=\"message\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "28ed44cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1     True\n",
       "r2    False\n",
       "r3     True\n",
       "Name: message, dtype: bool"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.contains(\"timeout\", case=False, na=False, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2de5d7",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0ac60",
   "metadata": {},
   "source": [
    "`series.str.contains(...)` answers True/False for each row based on pattern presence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dbe5c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf24c2",
   "metadata": {},
   "source": [
    "- `pat` (`str` or regex pattern): text/regex to search for.\n",
    "\n",
    "- `case` (`bool`, default `True`): case-sensitive matching toggle.\n",
    "\n",
    "- `flags` (`int`, default `0`): regex flags when regex mode is active.\n",
    "\n",
    "- `na` (scalar, optional): fill value for missing inputs in result booleans.\n",
    "\n",
    "- `regex` (`bool`, default `True`): interpret `pat` as regex or literal text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd3700",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d7240",
   "metadata": {},
   "source": [
    "Think of a spreadsheet rule: \"Does this cell contain this word?\"\n",
    "\n",
    "- Matching rows become `True`.\n",
    "\n",
    "- Non-matching rows become `False`.\n",
    "\n",
    "It creates a clean filter mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd1a25",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a81ff",
   "metadata": {},
   "source": [
    "- Pandas applies pattern matching to each string element.\n",
    "\n",
    "- Match result becomes a boolean at the same index label.\n",
    "\n",
    "- Missing entries are handled by `na` policy if provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a620a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90418e",
   "metadata": {},
   "source": [
    "- Regex mode can match more than expected if pattern is broad.\n",
    "\n",
    "- Case sensitivity defaults may miss intended matches.\n",
    "\n",
    "- Missing strings can propagate NA unless `na` is set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01370e60",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed18727",
   "metadata": {},
   "source": [
    "- Should matching be literal (`regex=False`) or regex-based?\n",
    "\n",
    "- Do you need case-insensitive matching?\n",
    "\n",
    "- How should missing text be represented in the boolean mask?\n",
    "\n",
    "- Are patterns tested against edge strings?\n",
    "\n",
    "- Is this filter stable across locales/encodings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7eae1e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f92de",
   "metadata": {},
   "source": [
    "Use `str.contains` to build robust text filters with explicit case/regex/NA behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2ff4f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Flag support tickets mentioning timeout issues for prioritized triage.\n",
    "\n",
    "Scenario: ticket texts can have mixed case and occasional missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "37ec7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout mask: {'t1': True, 't2': False, 't3': False, 't4': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ticket_text = pd.Series([\"Timeout while connecting\", \"Login success\", None, \"TIMEOUT on retry\"], index=[\"t1\", \"t2\", \"t3\", \"t4\"], name=\"text\")\n",
    "timeout_mask = ticket_text.str.contains(\"timeout\", case=False, na=False, regex=False)\n",
    "print(\"Timeout mask:\", timeout_mask.to_dict())\n",
    "\n",
    "assert bool(timeout_mask.loc[\"t1\"]) is True\n",
    "assert bool(timeout_mask.loc[\"t2\"]) is False\n",
    "assert bool(timeout_mask.loc[\"t3\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8aafa5",
   "metadata": {},
   "source": [
    "##### Series.str.startswith(prefix)\n",
    "`str.startswith(...)` checks whether each string begins with a prefix (or tuple of prefixes). It is useful for code-family detection and routing rules. The result is a boolean Series aligned to original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "fcd686ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    INC-1001\n",
       "b    REQ-2001\n",
       "c    INC-1002\n",
       "Name: ticket_id, dtype: str"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"INC-1001\", \"REQ-2001\", \"INC-1002\"], index=[\"a\", \"b\", \"c\"], name=\"ticket_id\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "b811d73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b    False\n",
       "c     True\n",
       "Name: ticket_id, dtype: bool"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.startswith(\"INC-\", na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee86cff",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cf49e",
   "metadata": {},
   "source": [
    "`series.str.startswith(...)` marks rows whose text begins with a target prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecf4ab",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688c98a",
   "metadata": {},
   "source": [
    "- `pat` (`str` or tuple of `str`): prefix pattern(s) to test.\n",
    "\n",
    "- `na` (scalar, optional): fill value used for missing string entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b791f78",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebca49f",
   "metadata": {},
   "source": [
    "Think of checking whether spreadsheet IDs start with a department code.\n",
    "\n",
    "- Matching prefixes return `True`.\n",
    "\n",
    "- Others return `False`.\n",
    "\n",
    "Great for category routing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2f195",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ad468",
   "metadata": {},
   "source": [
    "- Pandas compares beginning characters of each string with `pat`.\n",
    "\n",
    "- Match outcomes are returned as booleans at the same labels.\n",
    "\n",
    "- Missing values use the provided `na` behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4c3eb",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafedf3b",
   "metadata": {},
   "source": [
    "- Prefix checks are case-sensitive by default.\n",
    "\n",
    "- Hidden leading spaces can break matches.\n",
    "\n",
    "- Non-string noise can impact expected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3253c4",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a22384",
   "metadata": {},
   "source": [
    "- Are IDs cleaned (`strip`) before prefix checks?\n",
    "\n",
    "- Should prefixes be case-insensitive (via prior normalization)?\n",
    "\n",
    "- Do you need one prefix or multiple accepted prefixes?\n",
    "\n",
    "- How should missing values be handled?\n",
    "\n",
    "- Are routing rules documented for each prefix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c53a39",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc7970",
   "metadata": {},
   "source": [
    "Use `str.startswith` for fast, label-preserving prefix-based classification masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be768af",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Route incident tickets by ID prefix to the incident response queue.\n",
    "\n",
    "Scenario: only IDs starting with `INC-` should trigger urgent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "af776cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident mask: {'r1': True, 'r2': False, 'r3': False, 'r4': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ticket_id = pd.Series([\"INC-1001\", \"REQ-2001\", None, \"INC-1002\"], index=[\"r1\", \"r2\", \"r3\", \"r4\"], name=\"ticket\")\n",
    "is_incident = ticket_id.str.startswith(\"INC-\", na=False)\n",
    "print(\"Incident mask:\", is_incident.to_dict())\n",
    "\n",
    "assert bool(is_incident.loc[\"r1\"]) is True\n",
    "assert bool(is_incident.loc[\"r2\"]) is False\n",
    "assert bool(is_incident.loc[\"r3\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceac7a",
   "metadata": {},
   "source": [
    "##### Series.str.endswith(suffix)\n",
    "`str.endswith(...)` checks whether each string ends with a suffix (or tuple of suffixes). It is useful for extension checks, domain filters, and naming standards. It returns a boolean mask aligned to the original index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "c9539b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     report.csv\n",
       "f2      image.png\n",
       "f3    summary.csv\n",
       "Name: filename, dtype: str"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"report.csv\", \"image.png\", \"summary.csv\"], index=[\"f1\", \"f2\", \"f3\"], name=\"filename\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "db7f4868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     True\n",
       "f2    False\n",
       "f3     True\n",
       "Name: filename, dtype: bool"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.endswith(\".csv\", na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f9c22",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4203267",
   "metadata": {},
   "source": [
    "`series.str.endswith(...)` marks rows where text ends with a target suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6c332",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778e0cc",
   "metadata": {},
   "source": [
    "- `pat` (`str` or tuple of `str`): suffix pattern(s) to check.\n",
    "\n",
    "- `na` (scalar, optional): fill value for missing string entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a24c1a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4764f6a",
   "metadata": {},
   "source": [
    "Think of filtering spreadsheet filenames by extension.\n",
    "\n",
    "- `.csv` files become `True`.\n",
    "\n",
    "- Other files become `False`.\n",
    "\n",
    "You get a direct file-type mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd3e86",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539caff",
   "metadata": {},
   "source": [
    "- Pandas compares trailing characters of each string with `pat`.\n",
    "\n",
    "- Boolean match results keep original index labels.\n",
    "\n",
    "- Missing values follow `na` policy when provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc550f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445defcf",
   "metadata": {},
   "source": [
    "- Suffix checks are case-sensitive unless text is normalized first.\n",
    "\n",
    "- Trailing spaces can break expected matches.\n",
    "\n",
    "- Missing entries need explicit `na` handling for stable masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e6d13",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9a048",
   "metadata": {},
   "source": [
    "- Should suffix matching ignore case?\n",
    "\n",
    "- Are filenames cleaned for trailing spaces?\n",
    "\n",
    "- Do you need to accept multiple suffixes?\n",
    "\n",
    "- How should missing file names be treated?\n",
    "\n",
    "- Is suffix check enough, or do you need MIME/content validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecf8bf",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a33b7e",
   "metadata": {},
   "source": [
    "Use `str.endswith` to build reliable suffix-based filters before file-specific processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e816b27",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Select only `.csv` ingest files from a mixed file list before loading.\n",
    "\n",
    "Scenario: downstream parser should process CSV files only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "945a7560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV mask: {'x1': True, 'x2': False, 'x3': False, 'x4': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = pd.Series([\"report.csv\", \"image.png\", None, \"daily.csv\"], index=[\"x1\", \"x2\", \"x3\", \"x4\"], name=\"file\")\n",
    "is_csv = files.str.endswith(\".csv\", na=False)\n",
    "print(\"CSV mask:\", is_csv.to_dict())\n",
    "\n",
    "assert bool(is_csv.loc[\"x1\"]) is True\n",
    "assert bool(is_csv.loc[\"x2\"]) is False\n",
    "assert bool(is_csv.loc[\"x3\"]) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830261c6",
   "metadata": {},
   "source": [
    "##### Series.str.len()\n",
    "`str.len()` computes string length for each element. It is useful for validation rules such as code length checks and truncation audits. Output stays index-aligned for easy filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "f5c82ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k1     A100\n",
       "k2      B20\n",
       "k3    C3000\n",
       "Name: code, dtype: str"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"A100\", \"B20\", \"C3000\"], index=[\"k1\", \"k2\", \"k3\"], name=\"code\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "a50fdac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k1    4\n",
       "k2    3\n",
       "k3    5\n",
       "Name: code, dtype: int64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f06c4",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8a727",
   "metadata": {},
   "source": [
    "`series.str.len()` returns the character count of each text value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d3884",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f74cf",
   "metadata": {},
   "source": [
    "- `(none)`: `str.len()` takes no parameters and returns per-element lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1d7e0",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51edd5",
   "metadata": {},
   "source": [
    "Think of adding a helper column in a spreadsheet that counts characters in each cell.\n",
    "\n",
    "- Short entries get smaller numbers.\n",
    "\n",
    "- Long entries get larger numbers.\n",
    "\n",
    "This enables length-based quality checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17530cd2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575fb49",
   "metadata": {},
   "source": [
    "- Pandas computes length for each string element.\n",
    "\n",
    "- Length values are returned in a new Series with same index.\n",
    "\n",
    "- Result can be used directly in boolean validation masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e502cc",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4803ccc",
   "metadata": {},
   "source": [
    "- Missing values can produce missing lengths depending on dtype/context.\n",
    "\n",
    "- Length does not validate content semantics, only size.\n",
    "\n",
    "- Unicode grapheme complexity may differ from simple character expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a5945",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d6450",
   "metadata": {},
   "source": [
    "- Is length alone a valid quality rule, or do you need pattern validation too?\n",
    "\n",
    "- How should missing inputs be handled in length checks?\n",
    "\n",
    "- Are expected lengths fixed or range-based?\n",
    "\n",
    "- Do you need to trim whitespace before counting?\n",
    "\n",
    "- Are multi-byte/unicode cases relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa37ee",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932c98b",
   "metadata": {},
   "source": [
    "Use `str.len()` for quick, index-safe text length validation before deeper parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0fdd1f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate product code lengths before loading into a strict downstream system.\n",
    "\n",
    "Scenario: only 4-character product codes are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "c9d7c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code lengths: {'p1': 4, 'p2': 3, 'p3': 4, 'p4': 4}\n",
      "Length==4 mask: {'p1': True, 'p2': False, 'p3': True, 'p4': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "product_code = pd.Series([\"A100\", \"B20\", \"C300\", \"D999\"], index=[\"p1\", \"p2\", \"p3\", \"p4\"], name=\"code\")\n",
    "code_len = product_code.str.len()\n",
    "is_len4 = code_len.eq(4)\n",
    "print(\"Code lengths:\", code_len.to_dict())\n",
    "print(\"Length==4 mask:\", is_len4.to_dict())\n",
    "\n",
    "assert int(code_len.loc[\"p2\"]) == 3\n",
    "assert bool(is_len4.loc[\"p1\"]) is True\n",
    "assert int(is_len4.sum()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4938c",
   "metadata": {},
   "source": [
    "##### Series.str.split(sep)\n",
    "`str.split(...)` splits each string into list-like parts using a separator or regex pattern. It is useful for parsing composite text fields such as `city,country` or `key:value` payloads. The default output is a Series of lists unless `expand=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "03859a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1     Rome,IT\n",
       "r2    Milan,IT\n",
       "r3    Paris,FR\n",
       "Name: location, dtype: str"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"Rome,IT\", \"Milan,IT\", \"Paris,FR\"], index=[\"r1\", \"r2\", \"r3\"], name=\"location\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "f1b34d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1     [Rome, IT]\n",
       "r2    [Milan, IT]\n",
       "r3    [Paris, FR]\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.split(\",\", n=1, expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6319fb",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f08c3",
   "metadata": {},
   "source": [
    "`series.str.split(...)` breaks each text value into parts using a delimiter rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fec1b3",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045019b5",
   "metadata": {},
   "source": [
    "- `pat` (`str`, regex pattern, or `None`): separator pattern; default split-on-whitespace behavior when `None`.\n",
    "\n",
    "- `n` (`int`, default `-1`): maximum number of splits per string.\n",
    "\n",
    "- `expand` (`bool`, default `False`): return expanded columns when `True`; list-like entries when `False`.\n",
    "\n",
    "- `regex` (`bool` or `None`): control literal vs regex interpretation of `pat`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bdb3e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196e062",
   "metadata": {},
   "source": [
    "Think of splitting a spreadsheet cell with `City,Country` into two pieces.\n",
    "\n",
    "- Left part is city.\n",
    "\n",
    "- Right part is country code.\n",
    "\n",
    "It prepares structured fields from raw text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421e4da",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31905c0",
   "metadata": {},
   "source": [
    "- Pandas applies split logic to each string element using `pat`/`regex` rules.\n",
    "\n",
    "- Up to `n` splits are performed per row.\n",
    "\n",
    "- Output shape depends on `expand` choice, with index preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c89cb5",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7a561",
   "metadata": {},
   "source": [
    "- Inconsistent delimiters can produce uneven part counts.\n",
    "\n",
    "- Regex separators may split unexpectedly if not explicit.\n",
    "\n",
    "- Additional post-processing is needed when parts are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75a8c2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fea3d7",
   "metadata": {},
   "source": [
    "- Is separator literal text or regex pattern?\n",
    "\n",
    "- Do rows have consistent delimiter presence?\n",
    "\n",
    "- Should output stay list-like or expand into columns?\n",
    "\n",
    "- Is split limit `n` sufficient for all rows?\n",
    "\n",
    "- How will malformed rows be handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ea160",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8aa87",
   "metadata": {},
   "source": [
    "Use `str.split` to parse composite text into structured parts, with explicit delimiter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c89e1c",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Split `city,country` fields from ingestion logs before location-level analysis.\n",
    "\n",
    "Scenario: each row should produce exactly two parts for downstream mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "43bdbc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split parts: {'id1': ['Rome', 'IT'], 'id2': ['Milan', 'IT'], 'id3': ['Paris', 'FR']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "location = pd.Series([\"Rome,IT\", \"Milan,IT\", \"Paris,FR\"], index=[\"id1\", \"id2\", \"id3\"], name=\"location\")\n",
    "parts = location.str.split(\",\", n=1, expand=False)\n",
    "print(\"Split parts:\", parts.to_dict())\n",
    "\n",
    "assert parts.loc[\"id1\"][0] == \"Rome\"\n",
    "assert parts.loc[\"id2\"][1] == \"IT\"\n",
    "assert len(parts.loc[\"id3\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf078d7",
   "metadata": {},
   "source": [
    "##### Series.str.get(i)\n",
    "`str.get(i)` retrieves the i-th element from each string/list-like entry. It is commonly used after `str.split()` to pull a specific token such as region or code part. The result keeps original index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "aa566c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    [EU, IT]\n",
       "r2    [NA, US]\n",
       "r3    [AP, SG]\n",
       "Name: region_code, dtype: object"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"EU-IT\", \"NA-US\", \"AP-SG\"], index=[\"r1\", \"r2\", \"r3\"], name=\"region_code\").str.split(\"-\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "96d65dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    IT\n",
       "r2    US\n",
       "r3    SG\n",
       "Name: region_code, dtype: object"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def3d8b",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e723c79",
   "metadata": {},
   "source": [
    "`series.str.get(i)` picks one position from each row and returns it as a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476c40b",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c030014",
   "metadata": {},
   "source": [
    "- `i` (`int` or hashable): position/key to fetch from each element (for strings, lists, dict-like objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbca80",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac72a7f5",
   "metadata": {},
   "source": [
    "Think of splitting spreadsheet cells into parts and taking only one column of those parts.\n",
    "\n",
    "- Same position is selected in every row.\n",
    "\n",
    "- Labels remain aligned.\n",
    "\n",
    "Useful for token extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30136be",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d1bb9",
   "metadata": {},
   "source": [
    "- Pandas applies element-wise indexing (`[i]`) on each item in the Series.\n",
    "\n",
    "- Retrieved element is emitted at the same index label.\n",
    "\n",
    "- Missing/short elements can produce missing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f7d13",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae27b9",
   "metadata": {},
   "source": [
    "- If row structures are inconsistent, some positions may be missing.\n",
    "\n",
    "- Negative/invalid positions can produce unexpected missing values.\n",
    "\n",
    "- Depends on prior parsing quality (for example, split step)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403cc26c",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35101e7",
   "metadata": {},
   "source": [
    "- Are all rows guaranteed to have enough parts for index `i`?\n",
    "\n",
    "- Should missing extracted tokens be allowed or flagged?\n",
    "\n",
    "- Is tokenization logic (`split`) standardized across sources?\n",
    "\n",
    "- Do you need integer position or dictionary key extraction?\n",
    "\n",
    "- Are extracted tokens validated before downstream joins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b873f23",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0158aa",
   "metadata": {},
   "source": [
    "Use `str.get(i)` to extract one consistent token position from parsed text rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab393ca",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Extract country code from `region-country` text keys before mapping to market metadata.\n",
    "\n",
    "Scenario: every key should contain two tokens separated by `-`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "a6d64256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country token: {'k1': 'IT', 'k2': 'US', 'k3': 'SG'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "region_country = pd.Series([\"EU-IT\", \"NA-US\", \"AP-SG\"], index=[\"k1\", \"k2\", \"k3\"], name=\"region_country\")\n",
    "tokens = region_country.str.split(\"-\")\n",
    "country = tokens.str.get(1)\n",
    "print(\"Country token:\", country.to_dict())\n",
    "\n",
    "assert country.loc[\"k1\"] == \"IT\"\n",
    "assert country.loc[\"k2\"] == \"US\"\n",
    "assert list(country.index) == [\"k1\", \"k2\", \"k3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f372062",
   "metadata": {},
   "source": [
    "##### Series.str.join(sep)\n",
    "`str.join(sep)` joins list-like string elements using a separator. It is useful when normalized tokens need to be recomposed into a display or export field. Each row is joined independently and label alignment is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "512e0691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1        [red, blue]\n",
       "p2    [green, yellow]\n",
       "p3            [black]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([[\"red\", \"blue\"], [\"green\", \"yellow\"], [\"black\"]], index=[\"p1\", \"p2\", \"p3\"], name=\"tags\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "2d4b4e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1        red|blue\n",
       "p2    green|yellow\n",
       "p3           black\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.join(\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf1c30",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81550de4",
   "metadata": {},
   "source": [
    "`series.str.join(sep)` combines per-row string pieces into one string using a separator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a9485",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23d72a",
   "metadata": {},
   "source": [
    "- `sep` (`str`): separator inserted between elements while joining each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e802c59",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fec25",
   "metadata": {},
   "source": [
    "Think of merging multiple spreadsheet tokens back into one cell with a chosen delimiter.\n",
    "\n",
    "- Row parts are glued together.\n",
    "\n",
    "- Delimiter stays consistent.\n",
    "\n",
    "Good for export-ready text fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc2715",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3665171",
   "metadata": {},
   "source": [
    "- Pandas reads each list-like string element row-by-row.\n",
    "\n",
    "- It applies Python-style join with `sep`.\n",
    "\n",
    "- Joined string is returned at the same index label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1c829",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02991c0",
   "metadata": {},
   "source": [
    "- Non-string items in list-like values can raise errors.\n",
    "\n",
    "- Missing/empty lists may need explicit handling rules.\n",
    "\n",
    "- Inconsistent token order can create unstable outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7708a1",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb52ad8",
   "metadata": {},
   "source": [
    "- Are all list elements guaranteed to be strings?\n",
    "\n",
    "- Should empty rows become empty string or missing?\n",
    "\n",
    "- Is delimiter choice compatible with downstream parsing?\n",
    "\n",
    "- Are token orders deterministic?\n",
    "\n",
    "- Do you need escaping when tokens may contain delimiter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7323a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172e3be",
   "metadata": {},
   "source": [
    "Use `str.join(sep)` to deterministically recombine token lists into single text fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adec805",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Serialize per-product tag lists into a pipe-separated text column for downstream CSV export.\n",
    "\n",
    "Scenario: each product has a list of cleaned tags to be flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "64220905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined tags: {'p1': 'red|blue', 'p2': 'green|yellow', 'p3': 'black'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tag_list = pd.Series([[\"red\", \"blue\"], [\"green\", \"yellow\"], [\"black\"]], index=[\"p1\", \"p2\", \"p3\"], name=\"tags\")\n",
    "tag_text = tag_list.str.join(\"|\")\n",
    "print(\"Joined tags:\", tag_text.to_dict())\n",
    "\n",
    "assert tag_text.loc[\"p1\"] == \"red|blue\"\n",
    "assert tag_text.loc[\"p3\"] == \"black\"\n",
    "assert tag_text.index.equals(tag_list.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2005742",
   "metadata": {},
   "source": [
    "##### Series.str.extract(pattern)\n",
    "`str.extract(pattern, ...)` extracts captured regex groups from each string. It is useful for turning embedded text patterns into structured columns or fields. By default (`expand=True`), captured groups are returned as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "fab66535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o1    ORD-2025-001\n",
       "o2    ORD-2025-014\n",
       "o3    ORD-2024-003\n",
       "Name: order_id, dtype: str"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"ORD-2025-001\", \"ORD-2025-014\", \"ORD-2024-003\"], index=[\"o1\", \"o2\", \"o3\"], name=\"order_id\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "2aeb911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>2025</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2</th>\n",
       "      <td>2025</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>2024</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "o1  2025  001\n",
       "o2  2025  014\n",
       "o3  2024  003"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.extract(r\"ORD-(\\d{4})-(\\d{3})\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920bd4aa",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2f86",
   "metadata": {},
   "source": [
    "`series.str.extract(pattern)` pulls regex capture groups into structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642be368",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60612c7b",
   "metadata": {},
   "source": [
    "- `pat` (`str`): regex pattern containing capture groups `(...)`.\n",
    "\n",
    "- `flags` (`int`, default `0`): regex flags (for example, case-insensitive).\n",
    "\n",
    "- `expand` (`bool`, default `True`): return DataFrame with one column per group (`False` may return Series for single group)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e144e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d1183",
   "metadata": {},
   "source": [
    "Think of splitting a coded spreadsheet field into named pieces using a pattern template.\n",
    "\n",
    "- Pattern defines what to capture.\n",
    "\n",
    "- Captured pieces become columns.\n",
    "\n",
    "Great for structured parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ac886",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22590b7",
   "metadata": {},
   "source": [
    "- Pandas applies regex pattern to each row.\n",
    "\n",
    "- Captured groups are extracted when matches exist.\n",
    "\n",
    "- Output shape depends on number of groups and `expand` setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8efde",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a5306",
   "metadata": {},
   "source": [
    "- Rows that do not match produce missing outputs.\n",
    "\n",
    "- Incorrect regex can silently misparse data.\n",
    "\n",
    "- Regex-heavy extraction can be slower on very large text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a9dde",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a6540",
   "metadata": {},
   "source": [
    "- Is regex pattern tested against malformed rows?\n",
    "\n",
    "- Do you want DataFrame output (`expand=True`) or Series output for one group?\n",
    "\n",
    "- Are capture groups aligned with business fields?\n",
    "\n",
    "- How are non-matching rows handled downstream?\n",
    "\n",
    "- Are regex flags needed for case behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafadf9",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6532e",
   "metadata": {},
   "source": [
    "Use `str.extract` to convert patterned strings into explicit structured fields with capture groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aefd905",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Parse order IDs into `year` and `sequence` fields for reporting and partition logic.\n",
    "\n",
    "Scenario: order IDs follow a strict `ORD-YYYY-NNN` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "354d278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  seq\n",
      "a  2025  001\n",
      "b  2025  014\n",
      "c  2024  003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "order_id = pd.Series([\"ORD-2025-001\", \"ORD-2025-014\", \"ORD-2024-003\"], index=[\"a\", \"b\", \"c\"], name=\"order_id\")\n",
    "parts = order_id.str.extract(r\"ORD-(\\d{4})-(\\d{3})\", expand=True)\n",
    "parts.columns = [\"year\", \"seq\"]\n",
    "print(parts)\n",
    "\n",
    "assert parts.loc[\"a\", \"year\"] == \"2025\"\n",
    "assert parts.loc[\"b\", \"seq\"] == \"014\"\n",
    "assert list(parts.columns) == [\"year\", \"seq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c152ba1d",
   "metadata": {},
   "source": [
    "##### Series.str.findall(pattern)\n",
    "`str.findall(pattern)` returns all regex matches found in each string as a list. It is useful when one row can contain multiple occurrences of a token (tags, IDs, error codes). The output is a Series of list-like matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "932c7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m1    tags: #ml #ai\n",
       "m2      tags: #data\n",
       "m3          no tags\n",
       "Name: text, dtype: str"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series([\"tags: #ml #ai\", \"tags: #data\", \"no tags\"], index=[\"m1\", \"m2\", \"m3\"], name=\"text\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "66122309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m1    [#ml, #ai]\n",
       "m2       [#data]\n",
       "m3            []\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.str.findall(r\"#\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ed113",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512ca73",
   "metadata": {},
   "source": [
    "`series.str.findall(pattern)` collects every match per row, not just the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d426dcf",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf6b88",
   "metadata": {},
   "source": [
    "- `pat` (`str` or regex): pattern whose all matches should be collected.\n",
    "\n",
    "- `flags` (`int`, default `0`): regex flags applied during matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403debc",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e1624",
   "metadata": {},
   "source": [
    "Think of scanning each spreadsheet note and listing all hashtags found in that row.\n",
    "\n",
    "- Multiple matches are kept.\n",
    "\n",
    "- No-match rows return empty lists.\n",
    "\n",
    "Useful for token mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3281a4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d18e12",
   "metadata": {},
   "source": [
    "- Pandas runs regex search repeatedly per row to collect all occurrences.\n",
    "\n",
    "- Matches are stored as lists in output Series entries.\n",
    "\n",
    "- Index labels remain unchanged for traceability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47de9b9",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41c202",
   "metadata": {},
   "source": [
    "- Regex patterns can overmatch if not specific enough.\n",
    "\n",
    "- Output is list-like object dtype, which may need explode/normalization.\n",
    "\n",
    "- Heavy match extraction can be expensive on large text columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae0987",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146ce60",
   "metadata": {},
   "source": [
    "- Do you need all matches (`findall`) or just one (`extract`)?\n",
    "\n",
    "- Is the regex precise enough to avoid noise tokens?\n",
    "\n",
    "- Will you normalize list output (for example, with `explode`)?\n",
    "\n",
    "- Are no-match rows expected and handled?\n",
    "\n",
    "- Are regex flags required for case-insensitive capture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff05e5",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d3814",
   "metadata": {},
   "source": [
    "Use `str.findall` when each row may contain multiple pattern matches that must all be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7f327",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Extract all hashtag tokens from social posts before tag-frequency analysis.\n",
    "\n",
    "Scenario: each post can contain zero, one, or many hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "e6115dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tags: {'p1': ['#ml', '#ai'], 'p2': ['#data'], 'p3': []}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "post = pd.Series([\"#ml release #ai\", \"#data update\", \"plain text\"], index=[\"p1\", \"p2\", \"p3\"], name=\"post\")\n",
    "tags = post.str.findall(r\"#\\w+\")\n",
    "print(\"Found tags:\", tags.to_dict())\n",
    "\n",
    "assert tags.loc[\"p1\"] == [\"#ml\", \"#ai\"]\n",
    "assert tags.loc[\"p2\"] == [\"#data\"]\n",
    "assert tags.loc[\"p3\"] == []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ac3f4",
   "metadata": {},
   "source": [
    "#### Datetime accessor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b3a4d",
   "metadata": {},
   "source": [
    "##### Series.dt.year\n",
    "`dt.year` extracts the year component from each datetime value in a Series. It is useful for yearly trends, partition keys, and feature engineering. The output is a numeric Series aligned to the same index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "9b69f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2024-12-31 23:00:00\n",
       "e2   2025-01-01 00:15:00\n",
       "Name: event_ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2024-12-31 23:00:00\", \"2025-01-01 00:15:00\"]), index=[\"e1\", \"e2\"], name=\"event_ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "70cc46fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1    2024\n",
       "e2    2025\n",
       "Name: event_ts, dtype: int32"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c666aa4",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf85d91",
   "metadata": {},
   "source": [
    "`series.dt.year` gives the calendar year for each datetime row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4216954",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565fdf0",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.year` is a datetime property accessor, not a callable method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07542ead",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183be1a",
   "metadata": {},
   "source": [
    "Think of a spreadsheet timestamp column where you add a helper column containing just the year.\n",
    "\n",
    "- Full timestamp stays in source.\n",
    "\n",
    "- Year becomes easy to group/filter.\n",
    "\n",
    "Labels remain aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef78e2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04801b0a",
   "metadata": {},
   "source": [
    "- Pandas decodes each datetime value into calendar fields.\n",
    "\n",
    "- It reads the year field for each row.\n",
    "\n",
    "- Extracted years are returned as a new Series with same index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06443033",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65f205",
   "metadata": {},
   "source": [
    "- Requires datetime-like dtype; string/object values must be parsed first.\n",
    "\n",
    "- Timezone conversions done earlier can shift year near boundaries.\n",
    "\n",
    "- Missing datetimes produce missing outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed25d53",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1817e9",
   "metadata": {},
   "source": [
    "- Is the column guaranteed datetime dtype before extraction?\n",
    "\n",
    "- Should timestamps be normalized to a specific timezone first?\n",
    "\n",
    "- Do missing timestamps need a fallback year value?\n",
    "\n",
    "- Is yearly grouping the right granularity for this task?\n",
    "\n",
    "- Are year boundaries validated for end-of-year events?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59665de",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb9953",
   "metadata": {},
   "source": [
    "Use `dt.year` to quickly derive year-level features from datetime Series without losing index alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d2f93",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create yearly cohorts from account signup timestamps for retention analysis.\n",
    "\n",
    "Scenario: each account keeps its original label while adding year information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "db13076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort year: {'u1': 2023, 'u2': 2024, 'u3': 2024}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signup_ts = pd.Series(pd.to_datetime([\"2023-11-10 09:00:00\", \"2024-02-01 12:30:00\", \"2024-12-31 23:59:00\"]), index=[\"u1\", \"u2\", \"u3\"], name=\"signup_ts\")\n",
    "cohort_year = signup_ts.dt.year\n",
    "print(\"Cohort year:\", cohort_year.to_dict())\n",
    "\n",
    "assert int(cohort_year.loc[\"u1\"]) == 2023\n",
    "assert int(cohort_year.loc[\"u3\"]) == 2024\n",
    "assert cohort_year.index.equals(signup_ts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6245539",
   "metadata": {},
   "source": [
    "##### Series.dt.month\n",
    "`dt.month` extracts month numbers (1-12) from datetime values. It is commonly used for seasonal analysis and calendar-based dashboards. The result is an index-aligned numeric Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "da6e3237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   2025-01-15\n",
       "b   2025-07-04\n",
       "c   2025-12-20\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-15\", \"2025-07-04\", \"2025-12-20\"]), index=[\"a\", \"b\", \"c\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "5155093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     1\n",
       "b     7\n",
       "c    12\n",
       "Name: ts, dtype: int32"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e724e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5b6c0",
   "metadata": {},
   "source": [
    "`series.dt.month` returns the month number for each datetime entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc366a0",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ce8bf",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.month` is a datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0bec2",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2c1a4",
   "metadata": {},
   "source": [
    "Think of extracting the month column from full dates in a spreadsheet.\n",
    "\n",
    "- January is 1, December is 12.\n",
    "\n",
    "- Great for seasonal grouping.\n",
    "\n",
    "No row relabeling occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd71728",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e328023",
   "metadata": {},
   "source": [
    "- Pandas parses each datetime into calendar components.\n",
    "\n",
    "- The month component is selected for each row.\n",
    "\n",
    "- Output stays aligned to the original index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077349ee",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e32b46",
   "metadata": {},
   "source": [
    "- Month numbers alone lose year context when spanning multiple years.\n",
    "\n",
    "- Datetime parsing must be correct before extraction.\n",
    "\n",
    "- Missing datetimes lead to missing month values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cda08e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca0029",
   "metadata": {},
   "source": [
    "- Do you need month only, or year-month for uniqueness?\n",
    "\n",
    "- Is source timezone/format standardized before extraction?\n",
    "\n",
    "- Are missing timestamps handled explicitly?\n",
    "\n",
    "- Should month names be derived later for reporting?\n",
    "\n",
    "- Could fiscal month logic differ from calendar month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333511f1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529d60f",
   "metadata": {},
   "source": [
    "Use `dt.month` for month-level seasonality features, and combine with year if uniqueness is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cabef3",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build monthly demand seasonality features from order timestamps.\n",
    "\n",
    "Scenario: each order row keeps its ID while month number is added for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "0c6f0571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order month: {'o1': 1, 'o2': 3, 'o3': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "order_ts = pd.Series(pd.to_datetime([\"2025-01-10\", \"2025-03-22\", \"2025-03-31\"]), index=[\"o1\", \"o2\", \"o3\"], name=\"order_ts\")\n",
    "order_month = order_ts.dt.month\n",
    "print(\"Order month:\", order_month.to_dict())\n",
    "\n",
    "assert int(order_month.loc[\"o1\"]) == 1\n",
    "assert int(order_month.loc[\"o2\"]) == 3\n",
    "assert int(order_month.loc[\"o3\"]) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb79b8b",
   "metadata": {},
   "source": [
    "##### Series.dt.day\n",
    "`dt.day` extracts the day-of-month component from each datetime. It is useful for billing cutoffs, month-end checks, and daily bucket features. Output stays aligned with original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "8db248d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1   2025-02-01\n",
       "d2   2025-02-15\n",
       "d3   2025-02-28\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-02-01\", \"2025-02-15\", \"2025-02-28\"]), index=[\"d1\", \"d2\", \"d3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "dc4f3070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1     1\n",
       "d2    15\n",
       "d3    28\n",
       "Name: date, dtype: int32"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6f3c6",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e3353",
   "metadata": {},
   "source": [
    "`series.dt.day` returns day-of-month numbers (1-31) for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5666d02",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e4e29",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.day` is a property accessor on datetime-like Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ff6b4",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84c793",
   "metadata": {},
   "source": [
    "Think of pulling only the day number from full dates in a spreadsheet.\n",
    "\n",
    "- Useful for month-cycle rules.\n",
    "\n",
    "- Keeps row identity unchanged.\n",
    "\n",
    "Simple daily extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c212e7",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8700fb",
   "metadata": {},
   "source": [
    "- Pandas decomposes each datetime into date parts.\n",
    "\n",
    "- It returns the day-of-month field per row.\n",
    "\n",
    "- Index alignment remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298853b5",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc397f8",
   "metadata": {},
   "source": [
    "- Day number alone is ambiguous without month/year context.\n",
    "\n",
    "- Leap-year and month-end edge cases still need business validation.\n",
    "\n",
    "- Missing timestamps propagate missing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb618179",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44907fc1",
   "metadata": {},
   "source": [
    "- Is day-of-month enough, or do you need full date keys?\n",
    "\n",
    "- Are month-end behaviors validated (28/29/30/31)?\n",
    "\n",
    "- Should timezone conversion happen before extraction?\n",
    "\n",
    "- Are missing timestamps expected?\n",
    "\n",
    "- Is this for filtering, grouping, or feature engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84680f2",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0a7ca",
   "metadata": {},
   "source": [
    "Use `dt.day` for day-of-month features, paired with month/year context when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1bd32",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Flag transactions occurring on month-end days for reconciliation workflows.\n",
    "\n",
    "Scenario: day extraction is a first step before month-end rule checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "3ba35006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of month: {'t1': 10, 't2': 28, 't3': 31}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txn_date = pd.Series(pd.to_datetime([\"2025-02-10\", \"2025-02-28\", \"2025-03-31\"]), index=[\"t1\", \"t2\", \"t3\"], name=\"txn_date\")\n",
    "day_num = txn_date.dt.day\n",
    "print(\"Day of month:\", day_num.to_dict())\n",
    "\n",
    "assert int(day_num.loc[\"t1\"]) == 10\n",
    "assert int(day_num.loc[\"t2\"]) == 28\n",
    "assert int(day_num.loc[\"t3\"]) == 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a41c09",
   "metadata": {},
   "source": [
    "##### Series.dt.hour\n",
    "`dt.hour` extracts hour-of-day (0-23) from timestamp values. It is useful for intraday traffic, load, or operational pattern analysis. The output is a numeric Series with the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "d7555a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h1   2025-01-01 00:10:00\n",
       "h2   2025-01-01 13:45:00\n",
       "h3   2025-01-01 23:59:59\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 00:10:00\", \"2025-01-01 13:45:00\", \"2025-01-01 23:59:59\"]), index=[\"h1\", \"h2\", \"h3\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "3c98969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h1     0\n",
       "h2    13\n",
       "h3    23\n",
       "Name: ts, dtype: int32"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549764f6",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c3b72",
   "metadata": {},
   "source": [
    "`series.dt.hour` returns the hour component for each timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2132b5d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c45a3",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.hour` is a datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc02409",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f9aff",
   "metadata": {},
   "source": [
    "Think of deriving an hour bucket from each timestamp in a spreadsheet log.\n",
    "\n",
    "- Midnight is 0.\n",
    "\n",
    "- 1 PM is 13.\n",
    "\n",
    "Useful for hourly behavior charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9138a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6063699",
   "metadata": {},
   "source": [
    "- Pandas reads each timestamp and extracts hour field.\n",
    "\n",
    "- Hour values are returned at the same row labels.\n",
    "\n",
    "- No resampling or aggregation is performed automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce03abf",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7cd192",
   "metadata": {},
   "source": [
    "- Hour interpretation depends on timezone correctness.\n",
    "\n",
    "- Extracted hour alone loses date context.\n",
    "\n",
    "- Missing timestamps yield missing hour outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8efe2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272339a",
   "metadata": {},
   "source": [
    "- Are timestamps converted to business timezone before extracting hour?\n",
    "\n",
    "- Do you need hour as category bins afterward?\n",
    "\n",
    "- Is date context preserved elsewhere in the pipeline?\n",
    "\n",
    "- Are null timestamps handled?\n",
    "\n",
    "- Could daylight-saving transitions impact analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb62df5",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55bf2b",
   "metadata": {},
   "source": [
    "Use `dt.hour` to build intraday features once timezone and null-handling rules are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741d735",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Analyze peak customer-support message volume by hour of day.\n",
    "\n",
    "Scenario: timestamps are already standardized to local support timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "d37e3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour bucket: {'m1': 8, 'm2': 14, 'm3': 21}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "msg_ts = pd.Series(pd.to_datetime([\"2025-05-01 08:15:00\", \"2025-05-01 14:05:00\", \"2025-05-01 21:30:00\"]), index=[\"m1\", \"m2\", \"m3\"], name=\"msg_ts\")\n",
    "hour_bucket = msg_ts.dt.hour\n",
    "print(\"Hour bucket:\", hour_bucket.to_dict())\n",
    "\n",
    "assert int(hour_bucket.loc[\"m1\"]) == 8\n",
    "assert int(hour_bucket.loc[\"m2\"]) == 14\n",
    "assert int(hour_bucket.loc[\"m3\"]) == 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411bfe7",
   "metadata": {},
   "source": [
    "##### Series.dt.minute\n",
    "`dt.minute` extracts minute-of-hour (0-59) from each timestamp. It is useful for fine-grained operational diagnostics and temporal feature creation. Index alignment is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "e8aeb5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m1   2025-01-01 10:05:00\n",
       "m2   2025-01-01 10:30:45\n",
       "m3   2025-01-01 10:59:59\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 10:05:00\", \"2025-01-01 10:30:45\", \"2025-01-01 10:59:59\"]), index=[\"m1\", \"m2\", \"m3\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "7e474ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m1     5\n",
       "m2    30\n",
       "m3    59\n",
       "Name: ts, dtype: int32"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef660106",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56b48e",
   "metadata": {},
   "source": [
    "`series.dt.minute` returns minute values from each datetime entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96d8a0",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e791e5b",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.minute` is a datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2dd45",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fae817",
   "metadata": {},
   "source": [
    "Think of taking only minute values from timestamped rows in a spreadsheet.\n",
    "\n",
    "- Helps detect periodic minute patterns.\n",
    "\n",
    "- Keeps row mapping unchanged.\n",
    "\n",
    "Simple fine-grain extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bfefa",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b96755",
   "metadata": {},
   "source": [
    "- Pandas parses each timestamp into time components.\n",
    "\n",
    "- The minute component is emitted per row.\n",
    "\n",
    "- Output Series retains original index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e963111",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91694e",
   "metadata": {},
   "source": [
    "- Minute feature without hour/date context may be misleading.\n",
    "\n",
    "- Timezone shifts can alter minute values near conversions.\n",
    "\n",
    "- Missing timestamps produce missing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7847f",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a754798",
   "metadata": {},
   "source": [
    "- Do you also need hour/day context with minute values?\n",
    "\n",
    "- Are timestamps timezone-normalized before extraction?\n",
    "\n",
    "- Is minute-level granularity useful for the target metric?\n",
    "\n",
    "- How are null timestamps handled?\n",
    "\n",
    "- Could batching artifacts create fake minute patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a9f8f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb93ddd",
   "metadata": {},
   "source": [
    "Use `dt.minute` for fine-grained time features, paired with broader time context when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb2fbb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Inspect API request timing clusters at minute granularity for scheduler diagnostics.\n",
    "\n",
    "Scenario: operations team wants to detect bursts at specific minute marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "1625c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minute part: {'r1': 5, 'r2': 15, 'r3': 45}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "req_ts = pd.Series(pd.to_datetime([\"2025-07-01 09:05:10\", \"2025-07-01 09:15:50\", \"2025-07-01 09:45:00\"]), index=[\"r1\", \"r2\", \"r3\"], name=\"req_ts\")\n",
    "minute_part = req_ts.dt.minute\n",
    "print(\"Minute part:\", minute_part.to_dict())\n",
    "\n",
    "assert int(minute_part.loc[\"r1\"]) == 5\n",
    "assert int(minute_part.loc[\"r2\"]) == 15\n",
    "assert int(minute_part.loc[\"r3\"]) == 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef73af",
   "metadata": {},
   "source": [
    "##### Series.dt.second\n",
    "`dt.second` extracts second-of-minute (0-59) from datetime values. It is useful for high-resolution event sequencing and QA checks on timestamp precision. Output is a label-aligned numeric Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "35f246dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1   2025-01-01 10:00:05\n",
       "s2   2025-01-01 10:00:30\n",
       "s3   2025-01-01 10:00:59\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 10:00:05\", \"2025-01-01 10:00:30\", \"2025-01-01 10:00:59\"]), index=[\"s1\", \"s2\", \"s3\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "036afd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1     5\n",
       "s2    30\n",
       "s3    59\n",
       "Name: ts, dtype: int32"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878e128",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155a3fe",
   "metadata": {},
   "source": [
    "`series.dt.second` returns second values for each timestamp row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24ee31",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9fa63",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.second` is a datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c8525",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d47559",
   "metadata": {},
   "source": [
    "Think of extracting the seconds field from clock times in a spreadsheet log.\n",
    "\n",
    "- Useful for precision checks.\n",
    "\n",
    "- No row movement occurs.\n",
    "\n",
    "It isolates sub-minute timing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f7d96",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc4ec2",
   "metadata": {},
   "source": [
    "- Pandas decodes timestamp time fields.\n",
    "\n",
    "- It returns the second component per row label.\n",
    "\n",
    "- Output keeps index alignment intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979763f",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b166665",
   "metadata": {},
   "source": [
    "- Second values alone lose minute/hour/date context.\n",
    "\n",
    "- Not useful if source timestamps are only minute-level precision.\n",
    "\n",
    "- Missing datetimes propagate missing output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27454a66",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fc39c",
   "metadata": {},
   "source": [
    "- Does source data actually contain second-level precision?\n",
    "\n",
    "- Should seconds be combined with higher-level time fields?\n",
    "\n",
    "- Are null timestamps expected?\n",
    "\n",
    "- Is timezone conversion applied beforehand?\n",
    "\n",
    "- Are extracted seconds used for QA or modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cf700",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21151205",
   "metadata": {},
   "source": [
    "Use `dt.second` to inspect or engineer sub-minute timing features when timestamp precision supports it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744937c9",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate whether IoT events are arriving with second-level timestamp precision as expected.\n",
    "\n",
    "Scenario: ingestion QA checks second distribution before downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "efe900ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second part: {'e1': 5, 'e2': 30, 'e3': 59}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iot_ts = pd.Series(pd.to_datetime([\"2025-08-01 12:00:05\", \"2025-08-01 12:00:30\", \"2025-08-01 12:00:59\"]), index=[\"e1\", \"e2\", \"e3\"], name=\"iot_ts\")\n",
    "sec = iot_ts.dt.second\n",
    "print(\"Second part:\", sec.to_dict())\n",
    "\n",
    "assert int(sec.loc[\"e1\"]) == 5\n",
    "assert int(sec.loc[\"e2\"]) == 30\n",
    "assert int(sec.loc[\"e3\"]) == 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75eb61",
   "metadata": {},
   "source": [
    "##### Series.dt.weekday\n",
    "`dt.weekday` extracts day-of-week as integers where Monday=0 and Sunday=6. It is useful for weekday/weekend features and operational scheduling analysis. The result is index-aligned and easy to filter/group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "b7803ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w1   2025-01-06\n",
       "w2   2025-01-07\n",
       "w3   2025-01-12\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-06\", \"2025-01-07\", \"2025-01-12\"]), index=[\"w1\", \"w2\", \"w3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "45c69e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w1    0\n",
       "w2    1\n",
       "w3    6\n",
       "Name: date, dtype: int32"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bd95c",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce517132",
   "metadata": {},
   "source": [
    "`series.dt.weekday` gives weekday numbers (Mon=0 ... Sun=6) for each datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b5c91",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217d493",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.weekday` is a datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f3831",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d318c",
   "metadata": {},
   "source": [
    "Think of adding a weekday-number helper column next to each date in a spreadsheet.\n",
    "\n",
    "- Monday starts at 0.\n",
    "\n",
    "- Sunday is 6.\n",
    "\n",
    "Useful for workday vs weekend logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f54c9",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ea517c",
   "metadata": {},
   "source": [
    "- Pandas maps each date to its calendar weekday integer.\n",
    "\n",
    "- Weekday values are returned with original labels preserved.\n",
    "\n",
    "- You can build boolean masks like weekend/weekday directly from this output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ed1f2",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acedf0b",
   "metadata": {},
   "source": [
    "- Numeric encoding can be misread if mapping is not documented.\n",
    "\n",
    "- Locale/business calendars may differ (holidays not captured).\n",
    "\n",
    "- Datetime dtype and timezone assumptions still matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31558c2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbdbf6",
   "metadata": {},
   "source": [
    "- Is Monday=0 convention clear to downstream users?\n",
    "\n",
    "- Do you need holiday calendars beyond simple weekday numbers?\n",
    "\n",
    "- Are timezone conversions finalized before extraction?\n",
    "\n",
    "- Should weekend flags be derived immediately after weekday extraction?\n",
    "\n",
    "- Are null timestamps handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31115bde",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329b49c",
   "metadata": {},
   "source": [
    "Use `dt.weekday` for fast weekday features, and document the Monday=0 convention clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a19c82",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build a weekend traffic flag from event dates for staffing forecasts.\n",
    "\n",
    "Scenario: Saturday/Sunday events need separate operational treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "33ab9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday number: {'d1': 4, 'd2': 5, 'd3': 6}\n",
      "Weekend flag: {'d1': False, 'd2': True, 'd3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "event_date = pd.Series(pd.to_datetime([\"2025-01-10\", \"2025-01-11\", \"2025-01-12\"]), index=[\"d1\", \"d2\", \"d3\"], name=\"event_date\")\n",
    "weekday_num = event_date.dt.weekday\n",
    "is_weekend = weekday_num >= 5\n",
    "print(\"Weekday number:\", weekday_num.to_dict())\n",
    "print(\"Weekend flag:\", is_weekend.to_dict())\n",
    "\n",
    "assert int(weekday_num.loc[\"d1\"]) == 4\n",
    "assert bool(is_weekend.loc[\"d2\"]) is True\n",
    "assert bool(is_weekend.loc[\"d3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e90bc0",
   "metadata": {},
   "source": [
    "##### Series.dt.isocalendar()\n",
    "`dt.isocalendar()` returns ISO calendar components (`year`, `week`, `day`) for each datetime row. It is useful for ISO week-based reporting where week boundaries differ from simple calendar year logic. The result is a DataFrame aligned to the Series index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "0325b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1   2024-12-30\n",
       "d2   2025-01-01\n",
       "d3   2025-01-05\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2024-12-30\", \"2025-01-01\", \"2025-01-05\"]), index=[\"d1\", \"d2\", \"d3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "4e54126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  week  day\n",
       "d1  2025     1    1\n",
       "d2  2025     1    3\n",
       "d3  2025     1    7"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.isocalendar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e8814",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ffd85a",
   "metadata": {},
   "source": [
    "`series.dt.isocalendar()` gives ISO year/week/day fields for each date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd97be",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95640f54",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.isocalendar()` takes no parameters and returns a DataFrame with ISO components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfeefc3",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7200f04",
   "metadata": {},
   "source": [
    "Think of adding three helper columns in a spreadsheet: ISO year, ISO week, and ISO weekday.\n",
    "\n",
    "- Useful near year boundaries.\n",
    "\n",
    "- Labels stay aligned to original rows.\n",
    "\n",
    "You get week-based calendar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcaab4",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f727f",
   "metadata": {},
   "source": [
    "- Pandas maps each datetime to ISO-8601 calendar rules.\n",
    "\n",
    "- It computes ISO year, week number, and weekday for each row.\n",
    "\n",
    "- Output is a DataFrame indexed exactly like the source Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df25c5b",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2838ddd",
   "metadata": {},
   "source": [
    "- ISO week-year can differ from calendar year near Jan/Dec boundaries.\n",
    "\n",
    "- Output is a DataFrame, not a Series, so downstream code shape changes.\n",
    "\n",
    "- Datetime dtype parsing must be correct before extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478caf4a",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9f377",
   "metadata": {},
   "source": [
    "- Do stakeholders expect ISO weeks or calendar weeks?\n",
    "\n",
    "- Is ISO year difference near boundaries communicated clearly?\n",
    "\n",
    "- Which ISO component (`week`, `year`, `day`) is needed downstream?\n",
    "\n",
    "- Are timezone conversions finalized before extraction?\n",
    "\n",
    "- Is DataFrame output shape handled explicitly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bc9b8",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22888246",
   "metadata": {},
   "source": [
    "Use `dt.isocalendar()` when you need ISO week logic and explicit week-year/day components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77641e8",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build ISO-week dashboards where the first week can start in late December.\n",
    "\n",
    "Scenario: operations reports are planned by ISO week, not by calendar month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "a35b2948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  week  day\n",
      "e1  2025     1    1\n",
      "e2  2025     1    3\n",
      "e3  2025     2    1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "event_date = pd.Series(pd.to_datetime([\"2024-12-30\", \"2025-01-01\", \"2025-01-06\"]), index=[\"e1\", \"e2\", \"e3\"], name=\"event_date\")\n",
    "iso = event_date.dt.isocalendar()\n",
    "print(iso)\n",
    "\n",
    "assert int(iso.loc[\"e1\", \"year\"]) == 2025\n",
    "assert int(iso.loc[\"e2\", \"week\"]) == 1\n",
    "assert int(iso.loc[\"e3\", \"day\"]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335bd0d",
   "metadata": {},
   "source": [
    "##### Series.dt.is_month_start\n",
    "`dt.is_month_start` returns booleans indicating whether each timestamp falls on the first calendar day of its month. It is useful for monthly reset logic and cycle-begin flags. Output is index-aligned for easy filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "1b760a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   2025-02-01\n",
       "b   2025-02-02\n",
       "c   2025-03-01\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-02-01\", \"2025-02-02\", \"2025-03-01\"]), index=[\"a\", \"b\", \"c\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "2ad71f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b    False\n",
       "c     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_month_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d727d6",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f25c5",
   "metadata": {},
   "source": [
    "`series.dt.is_month_start` marks True on dates that are the first day of a month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389cedf",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430fb87",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_month_start` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92013d69",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da88824",
   "metadata": {},
   "source": [
    "Think of highlighting spreadsheet rows that start a new month.\n",
    "\n",
    "- First-day rows are flagged.\n",
    "\n",
    "- Others remain False.\n",
    "\n",
    "Useful for reset checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ddddb",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d532f16",
   "metadata": {},
   "source": [
    "- Pandas evaluates each date against calendar month boundaries.\n",
    "\n",
    "- It returns `True` when day-of-month equals 1.\n",
    "\n",
    "- Booleans keep original index mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e342cb",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f3690",
   "metadata": {},
   "source": [
    "- Business fiscal calendars may differ from calendar month starts.\n",
    "\n",
    "- Timezone conversions around boundaries can affect day assignment.\n",
    "\n",
    "- Requires valid datetime-like dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e004d2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df991135",
   "metadata": {},
   "source": [
    "- Do you need calendar month start or fiscal period start?\n",
    "\n",
    "- Is timezone normalized before boundary checks?\n",
    "\n",
    "- Are missing timestamps handled?\n",
    "\n",
    "- Will this flag drive automation resets?\n",
    "\n",
    "- Are month-start definitions documented for users?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0f64f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ce045",
   "metadata": {},
   "source": [
    "Use `dt.is_month_start` for calendar-month boundary flags in monitoring and scheduling logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc13e7",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Trigger monthly quota resets only on first-day records in transaction logs.\n",
    "\n",
    "Scenario: pipeline should run reset logic exactly at calendar month start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "9891a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month-start flag: {'t1': True, 't2': False, 't3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txn_date = pd.Series(pd.to_datetime([\"2025-02-01\", \"2025-02-15\", \"2025-03-01\"]), index=[\"t1\", \"t2\", \"t3\"], name=\"txn_date\")\n",
    "is_start = txn_date.dt.is_month_start\n",
    "print(\"Month-start flag:\", is_start.to_dict())\n",
    "\n",
    "assert bool(is_start.loc[\"t1\"]) is True\n",
    "assert bool(is_start.loc[\"t2\"]) is False\n",
    "assert bool(is_start.loc[\"t3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c023a4",
   "metadata": {},
   "source": [
    "##### Series.dt.is_month_end\n",
    "`dt.is_month_end` returns booleans for dates that are the last calendar day of a month. It is useful for month-end close, billing, and reconciliation checks. Result labels remain aligned to source rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "6444a39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   2025-02-27\n",
       "x2   2025-02-28\n",
       "x3   2025-03-31\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-02-27\", \"2025-02-28\", \"2025-03-31\"]), index=[\"x1\", \"x2\", \"x3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "4cf14c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    False\n",
       "x2     True\n",
       "x3     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_month_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b5199",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f732df",
   "metadata": {},
   "source": [
    "`series.dt.is_month_end` marks True on dates that are month-ending days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca039d",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cc3a8",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_month_end` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2e2d3",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6c53e",
   "metadata": {},
   "source": [
    "Think of flagging month-closing rows in a spreadsheet.\n",
    "\n",
    "- Last day entries are highlighted.\n",
    "\n",
    "- Others stay unflagged.\n",
    "\n",
    "Great for closing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4544b9b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d19378",
   "metadata": {},
   "source": [
    "- Pandas compares each date to that month?s final day.\n",
    "\n",
    "- It emits boolean flags per row.\n",
    "\n",
    "- Output preserves input index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca98eb1",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7246b",
   "metadata": {},
   "source": [
    "- Leap years change February month-end behavior.\n",
    "\n",
    "- Calendar month-end may differ from business close calendars.\n",
    "\n",
    "- Datetime parsing/timezone errors can misflag boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac94850",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1339a",
   "metadata": {},
   "source": [
    "- Is calendar month-end the right business boundary?\n",
    "\n",
    "- Are leap-year edge cases tested?\n",
    "\n",
    "- Should timezone conversion occur before flags?\n",
    "\n",
    "- How are null timestamps treated?\n",
    "\n",
    "- Will this flag drive financial close automation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3d9a1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b8e0a",
   "metadata": {},
   "source": [
    "Use `dt.is_month_end` to identify calendar month-close rows for billing and reconciliation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619750d",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Select month-end account snapshots for finance close reporting.\n",
    "\n",
    "Scenario: only last-day balances should feed the month-close table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "56414c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month-end flag: {'b1': False, 'b2': True, 'b3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "balance_date = pd.Series(pd.to_datetime([\"2025-01-30\", \"2025-01-31\", \"2025-02-28\"]), index=[\"b1\", \"b2\", \"b3\"], name=\"balance_date\")\n",
    "is_end = balance_date.dt.is_month_end\n",
    "print(\"Month-end flag:\", is_end.to_dict())\n",
    "\n",
    "assert bool(is_end.loc[\"b1\"]) is False\n",
    "assert bool(is_end.loc[\"b2\"]) is True\n",
    "assert bool(is_end.loc[\"b3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1443e",
   "metadata": {},
   "source": [
    "##### Series.dt.is_quarter_start\n",
    "`dt.is_quarter_start` flags dates that are at the beginning of calendar quarters. It is useful for quarterly KPI resets and reporting period transitions. Output is a boolean Series with unchanged index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "77aeebf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1   2025-01-01\n",
       "q2   2025-02-01\n",
       "q3   2025-04-01\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01\", \"2025-02-01\", \"2025-04-01\"]), index=[\"q1\", \"q2\", \"q3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "b4499d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1     True\n",
       "q2    False\n",
       "q3     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_quarter_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294834e",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfea91b",
   "metadata": {},
   "source": [
    "`series.dt.is_quarter_start` marks rows that land on quarter-opening dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ee85c",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99563f8",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_quarter_start` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3cb3e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195de417",
   "metadata": {},
   "source": [
    "Think of marking rows where a new quarter begins in a calendar sheet.\n",
    "\n",
    "- Quarter-open rows are True.\n",
    "\n",
    "- Other dates are False.\n",
    "\n",
    "Useful for quarter-cycle logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977ace9",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0608d4",
   "metadata": {},
   "source": [
    "- Pandas checks each date against quarter boundary rules (Jan/Apr/Jul/Oct starts).\n",
    "\n",
    "- It emits boolean flags per row.\n",
    "\n",
    "- Flags remain aligned to original index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ff6ca",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7306b76",
   "metadata": {},
   "source": [
    "- Fiscal quarters may not match calendar quarters.\n",
    "\n",
    "- Timezone/date normalization can affect boundary-day interpretation.\n",
    "\n",
    "- Missing datetimes propagate missing/False-like behavior depending dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d89b5",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7d5ec",
   "metadata": {},
   "source": [
    "- Are you using calendar quarters or custom fiscal quarters?\n",
    "\n",
    "- Is timezone conversion finalized before flags?\n",
    "\n",
    "- Should quarter-start drive automation triggers?\n",
    "\n",
    "- Are quarter boundary dates validated in tests?\n",
    "\n",
    "- How are missing timestamps handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13139f15",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b524565",
   "metadata": {},
   "source": [
    "Use `dt.is_quarter_start` for calendar-quarter boundary flags; adapt separately for fiscal calendars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a832a",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Trigger quarterly budget reset jobs only on quarter-start transaction dates.\n",
    "\n",
    "Scenario: jobs should run on Jan 1, Apr 1, Jul 1, and Oct 1 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "c7a76ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter-start flag: {'d1': True, 'd2': False, 'd3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txn_date = pd.Series(pd.to_datetime([\"2025-01-01\", \"2025-03-31\", \"2025-04-01\"]), index=[\"d1\", \"d2\", \"d3\"], name=\"txn_date\")\n",
    "is_q_start = txn_date.dt.is_quarter_start\n",
    "print(\"Quarter-start flag:\", is_q_start.to_dict())\n",
    "\n",
    "assert bool(is_q_start.loc[\"d1\"]) is True\n",
    "assert bool(is_q_start.loc[\"d2\"]) is False\n",
    "assert bool(is_q_start.loc[\"d3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f626cd",
   "metadata": {},
   "source": [
    "##### Series.dt.is_quarter_end\n",
    "`dt.is_quarter_end` flags dates that are the final day of a calendar quarter. It is useful for quarter-close snapshots and compliance reporting checkpoints. The output is a boolean mask aligned to the original index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "952954f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2025-03-30\n",
       "e2   2025-03-31\n",
       "e3   2025-06-30\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-03-30\", \"2025-03-31\", \"2025-06-30\"]), index=[\"e1\", \"e2\", \"e3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "1018ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1    False\n",
       "e2     True\n",
       "e3     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_quarter_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc88c27",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bfb7a",
   "metadata": {},
   "source": [
    "`series.dt.is_quarter_end` marks True on quarter-closing dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e87630",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7094f6",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_quarter_end` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264407b6",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88185253",
   "metadata": {},
   "source": [
    "Think of flagging quarter-close rows in a spreadsheet before final reporting.\n",
    "\n",
    "- Closing dates are True.\n",
    "\n",
    "- Intermediate dates are False.\n",
    "\n",
    "Useful for quarter-end extracts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb32acf",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fd102",
   "metadata": {},
   "source": [
    "- Pandas compares each date to calendar quarter-end boundaries.\n",
    "\n",
    "- It emits booleans indicating quarter-close rows.\n",
    "\n",
    "- Index mapping remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9cab7d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5a1aa",
   "metadata": {},
   "source": [
    "- Fiscal-quarter close may differ from calendar quarter-end.\n",
    "\n",
    "- Incorrect timezone/date handling can misclassify boundary rows.\n",
    "\n",
    "- Requires valid datetime dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279414e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef04df",
   "metadata": {},
   "source": [
    "- Do you need calendar or fiscal quarter-end logic?\n",
    "\n",
    "- Are quarter-end dates validated for each year?\n",
    "\n",
    "- Should this flag feed financial close controls?\n",
    "\n",
    "- Is timezone already standardized?\n",
    "\n",
    "- How are null timestamps handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b8b8f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb31d04",
   "metadata": {},
   "source": [
    "Use `dt.is_quarter_end` to isolate calendar quarter-close rows for reporting and controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e39750",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Extract quarter-end account balances for regulatory reports.\n",
    "\n",
    "Scenario: only records dated exactly at quarter close are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "92511f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter-end flag: {'s1': True, 's2': False, 's3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "snapshot_date = pd.Series(pd.to_datetime([\"2025-03-31\", \"2025-04-01\", \"2025-06-30\"]), index=[\"s1\", \"s2\", \"s3\"], name=\"snapshot_date\")\n",
    "is_q_end = snapshot_date.dt.is_quarter_end\n",
    "print(\"Quarter-end flag:\", is_q_end.to_dict())\n",
    "\n",
    "assert bool(is_q_end.loc[\"s1\"]) is True\n",
    "assert bool(is_q_end.loc[\"s2\"]) is False\n",
    "assert bool(is_q_end.loc[\"s3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe72fa5",
   "metadata": {},
   "source": [
    "##### Series.dt.is_year_start\n",
    "`dt.is_year_start` flags dates that fall on January 1st in calendar-year logic. It is useful for annual reset signals, YTD initialization, and year-boundary checks. Result is a boolean Series aligned to the source index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "fb15805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y1   2025-01-01\n",
       "y2   2025-01-02\n",
       "y3   2026-01-01\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01\", \"2025-01-02\", \"2026-01-01\"]), index=[\"y1\", \"y2\", \"y3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "0e4be4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y1     True\n",
       "y2    False\n",
       "y3     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_year_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f00a8d",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf735f7c",
   "metadata": {},
   "source": [
    "`series.dt.is_year_start` marks True when a date is the first day of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4986f64",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a98230",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_year_start` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee95d34",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d319e",
   "metadata": {},
   "source": [
    "Think of identifying New Year rows in a spreadsheet timeline.\n",
    "\n",
    "- Jan 1 rows are flagged.\n",
    "\n",
    "- Other days are not.\n",
    "\n",
    "Useful for annual resets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcabe8",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f7c39",
   "metadata": {},
   "source": [
    "- Pandas checks each date against calendar year start boundary.\n",
    "\n",
    "- It emits boolean flags per row.\n",
    "\n",
    "- Flags keep same index as original Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862e382",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44da815",
   "metadata": {},
   "source": [
    "- Fiscal-year start may not be January 1.\n",
    "\n",
    "- Timezone normalization can affect boundary-date assignment.\n",
    "\n",
    "- Missing datetimes require explicit handling policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd898cb1",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1daac6",
   "metadata": {},
   "source": [
    "- Is calendar year start the intended business boundary?\n",
    "\n",
    "- Do you need fiscal-year logic instead?\n",
    "\n",
    "- Should year-start flags trigger resets in code?\n",
    "\n",
    "- Are timezone assumptions fixed?\n",
    "\n",
    "- Are null dates expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277c658",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b704498",
   "metadata": {},
   "source": [
    "Use `dt.is_year_start` for calendar-year reset flags; customize separately for fiscal years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f3831",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Initialize yearly KPI accumulators only on first-day records.\n",
    "\n",
    "Scenario: annual metrics reset at calendar year start in reporting pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "b45e92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-start flag: {'m1': True, 'm2': False, 'm3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metric_date = pd.Series(pd.to_datetime([\"2025-01-01\", \"2025-01-15\", \"2026-01-01\"]), index=[\"m1\", \"m2\", \"m3\"], name=\"metric_date\")\n",
    "is_y_start = metric_date.dt.is_year_start\n",
    "print(\"Year-start flag:\", is_y_start.to_dict())\n",
    "\n",
    "assert bool(is_y_start.loc[\"m1\"]) is True\n",
    "assert bool(is_y_start.loc[\"m2\"]) is False\n",
    "assert bool(is_y_start.loc[\"m3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7fb052",
   "metadata": {},
   "source": [
    "##### Series.dt.is_year_end\n",
    "`dt.is_year_end` flags dates that are the final day of the calendar year (December 31). It is useful for year-end snapshots, closing entries, and annual reporting extracts. Output is a boolean Series aligned to input labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "36abcaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z1   2025-12-30\n",
       "z2   2025-12-31\n",
       "z3   2026-12-31\n",
       "Name: date, dtype: datetime64[us]"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-12-30\", \"2025-12-31\", \"2026-12-31\"]), index=[\"z1\", \"z2\", \"z3\"], name=\"date\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "d7dabaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z1    False\n",
       "z2     True\n",
       "z3     True\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.is_year_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e0e38",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977b649",
   "metadata": {},
   "source": [
    "`series.dt.is_year_end` marks True when a date is December 31st."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88abad",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94b42d",
   "metadata": {},
   "source": [
    "- `(none)`: `dt.is_year_end` is a boolean datetime property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a4c06",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123719b3",
   "metadata": {},
   "source": [
    "Think of marking final-day-of-year rows in a spreadsheet for annual close tasks.\n",
    "\n",
    "- Dec 31 rows are flagged.\n",
    "\n",
    "- Other dates remain False.\n",
    "\n",
    "Easy year-end filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab7f93",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f43d66",
   "metadata": {},
   "source": [
    "- Pandas checks whether each date equals calendar year-end boundary.\n",
    "\n",
    "- It outputs boolean flags at matching labels.\n",
    "\n",
    "- Source index alignment is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac3844",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942197c",
   "metadata": {},
   "source": [
    "- Fiscal-year end may differ from Dec 31.\n",
    "\n",
    "- Boundary accuracy depends on valid datetime parsing/timezone setup.\n",
    "\n",
    "- Missing dates require downstream handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71205d52",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5007d5",
   "metadata": {},
   "source": [
    "- Is calendar year-end the correct reporting boundary?\n",
    "\n",
    "- Are fiscal-year close dates different in your domain?\n",
    "\n",
    "- Should this flag control year-end extract logic?\n",
    "\n",
    "- Are timezone conversions finalized first?\n",
    "\n",
    "- Are null dates possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae1a17",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa4944",
   "metadata": {},
   "source": [
    "Use `dt.is_year_end` to identify calendar year-close rows for annual reporting workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8863b45",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Select year-end portfolio snapshots for annual performance reporting.\n",
    "\n",
    "Scenario: only Dec 31 observations should feed year-close metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "20064f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-end flag: {'p1': True, 'p2': False, 'p3': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "portfolio_date = pd.Series(pd.to_datetime([\"2025-12-31\", \"2026-01-01\", \"2026-12-31\"]), index=[\"p1\", \"p2\", \"p3\"], name=\"portfolio_date\")\n",
    "is_y_end = portfolio_date.dt.is_year_end\n",
    "print(\"Year-end flag:\", is_y_end.to_dict())\n",
    "\n",
    "assert bool(is_y_end.loc[\"p1\"]) is True\n",
    "assert bool(is_y_end.loc[\"p2\"]) is False\n",
    "assert bool(is_y_end.loc[\"p3\"]) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bf4e7",
   "metadata": {},
   "source": [
    "##### Series.dt.tz_localize(tz)\n",
    "`dt.tz_localize(tz)` attaches a timezone to naive datetime values without changing clock times. It is used to mark local timestamps as timezone-aware before cross-region operations. This step is often required before safe timezone conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "8f485e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2025-01-01 09:00:00\n",
       "e2   2025-01-01 17:30:00\n",
       "Name: event_ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 09:00:00\", \"2025-01-01 17:30:00\"]), index=[\"e1\", \"e2\"], name=\"event_ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "b382c0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2025-01-01 09:00:00+00:00\n",
       "e2   2025-01-01 17:30:00+00:00\n",
       "Name: event_ts, dtype: datetime64[us, UTC]"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf675ed",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b6e27",
   "metadata": {},
   "source": [
    "`series.dt.tz_localize(tz)` tags naive times with a timezone, keeping wall-clock values unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17cf20",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f47d0",
   "metadata": {},
   "source": [
    "- `tz` (timezone string/tzinfo): timezone to attach to naive timestamps.\n",
    "\n",
    "- `ambiguous` (default `\"raise\"`): how to handle ambiguous times (DST fall-back).\n",
    "\n",
    "- `nonexistent` (default `\"raise\"`): how to handle nonexistent times (DST spring-forward)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a00cd",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862912e",
   "metadata": {},
   "source": [
    "Think of writing the timezone label on a spreadsheet time column that previously had no zone info.\n",
    "\n",
    "- Clock numbers stay the same.\n",
    "\n",
    "- Timezone context is added.\n",
    "\n",
    "Now times become globally interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610ba71",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376cf70",
   "metadata": {},
   "source": [
    "- Pandas treats input timestamps as naive local times.\n",
    "\n",
    "- It attaches timezone metadata specified by `tz`.\n",
    "\n",
    "- Underlying instant interpretation becomes timezone-aware for later conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cccf90",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20a0a7",
   "metadata": {},
   "source": [
    "- Applying to already-aware timestamps raises errors.\n",
    "\n",
    "- DST-ambiguous/nonexistent times need explicit handling strategy.\n",
    "\n",
    "- Wrong localization timezone causes downstream time drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a47ca",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a812d",
   "metadata": {},
   "source": [
    "- Are timestamps truly naive before localizing?\n",
    "\n",
    "- Which timezone represents source-system clock time?\n",
    "\n",
    "- How should DST ambiguous/nonexistent times be handled?\n",
    "\n",
    "- Do you localize before any filtering/windowing?\n",
    "\n",
    "- Is timezone assumption documented for data lineage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac914034",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd50a3",
   "metadata": {},
   "source": [
    "Use `dt.tz_localize` to add correct timezone context to naive timestamps before global analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38cacc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Localize ingestion timestamps to UTC before merging events from multiple regions.\n",
    "\n",
    "Scenario: source logs are naive but known to be UTC clock times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "6e0fa0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1   2025-01-01 09:00:00+00:00\n",
      "r2   2025-01-01 17:30:00+00:00\n",
      "Name: ingest_ts, dtype: datetime64[us, UTC]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ingest_ts = pd.Series(pd.to_datetime([\"2025-01-01 09:00:00\", \"2025-01-01 17:30:00\"]), index=[\"r1\", \"r2\"], name=\"ingest_ts\")\n",
    "utc_ts = ingest_ts.dt.tz_localize(\"UTC\")\n",
    "print(utc_ts)\n",
    "\n",
    "assert str(utc_ts.dtype).endswith(\"UTC]\")\n",
    "assert utc_ts.loc[\"r1\"].hour == 9\n",
    "assert utc_ts.index.equals(ingest_ts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62251b4",
   "metadata": {},
   "source": [
    "##### Series.dt.tz_convert(tz)\n",
    "`dt.tz_convert(tz)` converts timezone-aware timestamps to another timezone, preserving the absolute instant in time. It is essential for localized reporting and operational dashboards. This requires input timestamps that are already timezone-aware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "fc96ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2025-01-01 12:00:00+00:00\n",
       "e2   2025-01-01 18:00:00+00:00\n",
       "Name: event_ts, dtype: datetime64[us, UTC]"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 12:00:00\", \"2025-01-01 18:00:00\"]), index=[\"e1\", \"e2\"], name=\"event_ts\").dt.tz_localize(\"UTC\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "3ef5062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1   2025-01-01 13:00:00+01:00\n",
       "e2   2025-01-01 19:00:00+01:00\n",
       "Name: event_ts, dtype: datetime64[us, UTC+01:00]"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.tz_convert(\"+01:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498141f",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf176a",
   "metadata": {},
   "source": [
    "`series.dt.tz_convert(tz)` shifts display timezone while keeping the same absolute moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b11a9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92012541",
   "metadata": {},
   "source": [
    "- `tz` (timezone string/tzinfo): target timezone for conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a52295",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8427e41",
   "metadata": {},
   "source": [
    "Think of converting a UTC schedule column into local office time in a spreadsheet.\n",
    "\n",
    "- Same real event instant.\n",
    "\n",
    "- Different local clock display.\n",
    "\n",
    "This enables region-specific views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a05151",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbf3eb",
   "metadata": {},
   "source": [
    "- Pandas interprets aware timestamps as instants on the time axis.\n",
    "\n",
    "- It remaps those instants to target timezone offset/rules.\n",
    "\n",
    "- Local clock components (hour/date) may change, but instant remains identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1293320d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98a3b1",
   "metadata": {},
   "source": [
    "- Calling on naive timestamps raises errors.\n",
    "\n",
    "- Wrong source localization before convert produces incorrect local times.\n",
    "\n",
    "- DST transitions can affect local-hour interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6084e",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d092c",
   "metadata": {},
   "source": [
    "- Are timestamps already timezone-aware before conversion?\n",
    "\n",
    "- Is source timezone assignment validated?\n",
    "\n",
    "- Which target timezone should reports use?\n",
    "\n",
    "- Are DST transitions tested around critical dates?\n",
    "\n",
    "- Do downstream joins depend on local or UTC timestamps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d9112",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0793f34",
   "metadata": {},
   "source": [
    "Use `dt.tz_convert` to present aware timestamps in the correct local timezone without changing event instant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86b536",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert UTC event logs to local support timezone for shift-based SLA monitoring.\n",
    "\n",
    "Scenario: analysis team reviews event times in UTC+1 local clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "8d365235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   2025-01-01 13:00:00+01:00\n",
      "b   2025-01-01 19:00:00+01:00\n",
      "Name: event_utc, dtype: datetime64[us, UTC+01:00]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "event_utc = pd.Series(pd.to_datetime([\"2025-01-01 12:00:00\", \"2025-01-01 18:00:00\"]), index=[\"a\", \"b\"], name=\"event_utc\").dt.tz_localize(\"UTC\")\n",
    "event_local = event_utc.dt.tz_convert(\"+01:00\")\n",
    "print(event_local)\n",
    "\n",
    "assert event_local.loc[\"a\"].hour == 13\n",
    "assert event_local.loc[\"b\"].hour == 19\n",
    "assert str(event_local.dtype).endswith(\"+01:00]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac117c",
   "metadata": {},
   "source": [
    "##### Series.dt.strftime(format)\n",
    "`dt.strftime(format)` formats datetime values as strings according to a format pattern. It is useful for display labels, export fields, and key formatting. The result is text, so datetime arithmetic no longer applies directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "d2efa021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1   2025-03-01 08:15:00\n",
       "d2   2025-03-02 09:45:00\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-03-01 08:15:00\", \"2025-03-02 09:45:00\"]), index=[\"d1\", \"d2\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "c364ac8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d1    2025-03-01 08:15\n",
       "d2    2025-03-02 09:45\n",
       "Name: ts, dtype: str"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11744897",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cee4d",
   "metadata": {},
   "source": [
    "`series.dt.strftime(format)` turns datetimes into formatted strings using your template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c8e3e",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a8979",
   "metadata": {},
   "source": [
    "- `date_format` (`str`): formatting pattern (for example, `%Y-%m-%d`, `%H:%M`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2d0c7",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56715462",
   "metadata": {},
   "source": [
    "Think of applying a custom date display format to spreadsheet date cells.\n",
    "\n",
    "- Underlying dates become text strings.\n",
    "\n",
    "- Format is consistent across rows.\n",
    "\n",
    "Great for presentation/export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05216ec",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260aeb5",
   "metadata": {},
   "source": [
    "- Pandas formats each datetime using the provided format directives.\n",
    "\n",
    "- Output values are string representations.\n",
    "\n",
    "- Index alignment is preserved, but dtype becomes string-like/object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94482ac",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d350ca5",
   "metadata": {},
   "source": [
    "- Once formatted, values are strings and lose datetime operations unless parsed again.\n",
    "\n",
    "- Format directives must match locale/report expectations.\n",
    "\n",
    "- Missing datetimes produce missing-formatted outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad7b6d",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f69e75",
   "metadata": {},
   "source": [
    "- Is this transformation only for presentation/export?\n",
    "\n",
    "- Do downstream steps still require datetime arithmetic?\n",
    "\n",
    "- Is format spec consistent with consuming system?\n",
    "\n",
    "- Should timezone conversion happen before formatting?\n",
    "\n",
    "- Are missing values represented clearly in output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7b87e",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a133bb",
   "metadata": {},
   "source": [
    "Use `dt.strftime` at the final presentation/export stage to avoid losing datetime semantics too early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06624fb",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Create human-readable timestamp labels for a CSV report consumed by non-technical stakeholders.\n",
    "\n",
    "Scenario: report requires `YYYY-MM-DD HH:MM` format strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "57802f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted label: {'r1': '2025-03-01 08:15', 'r2': '2025-03-02 09:45'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "report_ts = pd.Series(pd.to_datetime([\"2025-03-01 08:15:00\", \"2025-03-02 09:45:00\"]), index=[\"r1\", \"r2\"], name=\"report_ts\")\n",
    "label = report_ts.dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "print(\"Formatted label:\", label.to_dict())\n",
    "\n",
    "assert label.loc[\"r1\"] == \"2025-03-01 08:15\"\n",
    "assert label.loc[\"r2\"] == \"2025-03-02 09:45\"\n",
    "assert label.dtype == object or str(label.dtype) in {\"string\", \"str\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a4822",
   "metadata": {},
   "source": [
    "##### Series.dt.to_period(freq)\n",
    "`dt.to_period(freq)` converts datetime values to period values at a chosen frequency. It is useful for period-based grouping keys like month or quarter. Values become period-typed, while index labels remain aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "7c38fec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   2025-01-10\n",
       "x2   2025-01-31\n",
       "x3   2025-02-01\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-10\", \"2025-01-31\", \"2025-02-01\"]), index=[\"x1\", \"x2\", \"x3\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "4930815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    2025-01\n",
       "x2    2025-01\n",
       "x3    2025-02\n",
       "Name: ts, dtype: period[M]"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a53b6",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebcdaf",
   "metadata": {},
   "source": [
    "`series.dt.to_period(freq)` maps datetimes to period buckets (for example monthly periods)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d46a8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a8ee2",
   "metadata": {},
   "source": [
    "- `freq` (`str` or `None`): target period frequency (for example, `\"M\"`, `\"Q\"`, `\"D\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b2e8d2",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f07ba",
   "metadata": {},
   "source": [
    "Think of replacing exact dates in a spreadsheet with their month bucket labels.\n",
    "\n",
    "- Day precision is collapsed to period grain.\n",
    "\n",
    "- Useful for period reporting keys.\n",
    "\n",
    "Row mapping remains intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ed6fd",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c60a3",
   "metadata": {},
   "source": [
    "- Pandas converts each datetime to the corresponding period at `freq`.\n",
    "\n",
    "- Output becomes period dtype Series.\n",
    "\n",
    "- Index alignment is preserved for downstream joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919ca5d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd8199",
   "metadata": {},
   "source": [
    "- Choosing wrong frequency can lose needed detail.\n",
    "\n",
    "- Period values may require conversion back for timestamp-specific tools.\n",
    "\n",
    "- Mixed timezone handling should be settled before conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b6687",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff8651",
   "metadata": {},
   "source": [
    "- Is month/quarter/day period the correct business grain?\n",
    "\n",
    "- Do downstream tools accept period dtype?\n",
    "\n",
    "- Should conversion occur before or after aggregations?\n",
    "\n",
    "- Is timezone normalization complete first?\n",
    "\n",
    "- Is period label convention documented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07e50a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156ff84",
   "metadata": {},
   "source": [
    "Use `dt.to_period` to create clean period keys from timestamps for period-level analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c83f0",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Generate monthly period keys from transaction timestamps before period-level KPI aggregation.\n",
    "\n",
    "Scenario: dashboard groups on monthly periods instead of exact dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "ea865ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month period: {'t1': Period('2025-01', 'M'), 't2': Period('2025-01', 'M'), 't3': Period('2025-02', 'M')}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txn_ts = pd.Series(pd.to_datetime([\"2025-01-10\", \"2025-01-31\", \"2025-02-01\"]), index=[\"t1\", \"t2\", \"t3\"], name=\"txn_ts\")\n",
    "month_period = txn_ts.dt.to_period(\"M\")\n",
    "print(\"Month period:\", month_period.to_dict())\n",
    "\n",
    "assert str(month_period.loc[\"t1\"]) == \"2025-01\"\n",
    "assert str(month_period.loc[\"t3\"]) == \"2025-02\"\n",
    "assert month_period.index.equals(txn_ts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363f78e",
   "metadata": {},
   "source": [
    "##### Series.dt.to_timestamp(freq=None, how=\"start\")\n",
    "`dt.to_timestamp(...)` converts period values back to timestamp values at period boundaries. It is used when period-keyed data must rejoin timestamp-based workflows. This accessor applies when Series values are period-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "9efbdab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1    2025-01\n",
       "p2    2025-02\n",
       "p3    2025-03\n",
       "Name: period_val, dtype: period[M]"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.period_range(\"2025-01\", periods=3, freq=\"M\"), index=[\"p1\", \"p2\", \"p3\"], name=\"period_val\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "b0d2da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1   2025-01-01\n",
       "p2   2025-02-01\n",
       "p3   2025-03-01\n",
       "Name: period_val, dtype: datetime64[us]"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.to_timestamp(how=\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64530568",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849e159",
   "metadata": {},
   "source": [
    "`series.dt.to_timestamp(...)` turns period entries into concrete timestamps at start/end boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31788fa9",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434110b0",
   "metadata": {},
   "source": [
    "- `freq` (frequency or `None`): target timestamp frequency when needed.\n",
    "\n",
    "- `how` (`\"start\"` or `\"end\"`, default `\"start\"`): choose which period boundary to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52ab8e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1de30",
   "metadata": {},
   "source": [
    "Think of converting monthly spreadsheet labels into exact date stamps (first day or last day).\n",
    "\n",
    "- Period keys become concrete datetimes.\n",
    "\n",
    "- Useful for timestamp joins/charts.\n",
    "\n",
    "Boundary choice controls output date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafa4d6",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381600d",
   "metadata": {},
   "source": [
    "- Pandas reads each period value and computes boundary timestamp.\n",
    "\n",
    "- `how` selects start or end boundary.\n",
    "\n",
    "- Output is datetime dtype Series aligned to original index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63849720",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde79bc6",
   "metadata": {},
   "source": [
    "- Method requires period-like values; datetime values should not use this path.\n",
    "\n",
    "- Start/end boundary choice can shift reported day/time.\n",
    "\n",
    "- Downstream timezone handling may still be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeea643",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cea82f",
   "metadata": {},
   "source": [
    "- Are Series values period dtype before conversion?\n",
    "\n",
    "- Should boundary be start or end for business meaning?\n",
    "\n",
    "- Is frequency compatible with downstream models/charts?\n",
    "\n",
    "- Do you need timezone localization after conversion?\n",
    "\n",
    "- Are boundary conventions documented clearly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a17e8a",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f75ad",
   "metadata": {},
   "source": [
    "Use `dt.to_timestamp` to re-materialize period values into concrete timestamps with explicit boundary control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da39b6",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Convert monthly period features to month-start timestamps before joining with daily forecast frames.\n",
    "\n",
    "Scenario: forecasting tables use DatetimeIndex keys, not period dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "f2348df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp feature: {'f1': Timestamp('2025-01-01 00:00:00'), 'f2': Timestamp('2025-02-01 00:00:00'), 'f3': Timestamp('2025-03-01 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "period_feat = pd.Series(pd.period_range(\"2025-01\", periods=3, freq=\"M\"), index=[\"f1\", \"f2\", \"f3\"], name=\"period_feat\")\n",
    "ts_feat = period_feat.dt.to_timestamp(how=\"start\")\n",
    "print(\"Timestamp feature:\", ts_feat.to_dict())\n",
    "\n",
    "assert ts_feat.loc[\"f1\"] == pd.Timestamp(\"2025-01-01\")\n",
    "assert ts_feat.loc[\"f3\"] == pd.Timestamp(\"2025-03-01\")\n",
    "assert ts_feat.index.equals(period_feat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd183a",
   "metadata": {},
   "source": [
    "##### Series.dt.round(freq)\n",
    "`dt.round(freq)` rounds each timestamp to the nearest specified frequency boundary. It is useful for time-bucketing event logs before aggregation. Ambiguous/nonexistent DST cases can be controlled with dedicated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "cd98347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1   2025-01-01 10:29:00\n",
       "r2   2025-01-01 10:31:00\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.to_datetime([\"2025-01-01 10:29:00\", \"2025-01-01 10:31:00\"]), index=[\"r1\", \"r2\"], name=\"ts\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "3fa79af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1   2025-01-01 10:00:00\n",
       "r2   2025-01-01 11:00:00\n",
       "Name: ts, dtype: datetime64[us]"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.dt.round(\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f69625",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0291752",
   "metadata": {},
   "source": [
    "`series.dt.round(freq)` snaps timestamps to nearest frequency point (for example nearest hour)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e95f4",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33afad7",
   "metadata": {},
   "source": [
    "- `freq` (offset alias): rounding frequency (for example `\"h\"`, `\"15min\"`).\n",
    "\n",
    "- `ambiguous` (default `\"raise\"`): handling for ambiguous DST timestamps.\n",
    "\n",
    "- `nonexistent` (default `\"raise\"`): handling for nonexistent DST timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bac7a",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800bf35",
   "metadata": {},
   "source": [
    "Think of rounding spreadsheet times to nearest clock interval bucket.\n",
    "\n",
    "- 10:29 rounds to 10:00.\n",
    "\n",
    "- 10:31 rounds to 11:00.\n",
    "\n",
    "Useful for standardized time bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca2b8a",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea855f2",
   "metadata": {},
   "source": [
    "- Pandas computes nearest boundary according to `freq` for each timestamp.\n",
    "\n",
    "- It adjusts values to that boundary while preserving index labels.\n",
    "\n",
    "- DST edge parameters govern ambiguous/nonexistent local times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ddd9a",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425bedf",
   "metadata": {},
   "source": [
    "- Rounding may shift events across boundaries near cutoff times.\n",
    "\n",
    "- DST transitions can create ambiguous/nonexistent rounding cases.\n",
    "\n",
    "- Over-rounding may hide short-lived event spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd21fcc",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6b4ee",
   "metadata": {},
   "source": [
    "- Is rounding frequency aligned with reporting cadence?\n",
    "\n",
    "- Should near-boundary shifts be acceptable for business logic?\n",
    "\n",
    "- Are DST edge-case policies defined?\n",
    "\n",
    "- Would floor/ceil be more appropriate than round?\n",
    "\n",
    "- Are raw timestamps retained for audit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a8953",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36749441",
   "metadata": {},
   "source": [
    "Use `dt.round` to create consistent time buckets, with explicit DST policy where relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627ad25",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Round clickstream timestamps to hourly buckets before traffic aggregation.\n",
    "\n",
    "Scenario: dashboard reports hourly counts with nearest-hour assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "1c24a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded hour: {'c1': Timestamp('2025-01-01 10:00:00'), 'c2': Timestamp('2025-01-01 11:00:00'), 'c3': Timestamp('2025-01-01 12:00:00')}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "click_ts = pd.Series(pd.to_datetime([\"2025-01-01 10:29:00\", \"2025-01-01 10:31:00\", \"2025-01-01 11:30:00\"]), index=[\"c1\", \"c2\", \"c3\"], name=\"click_ts\")\n",
    "hour_bucket = click_ts.dt.round(\"h\")\n",
    "print(\"Rounded hour:\", hour_bucket.to_dict())\n",
    "\n",
    "assert hour_bucket.loc[\"c1\"] == pd.Timestamp(\"2025-01-01 10:00:00\")\n",
    "assert hour_bucket.loc[\"c2\"] == pd.Timestamp(\"2025-01-01 11:00:00\")\n",
    "assert hour_bucket.loc[\"c3\"] == pd.Timestamp(\"2025-01-01 12:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569b177",
   "metadata": {},
   "source": [
    "#### Category accessor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd816f4",
   "metadata": {},
   "source": [
    "##### Series.cat.categories\n",
    "`cat.categories` returns the category labels defined in the categorical dtype as an Index. It is useful to inspect allowed levels and validate taxonomy consistency across datasets. Categories can include levels not currently present in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "36accd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1       new\n",
       "u2    active\n",
       "u3    active\n",
       "Name: status, dtype: category\n",
       "Categories (3, str): ['new', 'active', 'churned']"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"new\", \"active\", \"active\"], categories=[\"new\", \"active\", \"churned\"]), index=[\"u1\", \"u2\", \"u3\"], name=\"status\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "ff73b664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new', 'active', 'churned'], dtype='str')"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1422804",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccabc7",
   "metadata": {},
   "source": [
    "`series.cat.categories` shows the full allowed category list, not only observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31998be2",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c9b65",
   "metadata": {},
   "source": [
    "- `(none)`: `cat.categories` is a categorical property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89eaa6",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be57b4",
   "metadata": {},
   "source": [
    "Think of category labels as the legend of allowed values in a spreadsheet dropdown.\n",
    "\n",
    "- The legend can contain values not currently selected.\n",
    "\n",
    "- Data rows reference this legend.\n",
    "\n",
    "You can audit domain consistency quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a295d6d",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a07eb",
   "metadata": {},
   "source": [
    "- Pandas stores category levels in categorical dtype metadata.\n",
    "\n",
    "- `cat.categories` reads that metadata directly.\n",
    "\n",
    "- Returned Index is independent from how many rows currently use each level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73998251",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd1632f",
   "metadata": {},
   "source": [
    "- Unused categories may confuse summaries if not expected.\n",
    "\n",
    "- Category order in this Index affects sorting if ordered behavior is used.\n",
    "\n",
    "- Mixing datasets with different category sets can break assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b99319",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c308d",
   "metadata": {},
   "source": [
    "- Are category levels centrally defined and versioned?\n",
    "\n",
    "- Should unused categories be removed before analysis?\n",
    "\n",
    "- Is category order meaningful for downstream logic?\n",
    "\n",
    "- Do all data sources share the same category set?\n",
    "\n",
    "- Are new categories reviewed before use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4437eb",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3f567",
   "metadata": {},
   "source": [
    "Use `cat.categories` to inspect and validate the allowed categorical levels explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383cedc",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Validate customer lifecycle status taxonomy before merging monthly snapshots from multiple systems.\n",
    "\n",
    "Scenario: downstream dashboards expect a fixed set of statuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "127a20ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category levels: ['new', 'active', 'churned']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "status = pd.Series(pd.Categorical([\"new\", \"active\", \"active\"], categories=[\"new\", \"active\", \"churned\"]), index=[\"c1\", \"c2\", \"c3\"], name=\"status\")\n",
    "levels = status.cat.categories\n",
    "print(\"Category levels:\", levels.tolist())\n",
    "\n",
    "assert list(levels) == [\"new\", \"active\", \"churned\"]\n",
    "assert \"churned\" in levels\n",
    "assert status.index.tolist() == [\"c1\", \"c2\", \"c3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1333b3",
   "metadata": {},
   "source": [
    "##### Series.cat.codes\n",
    "`cat.codes` returns integer codes representing category positions for each row. It is useful for compact storage and model-friendly encoding with category mapping retained separately. Missing category values are represented by code `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "bbdf6647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1       low\n",
       "r2      high\n",
       "r3       NaN\n",
       "r4    medium\n",
       "Name: risk, dtype: category\n",
       "Categories (3, str): ['low' < 'medium' < 'high']"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"low\", \"high\", None, \"medium\"], categories=[\"low\", \"medium\", \"high\"], ordered=True), index=[\"r1\", \"r2\", \"r3\", \"r4\"], name=\"risk\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "6d380c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    0\n",
       "r2    2\n",
       "r3   -1\n",
       "r4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b911201",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5322c",
   "metadata": {},
   "source": [
    "`series.cat.codes` gives each category an integer ID per row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b19c5",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1c385",
   "metadata": {},
   "source": [
    "- `(none)`: `cat.codes` is a categorical property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576c926",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745073b6",
   "metadata": {},
   "source": [
    "Think of replacing text labels in a spreadsheet with integer lookup IDs.\n",
    "\n",
    "- Each label maps to a code by category order.\n",
    "\n",
    "- Missing entries use a sentinel code.\n",
    "\n",
    "This speeds numeric processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7a281",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c005c",
   "metadata": {},
   "source": [
    "- Pandas stores each categorical value as an integer code internally.\n",
    "\n",
    "- `cat.codes` exposes those per-row codes as a Series.\n",
    "\n",
    "- Code-to-label mapping is defined by `cat.categories` order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60dc10",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da5890",
   "metadata": {},
   "source": [
    "- Codes depend on category order; reordering changes numeric meaning.\n",
    "\n",
    "- `-1` for missing must be handled explicitly in models.\n",
    "\n",
    "- Codes alone are not self-describing without category mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7992c6",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a920c",
   "metadata": {},
   "source": [
    "- Is category order fixed before using codes in modeling?\n",
    "\n",
    "- How are missing code `-1` values treated?\n",
    "\n",
    "- Is code-to-label mapping persisted for reproducibility?\n",
    "\n",
    "- Do you need ordered categories or nominal categories?\n",
    "\n",
    "- Could re-categorization invalidate old model features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863b8ab",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a9ced",
   "metadata": {},
   "source": [
    "Use `cat.codes` for efficient numeric representation, but always keep label mapping explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345345c5",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Build lightweight risk-tier features for model input while preserving category mapping for explainability.\n",
    "\n",
    "Scenario: missing tiers remain trackable via `-1` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "eef0afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category codes: {'a': 0, 'b': 2, 'c': -1, 'd': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "risk = pd.Series(pd.Categorical([\"low\", \"high\", None, \"medium\"], categories=[\"low\", \"medium\", \"high\"], ordered=True), index=[\"a\", \"b\", \"c\", \"d\"], name=\"risk\")\n",
    "codes = risk.cat.codes\n",
    "print(\"Category codes:\", codes.to_dict())\n",
    "\n",
    "assert int(codes.loc[\"a\"]) == 0\n",
    "assert int(codes.loc[\"b\"]) == 2\n",
    "assert int(codes.loc[\"c\"]) == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0618f",
   "metadata": {},
   "source": [
    "##### Series.cat.ordered\n",
    "`cat.ordered` tells whether category ordering is enabled for the categorical dtype. Ordered categories affect comparisons and sorting semantics. This flag is critical when category rank has business meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "c622d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u1    bronze\n",
       "u2    silver\n",
       "u3      gold\n",
       "Name: tier, dtype: category\n",
       "Categories (3, str): ['bronze' < 'silver' < 'gold']"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"bronze\", \"silver\", \"gold\"], categories=[\"bronze\", \"silver\", \"gold\"], ordered=True), index=[\"u1\", \"u2\", \"u3\"], name=\"tier\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "bae841b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01236fda",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe5ed5",
   "metadata": {},
   "source": [
    "`series.cat.ordered` returns `True` or `False` depending on whether category order matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c2b09",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ca192",
   "metadata": {},
   "source": [
    "- `(none)`: `cat.ordered` is a boolean categorical property accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228ca0e",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967ef60",
   "metadata": {},
   "source": [
    "Think of a spreadsheet dropdown where values may have rank order (bronze < silver < gold).\n",
    "\n",
    "- Ordered means rank comparisons are meaningful.\n",
    "\n",
    "- Unordered means labels are nominal only.\n",
    "\n",
    "This changes sort/compare behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7990d2",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7a8fb",
   "metadata": {},
   "source": [
    "- Pandas stores an `ordered` flag in categorical dtype metadata.\n",
    "\n",
    "- `cat.ordered` reads that flag directly.\n",
    "\n",
    "- Comparison/sorting rules use this metadata when operating on categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad52db",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3cab7",
   "metadata": {},
   "source": [
    "- Forgetting to set order can produce invalid ranking logic.\n",
    "\n",
    "- Wrong order definition can silently bias model/report outputs.\n",
    "\n",
    "- Ordered flag does not enforce business validation by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31edb0",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4edba3",
   "metadata": {},
   "source": [
    "- Does this category have true ordinal meaning?\n",
    "\n",
    "- Is the defined order agreed with business stakeholders?\n",
    "\n",
    "- Are comparisons on this category used downstream?\n",
    "\n",
    "- Should order differ by locale/business unit?\n",
    "\n",
    "- Is order metadata tested in pipelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731eedb9",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f287745",
   "metadata": {},
   "source": [
    "Use `cat.ordered` to confirm whether categorical comparisons should follow a defined rank order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8ba6d",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Check loyalty-tier order metadata before computing tier progression metrics.\n",
    "\n",
    "Scenario: progression logic requires ordered categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "1077a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered flag: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tier = pd.Series(pd.Categorical([\"bronze\", \"silver\", \"gold\"], categories=[\"bronze\", \"silver\", \"gold\"], ordered=True), index=[\"c1\", \"c2\", \"c3\"], name=\"tier\")\n",
    "is_ordered = tier.cat.ordered\n",
    "print(\"Ordered flag:\", is_ordered)\n",
    "\n",
    "assert bool(is_ordered) is True\n",
    "assert tier.cat.categories.tolist() == [\"bronze\", \"silver\", \"gold\"]\n",
    "assert tier.index.tolist() == [\"c1\", \"c2\", \"c3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ff134",
   "metadata": {},
   "source": [
    "##### Series.cat.add_categories(new_categories)\n",
    "`cat.add_categories(new_categories)` expands the set of allowed category labels without changing current values. It is useful when a new valid level appears in incoming data. The method returns a new Series with updated categorical dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "0162edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    A\n",
       "r2    B\n",
       "r3    A\n",
       "Name: segment, dtype: category\n",
       "Categories (2, str): ['A', 'B']"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"A\", \"B\", \"A\"], categories=[\"A\", \"B\"]), index=[\"r1\", \"r2\", \"r3\"], name=\"segment\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "48b88d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    A\n",
       "r2    B\n",
       "r3    A\n",
       "Name: segment, dtype: category\n",
       "Categories (3, str): ['A', 'B', 'C']"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.add_categories([\"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c059d2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b13557",
   "metadata": {},
   "source": [
    "`series.cat.add_categories(...)` adds new allowed labels to the category list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d405d30",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363695ac",
   "metadata": {},
   "source": [
    "- `new_categories` (label or list-like): category labels to append to the existing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c0692",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1eec3",
   "metadata": {},
   "source": [
    "Think of adding a new option to a spreadsheet validation dropdown before anyone selects it.\n",
    "\n",
    "- Existing rows stay unchanged.\n",
    "\n",
    "- New option becomes allowed.\n",
    "\n",
    "Useful for evolving taxonomies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a77d8e",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cf602",
   "metadata": {},
   "source": [
    "- Pandas creates a new categorical dtype including old + new categories.\n",
    "\n",
    "- Existing row codes remain mapped to original categories.\n",
    "\n",
    "- New categories are available for future assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef674e30",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88b553",
   "metadata": {},
   "source": [
    "- Adding many unused categories can clutter domain definitions.\n",
    "\n",
    "- Duplicate additions raise errors.\n",
    "\n",
    "- Category order implications should be reviewed if ordered=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f4450",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc2b76",
   "metadata": {},
   "source": [
    "- Is the new category officially approved?\n",
    "\n",
    "- Should category order be adjusted after adding levels?\n",
    "\n",
    "- Are downstream validation rules updated too?\n",
    "\n",
    "- Could unused added categories confuse reports?\n",
    "\n",
    "- Do you need migration logic for legacy rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd0a2c",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcabcfb",
   "metadata": {},
   "source": [
    "Use `add_categories` to extend allowed labels safely before assigning new category values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9e663",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Introduce a new customer segment label before nightly scoring starts assigning it.\n",
    "\n",
    "Scenario: pipeline must accept new segment without breaking categorical validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "bbdea481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended categories: ['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "segment = pd.Series(pd.Categorical([\"A\", \"B\", \"A\"], categories=[\"A\", \"B\"]), index=[\"c1\", \"c2\", \"c3\"], name=\"segment\")\n",
    "segment_ext = segment.cat.add_categories([\"C\"])\n",
    "print(\"Extended categories:\", segment_ext.cat.categories.tolist())\n",
    "\n",
    "assert \"C\" in segment_ext.cat.categories\n",
    "assert segment_ext.cat.categories.tolist() == [\"A\", \"B\", \"C\"]\n",
    "assert segment_ext.iloc[0] == \"A\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bbe16",
   "metadata": {},
   "source": [
    "##### Series.cat.remove_categories(categories)\n",
    "`cat.remove_categories(categories)` removes specified labels from the category set. Any existing values using removed labels become missing (`NaN`). It is useful when deprecating old taxonomy levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "d3494227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i1       low\n",
       "i2    medium\n",
       "i3      high\n",
       "i4    medium\n",
       "Name: priority, dtype: category\n",
       "Categories (3, str): ['low', 'medium', 'high']"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"low\", \"medium\", \"high\", \"medium\"], categories=[\"low\", \"medium\", \"high\"]), index=[\"i1\", \"i2\", \"i3\", \"i4\"], name=\"priority\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "1db1afa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i1     low\n",
       "i2     NaN\n",
       "i3    high\n",
       "i4     NaN\n",
       "Name: priority, dtype: category\n",
       "Categories (2, str): ['high', 'low']"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.remove_categories([\"medium\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764be9c2",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647531a",
   "metadata": {},
   "source": [
    "`series.cat.remove_categories(...)` deletes category labels and nulls rows that used them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f75b3b8",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a65774",
   "metadata": {},
   "source": [
    "- `removals` (label or list-like): category labels to remove from allowed set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a7490",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b70445",
   "metadata": {},
   "source": [
    "Think of removing an option from a spreadsheet dropdown.\n",
    "\n",
    "- Cells using that removed option become blank/invalid.\n",
    "\n",
    "- Remaining options stay valid.\n",
    "\n",
    "This enforces updated taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55781f02",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca88e3d",
   "metadata": {},
   "source": [
    "- Pandas drops selected labels from categorical metadata.\n",
    "\n",
    "- Rows referencing removed labels are reassigned to missing value.\n",
    "\n",
    "- Output returns updated categorical dtype and values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067297d",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddcde5",
   "metadata": {},
   "source": [
    "- Removing active categories can create many missing values.\n",
    "\n",
    "- Downstream logic must handle new NaNs explicitly.\n",
    "\n",
    "- Irreversible data meaning loss if not backed up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0c532",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad41c1",
   "metadata": {},
   "source": [
    "- Are removed categories truly obsolete?\n",
    "\n",
    "- How will NaNs created by removal be handled?\n",
    "\n",
    "- Should values be remapped before removal instead?\n",
    "\n",
    "- Is impact on historical reporting acceptable?\n",
    "\n",
    "- Is a backup snapshot kept before category removal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40925c1",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48efb5",
   "metadata": {},
   "source": [
    "Use `remove_categories` when retiring labels, and plan explicit handling for rows that become missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4368f",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Deprecate a legacy priority level and force unresolved rows into NA for manual review.\n",
    "\n",
    "Scenario: removed category should no longer appear in operational dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "9550985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1     low\n",
      "t2     NaN\n",
      "t3    high\n",
      "t4     NaN\n",
      "Name: priority, dtype: category\n",
      "Categories (2, str): ['high', 'low']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "priority = pd.Series(pd.Categorical([\"low\", \"medium\", \"high\", \"medium\"], categories=[\"low\", \"medium\", \"high\"]), index=[\"t1\", \"t2\", \"t3\", \"t4\"], name=\"priority\")\n",
    "priority_new = priority.cat.remove_categories([\"medium\"])\n",
    "print(priority_new)\n",
    "\n",
    "assert \"medium\" not in priority_new.cat.categories\n",
    "assert pd.isna(priority_new.loc[\"t2\"])\n",
    "assert priority_new.loc[\"t3\"] == \"high\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c7363f",
   "metadata": {},
   "source": [
    "##### Series.cat.rename_categories(new_categories)\n",
    "`cat.rename_categories(new_categories)` renames category labels while preserving category structure and row assignments. It is useful for taxonomy relabeling without changing business meaning. Renaming can be done with mapping, sequence, or callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "3e7d0487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1    L\n",
       "r2    M\n",
       "r3    H\n",
       "Name: risk, dtype: category\n",
       "Categories (3, str): ['L', 'M', 'H']"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"L\", \"M\", \"H\"], categories=[\"L\", \"M\", \"H\"]), index=[\"r1\", \"r2\", \"r3\"], name=\"risk\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "052d005c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r1       Low\n",
       "r2    Medium\n",
       "r3      High\n",
       "Name: risk, dtype: category\n",
       "Categories (3, str): ['Low', 'Medium', 'High']"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.rename_categories({\"L\": \"Low\", \"M\": \"Medium\", \"H\": \"High\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bc358",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ef0fb",
   "metadata": {},
   "source": [
    "`series.cat.rename_categories(...)` changes category labels without changing which rows belong to each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61571534",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6e6bc",
   "metadata": {},
   "source": [
    "- `new_categories` (list-like, dict-like, or callable): renaming definition for existing category labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c21e2",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c10ed",
   "metadata": {},
   "source": [
    "Think of renaming labels in a spreadsheet legend while keeping every row mapped to the same legend slot.\n",
    "\n",
    "- Meaning stays same.\n",
    "\n",
    "- Label text becomes clearer.\n",
    "\n",
    "No recoding of row assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211de5b",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742528a",
   "metadata": {},
   "source": [
    "- Pandas updates category label names in categorical metadata.\n",
    "\n",
    "- Row codes remain unchanged, so membership mapping is preserved.\n",
    "\n",
    "- Result has same shape/index with renamed category labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03984035",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd965e",
   "metadata": {},
   "source": [
    "- Incomplete/incorrect mapping can raise errors or leave inconsistent naming.\n",
    "\n",
    "- Renaming does not merge categories with different meanings.\n",
    "\n",
    "- Downstream references to old labels will break if not updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99acb67",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb58ba5",
   "metadata": {},
   "source": [
    "- Is mapping complete for every existing category?\n",
    "\n",
    "- Are renamed labels backward-compatible with downstream systems?\n",
    "\n",
    "- Do any old labels need deprecation/removal instead of rename?\n",
    "\n",
    "- Are reports/tests updated to new label names?\n",
    "\n",
    "- Is business meaning unchanged after relabeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12692f",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f03a8",
   "metadata": {},
   "source": [
    "Use `rename_categories` to clean label names while preserving categorical assignments exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bf7fa",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Migrate shorthand risk labels to readable names for executive reporting.\n",
    "\n",
    "Scenario: model logic stays unchanged, but report labels must be human-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "0798e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a       Low\n",
      "b    Medium\n",
      "c      High\n",
      "Name: risk, dtype: category\n",
      "Categories (3, str): ['Low', 'Medium', 'High']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "risk = pd.Series(pd.Categorical([\"L\", \"M\", \"H\"], categories=[\"L\", \"M\", \"H\"]), index=[\"a\", \"b\", \"c\"], name=\"risk\")\n",
    "risk_named = risk.cat.rename_categories({\"L\": \"Low\", \"M\": \"Medium\", \"H\": \"High\"})\n",
    "print(risk_named)\n",
    "\n",
    "assert risk_named.cat.categories.tolist() == [\"Low\", \"Medium\", \"High\"]\n",
    "assert risk_named.loc[\"a\"] == \"Low\"\n",
    "assert risk_named.index.equals(risk.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bffef",
   "metadata": {},
   "source": [
    "##### Series.cat.reorder_categories(new_categories)\n",
    "`cat.reorder_categories(new_categories, ordered=...)` changes the category order without changing labels. It is important when sorting/comparison priority must follow business rank. The new order must contain exactly the same category set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "74a8d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1       low\n",
       "x2      high\n",
       "x3    medium\n",
       "Name: severity, dtype: category\n",
       "Categories (3, str): ['low' < 'medium' < 'high']"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(pd.Categorical([\"low\", \"high\", \"medium\"], categories=[\"low\", \"medium\", \"high\"], ordered=True), index=[\"x1\", \"x2\", \"x3\"], name=\"severity\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "ab023ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1       low\n",
       "x2      high\n",
       "x3    medium\n",
       "Name: severity, dtype: category\n",
       "Categories (3, str): ['high' < 'medium' < 'low']"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.cat.reorder_categories([\"high\", \"medium\", \"low\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87a10a",
   "metadata": {},
   "source": [
    "###### In plain language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e287a",
   "metadata": {},
   "source": [
    "`series.cat.reorder_categories(...)` changes category ranking order used by sorting/comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b9a57",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ccefd6",
   "metadata": {},
   "source": [
    "- `new_categories` (list-like): full category list in desired new order (same elements required).\n",
    "\n",
    "- `ordered` (`bool` or `None`): optionally set ordered flag while reordering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7b11f",
   "metadata": {},
   "source": [
    "###### Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb626cd6",
   "metadata": {},
   "source": [
    "Think of changing the rank order in a spreadsheet legend (for example High > Medium > Low).\n",
    "\n",
    "- Labels stay the same.\n",
    "\n",
    "- Priority order changes.\n",
    "\n",
    "Sort results follow the new rank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb4314",
   "metadata": {},
   "source": [
    "###### Core mechanism (what causes what, and why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efcc4b",
   "metadata": {},
   "source": [
    "- Pandas validates `new_categories` has identical label set to existing categories.\n",
    "\n",
    "- It rewrites category order metadata accordingly.\n",
    "\n",
    "- Sorting/comparison operations then use the updated order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b83a0c",
   "metadata": {},
   "source": [
    "###### Weaknesses / edge cases / gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38df37",
   "metadata": {},
   "source": [
    "- Missing/extra labels in `new_categories` raise errors.\n",
    "\n",
    "- Reordering can change downstream sort outputs significantly.\n",
    "\n",
    "- Ordered semantics may be misunderstood if not documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71add2",
   "metadata": {},
   "source": [
    "###### Targeted questions (to catch gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d6bdd",
   "metadata": {},
   "source": [
    "- Is the new order approved as business ranking?\n",
    "\n",
    "- Does `new_categories` include exactly the same labels?\n",
    "\n",
    "- Should ordered flag be explicitly set here?\n",
    "\n",
    "- Are downstream sorted reports validated after reorder?\n",
    "\n",
    "- Is old-vs-new ordering impact communicated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ac601",
   "metadata": {},
   "source": [
    "###### Refined explanation (simpler, clearer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee6485",
   "metadata": {},
   "source": [
    "Use `reorder_categories` to enforce business ranking in categorical sorting and comparison workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897b308",
   "metadata": {},
   "source": [
    "###### Real-life use case:\n",
    "Prioritize incident severity sorting so `high` appears before `medium` and `low` in monitoring queues.\n",
    "\n",
    "Scenario: queue view must follow operational urgency, not alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "7477f6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered categories: ['high', 'medium', 'low']\n",
      "Sorted severity: {'i2': 'high', 'i3': 'medium', 'i1': 'low'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "severity = pd.Series(pd.Categorical([\"low\", \"high\", \"medium\"], categories=[\"low\", \"medium\", \"high\"], ordered=True), index=[\"i1\", \"i2\", \"i3\"], name=\"severity\")\n",
    "severity_ord = severity.cat.reorder_categories([\"high\", \"medium\", \"low\"], ordered=True)\n",
    "sorted_sev = severity_ord.sort_values()\n",
    "print(\"Reordered categories:\", severity_ord.cat.categories.tolist())\n",
    "print(\"Sorted severity:\", sorted_sev.to_dict())\n",
    "\n",
    "assert severity_ord.cat.categories.tolist() == [\"high\", \"medium\", \"low\"]\n",
    "assert sorted_sev.iloc[0] == \"high\"\n",
    "assert severity_ord.cat.ordered is True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
